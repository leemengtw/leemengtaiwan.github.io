<!DOCTYPE html>
<!--[if lt IE 9 ]><html class="no-js oldie" lang="zh-hant-tw"> <![endif]-->
<!--[if IE 9 ]><html class="no-js oldie ie9" lang="zh-hant-tw"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<html class="no-js" lang="zh-hant-tw">
<!--<![endif]-->

<head>

    <!--- basic page needs
    ================================================== -->
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="author" content="Lee Meng" />
<title>LeeMeng - 由淺入深的深度學習資源整理</title>
    <!--- article-specific meta data
    ================================================== -->
        <meta name="description" content="這裡紀錄了我在學習深度學習時蒐集的一些線上資源。內容由淺入深，而且會一直被更新，希望能幫助你順利地開始學習：）" />
        <meta name="keywords" content="深度學習, Python, Keras, TensorFlow" />
        <meta name="tags" content="深度學習" />
        <meta name="tags" content="Python" />
        <meta name="tags" content="Keras" />
        <meta name="tags" content="TensorFlow" />


    <!--- Open Graph Object metas
    ================================================== -->
        <meta property="og:image" content="https://leemeng.tw/theme/images/background/joshua-newton-214848-unsplash.jpg" />
        <meta property="og:type" content="article" />
        <meta property="og:url" content="https://leemeng.tw/deep-learning-resources.html" />
        <meta property="og:title" content="由淺入深的深度學習資源整理" />
        <meta property="og:description" content="這裡紀錄了我在學習深度學習時蒐集的一些線上資源。內容由淺入深，而且會一直被更新，希望能幫助你順利地開始學習：）" />

    <!-- mobile specific metas
    ================================================== -->
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- CSS
    ================================================== -->
    <!--for customized css in individual page-->
        <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/bootstrap.min.css">

    <!--for showing toc navigation which slide in from left-->
        <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/toc-nav.css">

    <!--for responsive embed youtube video-->
        <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/embed_youtube.css">

    <!--for prettify dark-mode result-->
        <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/darkmode.css">

    <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/base.css">
    <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/vendor.css">
    <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/main.css">
    <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/ipython.css">
    <link rel="stylesheet" type="text/css" href='https://leemeng.tw/theme/css/progress-bar.css' />


    <!--TiqueSearch-->
    <link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400">
    <link rel="stylesheet" href="https://leemeng.tw/theme/tipuesearch/css/normalize.css">
    <link rel="stylesheet" href="https://leemeng.tw/theme/tipuesearch/css/tipuesearch.css">

    <!-- script
    ================================================== -->
    <script src="https://leemeng.tw/theme/js/modernizr.js"></script>
    <script src="https://leemeng.tw/theme/js/pace.min.js"></script>


    <!-- favicons
    ================================================== -->
    <link rel="shortcut icon" href="../theme/images/favicon.ico" type="image/x-icon"/>
    <link rel="icon" href="../theme/images/favicon.ico" type="image/x-icon"/>

<!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-106559980-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments)};
  gtag('js', new Date());

  gtag('config', 'UA-106559980-1');
</script>



</head>


<body id="top">

    <!-- header
    ================================================== -->
    <header class="s-header">

        <div class="header-logo">
            <a class="site-logo" href="../index.html"><img src="https://leemeng.tw/theme/images/logo.png" alt="Homepage"></a>
        </div>
<!--navigation bar ref: http://jinja.pocoo.org/docs/2.10/tricks/-->



<nav class="header-nav-wrap">
    <ul class="header-nav">
        <li>
            <a href="../index.html#home">Home</a>
        </li>
        <li>
            <a href="../index.html#about">About</a>
        </li>
        <li>
            <a href="../index.html#projects">Projects</a>
        </li>
        <li class="current">
            <a href="../blog.html">Blog</a>
        </li>
        <li>
            <a href="https://demo.leemeng.tw">Demo</a>
        </li>
        <li>
            <a href="../books.html">Books</a>
        </li>
        <li>
            <a href="../index.html#contact">Contact</a>
        </li>

    </ul>

    <!--<div class="search-container">-->
        <!--<form action="../search.html">-->
            <!--<input type="text" placeholder="Search.." name="search">-->
            <!--<button type="submit"><i class="im im-magnifier" aria-hidden="true"></i></button>-->
        <!--</form>-->
    <!--</div>-->

</nav>
        <a class="header-menu-toggle" href="#0"><span>Menu</span></a>

    </header> <!-- end s-header -->



    <!--TOC navigation displayed when clicked from left-navigation button-->
    <div id="tocNav" class="overlay" onclick="closeTocNav()">
      <div class="overlay-content">
        <div id="toc"><ul><li><a class="toc-href" href="#" title="由淺入深的深度學習資源整理">由淺入深的深度學習資源整理</a><ul><li><a class="toc-href" href="#ben wen zhang jie" title="本文章節">本文章節</a></li><li><a class="toc-href" href="#you wan kong jian" title="遊玩空間">遊玩空間</a><ul><li><a class="toc-href" href="#deep playground" title="Deep Playground">Deep Playground</a></li><li><a class="toc-href" href="#convnetjs" title="ConvNetJS">ConvNetJS</a></li><li><a class="toc-href" href="#magenta" title="Magenta">Magenta</a></li><li><a class="toc-href" href="#google ai experiments" title="Google AI Experiments">Google AI Experiments</a></li><li><a class="toc-href" href="#quick draw" title="Quick Draw">Quick Draw</a></li><li><a class="toc-href" href="#teachable machine" title="Teachable Machine">Teachable Machine</a></li><li><a class="toc-href" href="#fast neural style" title="Fast Neural Style">Fast Neural Style</a></li><li><a class="toc-href" href="#tensorflow.js" title="TensorFlow.js">TensorFlow.js</a></li><li><a class="toc-href" href="#gan lab" title="GAN Lab">GAN Lab</a></li><li><a class="toc-href" href="#talk to transformer" title="Talk to Transformer">Talk to Transformer</a></li><li><a class="toc-href" href="#nvidia ai playground" title="NVIDIA AI PLAYGROUND">NVIDIA AI PLAYGROUND</a></li><li><a class="toc-href" href="#grover" title="Grover">Grover</a></li><li><a class="toc-href" href="#waifu vending machine" title="Waifu Vending Machine">Waifu Vending Machine</a></li><li><a class="toc-href" href="#this waifu does not exist" title="This Waifu Does Not Exist">This Waifu Does Not Exist</a></li><li><a class="toc-href" href="#ai notes" title="AI Notes">AI Notes</a></li><li><a class="toc-href" href="#anomagram" title="Anomagram">Anomagram</a></li></ul></li><li><a class="toc-href" href="#xian shang ke cheng_1" title="線上課程">線上課程</a><ul><li><a class="toc-href" href="#li hong yi jiao shou de ji qi xue xi  / shen du xue xi ke cheng" title="李宏毅教授的機器學習 / 深度學習課程">李宏毅教授的機器學習 / 深度學習課程</a></li><li><a class="toc-href" href="#deep learning specialization @ coursera" title="Deep Learning Specialization @ Coursera">Deep Learning Specialization @ Coursera</a></li><li><a class="toc-href" href="#practical deep learning for coders @ fast.ai" title="Practical Deep Learning For Coders @ fast.ai">Practical Deep Learning For Coders @ fast.ai</a></li><li><a class="toc-href" href="#deep learning @ kaggle learn" title="Deep Learning @ Kaggle Learn">Deep Learning @ Kaggle Learn</a></li><li><a class="toc-href" href="#elements of artificial intelligence" title="Elements of Artificial Intelligence">Elements of Artificial Intelligence</a></li><li><a class="toc-href" href="#mit deep learning" title="MIT Deep Learning">MIT Deep Learning</a></li><li><a class="toc-href" href="#mit 6.s191 introduction to deep learning" title="MIT 6.S191 Introduction to Deep Learning">MIT 6.S191 Introduction to Deep Learning</a></li><li><a class="toc-href" href="#ai for everyone" title="AI For Everyone">AI For Everyone</a></li><li><a class="toc-href" href="#cs224n: natural language processing with deep learning" title="CS224n: Natural Language Processing with Deep Learning">CS224n: Natural Language Processing with Deep Learning</a></li><li><a class="toc-href" href="#cs231n: convolutional neural networks for visual recognition" title="CS231n: Convolutional Neural Networks for Visual Recognition">CS231n: Convolutional Neural Networks for Visual Recognition</a></li></ul></li><li><a class="toc-href" href="#shi yong gong ju_1" title="實用工具">實用工具</a><ul><li><a class="toc-href" href="#colaboratory" title="Colaboratory">Colaboratory</a></li><li><a class="toc-href" href="#tensorboard" title="TensorBoard">TensorBoard</a></li><li><a class="toc-href" href="#embedding projector" title="Embedding Projector">Embedding Projector</a></li><li><a class="toc-href" href="#lucid" title="Lucid">Lucid</a></li><li><a class="toc-href" href="#papers with code" title="Papers with Code">Papers with Code</a></li><li><a class="toc-href" href="#what-if tool" title="What-If Tool">What-If Tool</a></li><li><a class="toc-href" href="#bertviz" title="BertViz">BertViz</a></li><li><a class="toc-href" href="#ml visuals" title="ML Visuals">ML Visuals</a></li></ul></li><li><a class="toc-href" href="#qi ta jiao cai_1" title="其他教材">其他教材</a><ul><li><a class="toc-href" href="#seedbank" title="Seedbank">Seedbank</a></li><li><a class="toc-href" href="#deep learning with python" title="Deep Learning with Python">Deep Learning with Python</a></li><li><a class="toc-href" href="#stanford cs230 cheatsheets" title="Stanford CS230 Cheatsheets">Stanford CS230 Cheatsheets</a></li><li><a class="toc-href" href="#practicalai" title="practicalAI">practicalAI</a></li><li><a class="toc-href" href="#allennlp demo" title="AllenNLP Demo">AllenNLP Demo</a></li><li><a class="toc-href" href="#hands-on machine learning 2" title="Hands-on Machine Learning 2">Hands-on Machine Learning 2</a></li></ul></li><li><a class="toc-href" href="#you zhi wen zhang_1" title="優質文章">優質文章</a></li><li><a class="toc-href" href="#jing dian lun wen" title="經典論文">經典論文</a><ul><li><a class="toc-href" href="#zi ran yu yan chu li  natural language processing (nlp)" title="自然語言處理 Natural Language Processing (NLP)">自然語言處理 Natural Language Processing (NLP)</a></li><li><a class="toc-href" href="#dian nao shi jue  computer vision (cv)" title="電腦視覺 Computer Vision (CV)">電腦視覺 Computer Vision (CV)</a><ul><li><a class="toc-href" href="#lei shen jing wang lu jia gou  neural network architecture" title="類神經網路架構 Neural Network Architecture">類神經網路架構 Neural Network Architecture</a></li><li><a class="toc-href" href="#zi liao ji  dataset" title="資料集 Dataset">資料集 Dataset</a></li><li><a class="toc-href" href="#wu ti zhen ce yu qie ge  object detection and segmentation" title="物體偵測與切割 Object Detection and Segmentation">物體偵測與切割 Object Detection and Segmentation</a></li><li><a class="toc-href" href="#sheng cheng mo xing  generative models" title="生成模型 Generative Models">生成模型 Generative Models</a></li></ul></li></ul></li><li><a class="toc-href" href="#qi ta zheng li_2" title="其他整理">其他整理</a><ul><li><a class="toc-href" href="#deep-learning-ocean" title="deep-learning-ocean">deep-learning-ocean</a></li></ul></li><li><a class="toc-href" href="#dai ban shi xiang_1" title="待辦事項">待辦事項</a></li><li><a class="toc-href" href="#ru he gong xian" title="如何貢獻">如何貢獻</a></li></ul></li></ul></div>
      </div>
    </div>

    <!--custom images with icon shown on left nav-->
    <!--the details are set in `pelicanconf.py` as `LEFT_NAV_IMAGES`-->

    <article class="blog-single">

        <!-- page header/blog hero, use custom cover image if available
        ================================================== -->
            <div class="page-header page-header--single page-hero" style="background-image:url(https://leemeng.tw/theme/images/background/joshua-newton-214848-unsplash.jpg)">

            <div class="row page-header__content narrow">
                <article class="col-full">
                    <div class="page-header__info">
                        <div class="page-header__cat">
                            <a href="https://leemeng.tw/tag/shen-du-xue-xi.html" rel="tag">深度學習</a>
                            <a href="https://leemeng.tw/tag/python.html" rel="tag">Python</a>
                            <a href="https://leemeng.tw/tag/keras.html" rel="tag">Keras</a>
                            <a href="https://leemeng.tw/tag/tensorflow.html" rel="tag">TensorFlow</a>
                        </div>
                    </div>
                    <h1 class="page-header__title">
                        <a href="https://leemeng.tw/deep-learning-resources.html" title="">
                            由淺入深的深度學習資源整理
                        </a>
                    </h1>
                    <ul class="page-header__meta">
                        <li class="date">2019-01-08 (Tue)</li>
                        <li class="page-view">
                            25,384 views
                        </li>
                    </ul>

                </article>
            </div>

        </div> <!-- end page-header -->

        <div class="KW_progressContainer">
            <div class="KW_progressBar"></div>
        </div>

        <div class="row blog-content" style="position: relative">
<div id="left-navigation">

    <div id="search-wrap">
        <i class="im im-magnifier" aria-hidden="true"></i>
        <div id="search">
            <form action="../search.html">
            <div class="tipue_search_right"><input type="text" name="q" id="tipue_search_input" pattern=".{2,}" title="想搜尋什麼呢？（請至少輸入兩個字）" required></div>
            </form>
        </div>
    </div>

    <div id="toc-wrap">
        <a title="顯示/隱藏 文章章節">
            <i class="im im-menu" aria-hidden="true" onclick="toggleTocNav()"></i>
        </a>
    </div>

    <div id="social-wrap" style="cursor: pointer">
        <a class="open-popup" title="訂閱最新文章">
            <i class="im im-newspaper-o" aria-hidden="true"></i>
        </a>
    </div>
    <div id="social-wrap">
        <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//leemeng.tw/deep-learning-resources.html" target="_blank" title="分享到 Facebook">
            <i class="im im-facebook" aria-hidden="true"></i>
        </a>
    </div>
    <div id="social-wrap">
        <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A//leemeng.tw/deep-learning-resources.html&title=%E7%94%B1%E6%B7%BA%E5%85%A5%E6%B7%B1%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E8%B3%87%E6%BA%90%E6%95%B4%E7%90%86&summary=%E9%80%99%E8%A3%A1%E7%B4%80%E9%8C%84%E4%BA%86%E6%88%91%E5%9C%A8%E5%AD%B8%E7%BF%92%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E6%99%82%E8%92%90%E9%9B%86%E7%9A%84%E4%B8%80%E4%BA%9B%E7%B7%9A%E4%B8%8A%E8%B3%87%E6%BA%90%E3%80%82%E5%85%A7%E5%AE%B9%E7%94%B1%E6%B7%BA%E5%85%A5%E6%B7%B1%EF%BC%8C%E8%80%8C%E4%B8%94%E6%9C%83%E4%B8%80%E7%9B%B4%E8%A2%AB%E6%9B%B4%E6%96%B0%EF%BC%8C%E5%B8%8C%E6%9C%9B%E8%83%BD%E5%B9%AB%E5%8A%A9%E4%BD%A0%E9%A0%86%E5%88%A9%E5%9C%B0%E9%96%8B%E5%A7%8B%E5%AD%B8%E7%BF%92%EF%BC%9A%EF%BC%89&source=https%3A//leemeng.tw/deep-learning-resources.html" target="_blank" title="分享到 LinkedIn">
            <i class="im im-linkedin" aria-hidden="true"></i>
        </a>
    </div>
    <div id="social-wrap">
        <a href="https://twitter.com/intent/tweet?text=%E7%94%B1%E6%B7%BA%E5%85%A5%E6%B7%B1%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E8%B3%87%E6%BA%90%E6%95%B4%E7%90%86&url=https%3A//leemeng.tw/deep-learning-resources.html&hashtags=shen-du-xue-xi,python,keras,tensorflow" target="_blank" title="分享到 Twitter">
            <i class="im im-twitter" aria-hidden="true"></i>
        </a>
    </div>


    <!--custom images with icon shown on left nav-->

</div>

            <div class="col-full blog-content__main">

                <style>
    h3 {
        margin-top: 3rem;
    }
    h3 a {
        font-size: 18px;
    }
</style>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3">
<blockquote>
<p>
                            不聞不若聞之，聞之不若見之，見之不若知之，知之不若行之，學至於行之而止矣。
                            <br/>
<span style="float:right">── 《荀子．儒效》<span>
</span></span></p>
</blockquote>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" style="margin-top: 8rem">
<p>
        這段話翻成白話文就是「沒聽過比不上聽過；聽過比不上實際看過；看過則比不上實際了解；而了解又不如動手實踐。唯有身體力行才能真正地學到東西。」
    </p>
<p>
        這句古老的諺語向我們傳達了「實踐」的重要以及學習的幾個過程。
    </p>
<p>
        做為一門學問，<a href="https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0" target="_blank">深度學習</a>也是同樣道理。
        僅說自己對深度學習有興趣或是有關注（聞、見），但卻沒有實際花時間去深入了解或實際應用（知、行）是無法真正學會深度學習的。
    </p>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<img src="/images/patrick-tomasso-71909-unsplash.jpg"/>
<br/>
</div>
</div>
<p>
        雖說如此，不了解深度學習能拿來做什麼的人或許還不少。
    </p>
<p>
        我嘗試將自己在學習過程中蒐集到的重要資源由淺入深地做些整理。
        希望透過此文，能讓在各個學習階段的你都能從這裡獲得些什麼，並實際動手學習、探索發展快速的深度學習世界。
    </p>
<p>
        本文內容會持續被更新，你可以定期回來看看或是關注這個 
        <a href="https://github.com/leemengtaiwan/deep-learning-resources" target="_blank">Github Repo</a>。
    </p>
</div>
<div align="center">
<img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/general/paper-ball.jpg"/>
</div>
<hr/>
<p>這裡紀錄了我在學習<a href="https://leemeng.tw/deep-learning-for-everyone-understand-neural-net-and-linear-algebra.html">深度學習</a>時蒐集的一些線上資源。內容由淺入深，而且會不斷更新，希望能幫助你順利地開始學習：）</p>
<h2 id="ben wen zhang jie">本文章節</h2>
<ul>
<li><a href="#playground">遊玩空間</a></li>
<li><a href="#courses">線上課程</a></li>
<li><a href="#tools">實用工具</a></li>
<li><a href="#tutorials">其他教材</a></li>
<li><a href="#blogs">優質文章</a></li>
<li><a href="#papers">經典論文</a></li>
<li><a href="#collections">其他整理</a></li>
</ul>
<h2 id="you wan kong jian"><div id="playground">遊玩空間</div></h2>
<p>這節列舉了一些透過瀏覽器就能馬上開始遊玩 / 體驗深度學習的應用。作為這些應用的使用者，你可以先高層次、直觀地了解深度學習能做些什麼。之後有興趣再進一步了解背後原理。</p>
<p>這小節最適合：</p>
<ul>
<li>想要快速體會深度學習如何被應用在真實世界的好奇寶寶</li>
<li>想要直觀理解<a href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">類神經網路（Artifical Neural Network）</a>運作方式的人</li>
<li>想從別人的深度學習應用取得一些靈感的開發者</li>
</ul>
<table>
<thead>
<tr>
<th align="center"><a href="https://playground.tensorflow.org/">Deep Playground</a></th>
<th align="center"><a href="https://cs.stanford.edu/people/karpathy/convnetjs/index.html">ConvNetJS</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://playground.tensorflow.org/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/deep-playground.jpg"/></a></td>
<td align="center"><a href="https://cs.stanford.edu/people/karpathy/convnetjs/index.html"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/convnetjs.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="deep playground"><a href="https://playground.tensorflow.org/">Deep Playground</a></h3>
<ul>
<li>由 <a href="https://github.com/tensorflow/playground">Tensorflow 團隊</a>推出，模擬訓練一個類神經網路的過程並了解其運作原理</li>
<li>可以搭配這篇 <a href="https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks/playground-exercises">Introduction to Neural Networks: Playground Exercises</a> 學習</li>
</ul>
<h3 id="convnetjs"><a href="https://cs.stanford.edu/people/karpathy/convnetjs/">ConvNetJS</a></h3>
<ul>
<li>訓練類神經網路來解決經典的 <a href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html">MNIST 手寫數字辨識問題</a>、<a href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/image_regression.html">圖片生成</a>以及<a href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html">增強式學習</a></li>
<li>由 Tesla 的 AI 負責人 <a href="https://cs.stanford.edu/people/karpathy/">Andrej Karpathy</a> 建立</li>
</ul>
<hr/>
<table>
<thead>
<tr>
<th align="center"><a href="https://magenta.tensorflow.org/">Magenta</a></th>
<th align="center"><a href="https://experiments.withgoogle.com/collection/ai">Google AI Experiments</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://magenta.tensorflow.org/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/magenta.jpg"/></a></td>
<td align="center"><a href="https://experiments.withgoogle.com/collection/ai"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/google-ai-experiment.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="magenta"><a href="https://magenta.tensorflow.org/">Magenta</a></h3>
<ul>
<li>一個利用<a href="https://zh.wikipedia.org/zh-hant/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">機器學習</a>來協助人們進行音樂以及藝術創作的開源專案</li>
<li>可以在網站上的 <a href="https://magenta.tensorflow.org/demos">Demo 頁面</a>嘗試各種由深度學習驅動的音樂 / 繪畫應用（如彈奏鋼琴、擊鼓）</li>
</ul>
<h3 id="google ai experiments"><a href="https://experiments.withgoogle.com/collection/ai">Google AI Experiments</a></h3>
<ul>
<li>這邊展示了接近 40 個利用圖片、語言以及音樂來與使用者產生互動的機器學習 Apps，值得慢慢探索</li>
<li>知名例子有 <a href="https://quickdraw.withgoogle.com/">Quick Draw</a> 以及 <a href="https://teachablemachine.withgoogle.com/">Teachable Machine</a>，將在下方介紹</li>
</ul>
<hr/>
<table>
<thead>
<tr>
<th align="center"><a href="https://quickdraw.withgoogle.com/">Quick Draw</a></th>
<th align="center"><a href="https://teachablemachine.withgoogle.com/">Teachable Machine</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://quickdraw.withgoogle.com/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/quickdraw.jpg"/></a></td>
<td align="center"><a href="https://teachablemachine.withgoogle.com/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/teachable-machine.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="quick draw"><a href="https://quickdraw.withgoogle.com/">Quick Draw</a></h3>
<ul>
<li>由 Google 推出的知名手寫塗鴉辨識，使用的神經網路架構有常見的<a href="https://zh.wikipedia.org/wiki/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">卷積神經網路 CNN </a>以及<a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E6%9C%89%E8%A8%98%E6%86%B6%E7%9A%84%E5%BE%AA%E7%92%B0%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF_1">循環神經網路 RNN</a></li>
<li>該深度學習模型會不斷將最新的筆觸當作輸入來預測使用者想畫的物件。你會驚嘆於她精準且即時的判斷</li>
</ul>
<h3 id="teachable machine"><a href="https://teachablemachine.withgoogle.com/">Teachable Machine</a></h3>
<ul>
<li>利用電腦 / 手機上的相機來訓練能將影像對應到其他圖片、音訊的神經網路，饒富趣味</li>
<li>透過這例子，你將暸解機器學習的神奇之處以及其侷限所在</li>
</ul>
<hr/>
<table>
<thead>
<tr>
<th align="center"><a href="https://tenso.rs/demos/fast-neural-style/">Fast Neural Style</a></th>
<th align="center"><a href="https://js.tensorflow.org/">TensorFlow.js</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://tenso.rs/demos/fast-neural-style/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/fast-neural-style.jpg"/></a></td>
<td align="center"><a href="https://js.tensorflow.org/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/human-pose-estimation.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="fast neural style"><a href="https://tenso.rs/demos/fast-neural-style/">Fast Neural Style</a></h3>
<ul>
<li>展示如何使用 WebGL 在瀏覽器快速地進行<a href="https://medium.com/tensorflow/neural-style-transfer-creating-art-with-deep-learning-using-tf-keras-and-eager-execution-7d541ac31398">神經風格轉換 Neural Style Transfer</a></li>
<li>你可以選擇任何一張圖片，並在此網站上將其畫風轉變成指定的藝術照</li>
<li><a href="https://deepart.io/">Deepart.io</a> 也提供類似服務</li>
</ul>
<h3 id="tensorflow.js"><a href="https://js.tensorflow.org/">TensorFlow.js</a></h3>
<ul>
<li>TensorFlow.js 頁面有多個利用 JavaScript 實現的深度學習應用，如上圖中的<a href="https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5">人類姿勢估計 Human Pose Estimation</a>。</li>
<li>你可以在該應用裡頭打開自己的攝影機，看該應用能不能偵測到你與朋友的姿勢。</li>
</ul>
<hr/>
<table>
<thead>
<tr>
<th align="center"><a href="https://poloclub.github.io/ganlab/">GAN Lab</a></th>
<th align="center"><a href="https://talktotransformer.com/">Talk to Transformer</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://poloclub.github.io/ganlab/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/gan-lab.jpg"/></a></td>
<td align="center"><a href="https://talktotransformer.com/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/talk_to_transformer.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="gan lab"><a href="https://poloclub.github.io/ganlab/">GAN Lab</a></h3>
<ul>
<li><a href="https://zh.wikipedia.org/wiki/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C">對抗生成網路（<strong>G</strong>enerative <strong>A</strong>dversarial <strong>N</strong>etwork，簡稱GAN）</a>是非監督式學習的一種方法，通過讓兩個神經網路相互博弈的方式進行學習。此網站以 <a href="https://js.tensorflow.org/">TensorFlow.js</a> 實作 GAN 中兩個神經網路的學習過程，幫助有興趣的你更直觀地理解神奇的 GAN 的運作方式</li>
</ul>
<h3 id="talk to transformer"><a href="https://talktotransformer.com/">Talk to Transformer</a></h3>
<ul>
<li>展示了一個由 OpenAI 推出，名為 <a href="https://openai.com/blog/better-language-models/">GPT-2 的無監督式語言模型</a>。該模型以 Google 發表的神經網路架構 <a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">Transformer</a> 為基底，在給定一段魔戒或是復仇者聯盟的文字內容，該模型可以自己生成唯妙唯俏的延伸劇情。你也可以嘗試 <a href="https://gpt2.apps.allenai.org/?text=Joel%20is">AllenAI GPT-2 Explorer</a> 來觀察 GPT-2 預測下個字的機率。</li>
<li>想要深入了解 Transformer 或 GPT-2，推薦閱讀：</li>
<li><a href="https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html">淺談神經機器翻譯 &amp; 用 Transformer 與 TensorFlow 2 英翻中</a></li>
<li><a href="https://leemeng.tw/gpt2-language-model-generate-chinese-jing-yong-novels.html">直觀理解 GPT-2 語言模型並生成金庸武俠小說</a></li>
<li><a href="https://jalammar.github.io/illustrated-gpt2/">The Illustrated GPT-2 (Visualizing Transformer Language Models)</a></li>
</ul>
<hr/>
<table>
<thead>
<tr>
<th align="center"><a href="https://www.nvidia.com/en-us/research/ai-playground/">NVIDIA AI PLAYGROUND</a></th>
<th align="center"><a href="https://grover.allenai.org/">Grover</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://www.nvidia.com/en-us/research/ai-playground/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/nvidia-ai-playground.jpg"/></a></td>
<td align="center"><a href="https://grover.allenai.org/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/grover.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="nvidia ai playground"><a href="https://www.nvidia.com/en-us/research/ai-playground/">NVIDIA AI PLAYGROUND</a></h3>
<ul>
<li>提供 <a href="https://arxiv.org/abs/1903.07291">GauGAN</a> 的線上展示，讓你可以利用簡單的筆觸來生成真實世界的風景圖片，也能上傳自己的圖片做風格轉換</li>
<li>提供 <a href="https://arxiv.org/abs/1804.07723">Image Impainting</a> 服務，讓使用者自由抹去部分圖片並讓 AI 自動生成被抹去的區塊</li>
</ul>
<h3 id="grover"><a href="https://grover.allenai.org/">Grover</a></h3>
<ul>
<li>一個偵測 / 生成神經假新聞（Neural Fake News）的研究，其網頁展示如何自動生成假新聞。</li>
</ul>
<hr/>
<table>
<thead>
<tr>
<th align="center"><a href="https://waifulabs.com">Waifu Vending Machine</a></th>
<th align="center"><a href="https://www.thiswaifudoesnotexist.net/">This Waifu Does Not Exist</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://waifulabs.com"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/waifulabs.jpg"/></a></td>
<td align="center"><a href="https://www.thiswaifudoesnotexist.net/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/thiswaifudoesnotexist.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="waifu vending machine"><a href="https://waifulabs.com">Waifu Vending Machine</a></h3>
<ul>
<li>Waifu 來自日文 ワイフ，指的是一些非常受到歡迎、且被不少玩家/觀眾視為妻子的動漫女性角色。<a href="https://twitter.com/SizigiStudios">Sizigi Studios</a> 團隊利用 GAN 隨機初始 16 名虛擬動漫角色，讓使用者可以進一步依照喜愛來創造專屬於自己的 Waifu。</li>
<li>Waifu Vending Machine 產生的 Waifu 品質很高，使用者可以下載並分享自己創造的 Waifu，也可以選擇購買印製該 Waifu 的海報與抱枕。</li>
</ul>
<h3 id="this waifu does not exist"><a href="https://www.thiswaifudoesnotexist.net/">This Waifu Does Not Exist</a></h3>
<ul>
<li>以 Nvidia 的 <a href="https://github.com/NVlabs/stylegan">StyleGAN</a> 隨機生成的 Waifu（右圖左側）。作者 <a href="https://www.gwern.net/">Gwern</a> 同時也使用<a href="https://blog.openai.com/better-language-models/">開源的小型 GPT-2</a> 隨機生成一段動漫劇情（右圖右側）。自釋出後已超越一百萬使用者拜訪該網站。</li>
<li>你也可以用大螢幕查看作者的另個相關網站：<a href="https://www.obormot.net/demos/these-waifus-do-not-exist">These Waifus Do Not Exist</a>，用全畫面一次「觀賞」數十名隨機生成的 Waifus。</li>
</ul>
<hr/>
<table>
<thead>
<tr>
<th align="center"><a href="http://www.deeplearning.ai/ai-notes/">AI Notes</a></th>
<th align="center"><a href="https://anomagram.fastforwardlabs.com/#/">Anomagram</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="http://www.deeplearning.ai/ai-notes/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/deeplearning-ai-notes.jpg"/></a></td>
<td align="center"><a href="https://anomagram.fastforwardlabs.com/#/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/anomagram.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="ai notes"><a href="http://www.deeplearning.ai/ai-notes/">AI Notes</a></h3>
<ul>
<li>AI Notes 是 <a href="#deep-learning-specialization--coursera">吳恩達的 Deep Learning 專項課程</a>的輔助教材，使用數學證明以及由 TensorFlow.js 建立的線上 demo 讓你可以直觀地學習<a href="http://www.deeplearning.ai/ai-notes/initialization/">如何初始化神經網路權重</a>及<a href="http://www.deeplearning.ai/ai-notes/optimization/">如何最佳化模型權重</a> </li>
<li>縮圖為 <a href="http://www.deeplearning.ai/ai-notes/optimization/">Parameter optimization in neural networks</a> 單元中使用不同 Optimiziers 訓練模型的線上 demo</li>
</ul>
<h3 id="anomagram"><a href="https://anomagram.fastforwardlabs.com/#/">Anomagram</a></h3>
<ul>
<li>Anomagram 是一個以 Tensorflow.js 實作，可以建立、訓練並測試能夠用來做異常檢測的 Autoencoder。</li>
</ul>
<h2 id="xian shang ke cheng_1"><div id="courses">線上課程</div></h2>
<p>看完<a href="#playground">遊玩空間</a>的大量實際應用，相信你已經迫不及待地想要開始學習強大的深度學習技術了。</p>
<p>這節列舉了一些有用的線上課程以及學習教材，幫助你掌握深度學習的基本知識（沒有特別註明的話皆為免費存取）。</p>
<p>另外值得一提的是，大部分課程都要求一定程度的 <a href="https://www.python.org/">Python</a> 程式能力。</p>
<table>
<thead>
<tr>
<th align="center"><a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html">李宏毅教授的機器學習 / 深度學習課程</a></th>
<th align="center"><a href="https://www.coursera.org/specializations/deep-learning">Deep Learning Specialization @ Coursera</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS18.html"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/Hung-Yi-Lee-ml-courses.jpg"/></a></td>
<td align="center"><a href="https://www.coursera.org/specializations/deep-learning"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/deep-learning-specification-coursera.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="li hong yi jiao shou de ji qi xue xi  / shen du xue xi ke cheng"><a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html">李宏毅教授的機器學習 / 深度學習課程</a></h3>
<ul>
<li>大概是全世界最好、最完整的深度學習<b>中文</b>學習資源，且作業皆提供 Colab 筆記本範例。</li>
<li>影片內容涵蓋基本理論（約 10 小時觀看時間）一直到進階的<a href="https://zh.wikipedia.org/wiki/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C">生成對抗網路 GAN</a> 以及<a href="https://zh.wikipedia.org/wiki/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0">強化學習 RL</a>。</li>
<li>想學語音辨識或是自然語言處理則可參考教授的<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_DLHLP20.html">用深度學習處理人類語言</a>。</li>
<li><a href="https://github.com/datawhalechina/leeml-notes">李宏毅机器学习笔记(LeeML-Notes，簡體)</a> 則將教授上課的影片內容轉為筆記，方便瀏覽課程內容。</li>
</ul>
<h3 id="deep learning specialization @ coursera"><a href="https://www.coursera.org/specializations/deep-learning">Deep Learning Specialization @ Coursera</a></h3>
<ul>
<li>原 Google Brain 的<a href="https://zh.wikipedia.org/wiki/%E5%90%B4%E6%81%A9%E8%BE%BE">吳恩達</a>教授開授的整個深度學習專項課程共分五堂課，從<a href="https://www.coursera.org/learn/neural-networks-deep-learning?specialization=deep-learning">神經網路的基礎</a>到能夠進行機器翻譯、語音辨識的<a href="https://www.coursera.org/learn/nlp-sequence-models">序列模型</a>，每堂課預計 1 個月完成，收費採訂閱制</li>
<li>程式作業會交互使用 <a href="http://www.numpy.org/">Numpy</a>、<a href="https://keras.io/">Keras</a> 以及 <a href="https://www.tensorflow.org/">TensorFlow</a> 來實作深度學習模型</li>
</ul>
<hr/>
<table>
<thead>
<tr>
<th align="center"><a href="https://course.fast.ai/index.html">Practical Deep Learning For Coders @ fast.ai</a></th>
<th align="center"><a href="https://www.kaggle.com/learn/deep-learning">Deep Learning @ Kaggle Learn</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://course.fast.ai/index.html"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/fast-ai.jpg"/></a></td>
<td align="center"><a href="https://www.kaggle.com/learn/deep-learning"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/kaggle-learn-dl.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="practical deep learning for coders @ fast.ai"><a href="https://course.fast.ai/index.html">Practical Deep Learning For Coders @ fast.ai</a></h3>
<ul>
<li>7 週課程，一週約需安排 10 小時上課。該課程由<a href="https://www.kaggle.com/jhoward">傑里米&middot;霍華德</a>來講解深度學習，其在知名數據建模和數據分析競賽平台 <a href="https://www.kaggle.com/">Kaggle</a> 維持兩年的世界第一</li>
</ul>
<h3 id="deep learning @ kaggle learn"><a href="https://www.kaggle.com/learn/deep-learning">Deep Learning @ Kaggle Learn</a></h3>
<ul>
<li>14 堂課程，主要使用 TensorFlow 實作深度學習模型</li>
<li>內容主要專注在<a href="https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89">電腦視覺（Computer Vision）</a>以及如何應用<a href="https://en.wikipedia.org/wiki/Transfer_learning">遷移學習（Transfer Learning）</a></li>
</ul>
<hr/>
<table>
<thead>
<tr>
<th align="center"><a href="https://www.elementsofai.com/">Elements of Artificial Intelligence</a></th>
<th align="center"><a href="https://deeplearning.mit.edu/">MIT Deep Learning</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://www.elementsofai.com/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/elementsofai.jpg"/></a></td>
<td align="center"><a href="https://selfdrivingcars.mit.edu/deeptraffic"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/mlt-deep-learning.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="elements of artificial intelligence"><a href="https://www.elementsofai.com/">Elements of Artificial Intelligence</a></h3>
<ul>
<li>芬蘭最高學府<a href="https://zh.wikipedia.org/wiki/%E8%B5%AB%E5%B0%94%E8%BE%9B%E5%9F%BA%E5%A4%A7%E5%AD%A6">赫爾辛基大學</a>推出的 AI 課程。此課程目的在於讓所有人都能了解 AI，不需要任何程式經驗。這堂課非常適合完全沒有接觸過深度學習或是相關領域的人</li>
<li>課程分 6 個部分，包含「何謂 AI ？」、「真實世界的 AI」、「機器學習」以及「神經網路」等章節</li>
</ul>
<h3 id="mit deep learning"><a href="https://deeplearning.mit.edu/">MIT Deep Learning</a></h3>
<ul>
<li>麻省理工學院推出的深度學習課程，內容包含深度學習基礎、深度強化學習以及自動駕駛相關知識。<a href="https://github.com/lexfridman/mit-deep-learning">Github Repo</a> 包含了多個教學筆記本，值得參考。</li>
<li>上圖是 <a href="https://selfdrivingcars.mit.edu/deeptraffic/">DeepTraffic</a>，由 MIT 的研究科學家 <a href="https://lexfridman.com/">Lex Fridman</a> 推出的一個深度強化學習競賽。此競賽目標是建立一個可以在高速公路上駕駛汽車的神經網路。你可以在<a href="https://selfdrivingcars.mit.edu/deeptraffic/">這裡</a>看到線上 Demo 以及詳細說明。</li>
</ul>
<hr/>
<table>
<thead>
<tr>
<th align="center"><a href="http://introtodeeplearning.com">6.S191: Introduction to Deep Learning</a></th>
<th align="center"><a href="https://www.coursera.org/learn/ai-for-everyone">AI For Everyone</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="http://introtodeeplearning.com"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/intro-to-deeplearning-mit.jpg"/></a></td>
<td align="center"><a href="https://www.coursera.org/learn/ai-for-everyone"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/ai-for-everyone.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="mit 6.s191 introduction to deep learning"><a href="http://introtodeeplearning.com/">MIT 6.S191 Introduction to Deep Learning</a></h3>
<ul>
<li>麻省理工學院推出的另一堂基礎深度學習課程，介紹深度學習以及其應用。內容涵蓋機器翻譯、圖像辨識以及更多其他應用。此課程使用 Python 以及 TensorFlow 來實作作業，並預期學生具備基礎的微積分（梯度下降、鏈鎖律）以及線性代數（矩陣相乘）。</li>
</ul>
<h3 id="ai for everyone"><a href="https://www.coursera.org/learn/ai-for-everyone">AI For Everyone</a></h3>
<ul>
<li>Coursera 課程。<a href="https://zh.wikipedia.org/wiki/%E5%90%B4%E6%81%A9%E8%BE%BE">吳恩達</a>教授在這堂簡短的課程裡頭，針對非技術人士以及企業經理人說明何謂 AI、如何建立 AI 專案以及闡述 AI 與社會的關係。此課程十分適合沒有技術背景的讀者。<a href="https://leemeng.tw/10-key-takeaways-from-ai-for-everyone-course.html">從 AI For Everyone 學到的 10 個重要 AI 概念</a>則是我個人上完課後整理的心得分享。</li>
</ul>
<hr/>
<table>
<thead>
<tr>
<th align="center"><a href="http://web.stanford.edu/class/cs224n/">CS224n: Natural Language Processing with Deep Learning</a></th>
<th align="center"><a href="http://cs231n.stanford.edu/">CS231n: Convolutional Neural Networks for Visual Recognition</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href=""><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/cs224n.jpg"/></a></td>
<td align="center"><a href=""><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/cs231n.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="cs224n: natural language processing with deep learning"><a href="http://web.stanford.edu/class/cs224n/">CS224n: Natural Language Processing with Deep Learning</a></h3>
<ul>
<li>由<a href="http://technews.tw/2018/11/21/stanford-ai-lab-christopher-manning/">史丹佛 AI 實驗室的 Christopher Manning 教授</a>從語言學、計算機科學的角度講述自然語言處理的所有必要知識，是想要打好 NLP 基礎的人不可不學的一堂課。課程約有 20 部影片，每部約長 1.5 小時。</li>
</ul>
<h3 id="cs231n: convolutional neural networks for visual recognition"><a href="http://cs231n.stanford.edu/">CS231n: Convolutional Neural Networks for Visual Recognition</a></h3>
<ul>
<li>由<a href="http://vision.stanford.edu/index.html">史丹佛 Vision Lab 的李飛飛（Fei-Fei Li）教授</a>等人以<a href="http://cs231n.stanford.edu/slides/2019/cs231n_2019_lecture02.pdf">圖像分類</a>任務為軸心，講述卷積神經網路以及所有電腦視覺的相關基礎知識。這是想要學會使用（卷積）神經網路來處理圖像數據的人不可不學的一堂課。<a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv">Youtube 上有 16 部 2017 年的課程錄影</a>，每部約長 1 小時。</li>
<li>課程中也包含了不少線上展示，如<a href="http://vision.stanford.edu/teaching/cs231n-demos/linear-classify/">線性分類器的 loss 視覺化</a>、<a href="http://vision.stanford.edu/teaching/cs231n-demos/knn/">kNN demo</a> 以及圖像分類的 <a href="http://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html">CIFAR-10 demo</a>。</li>
</ul>
<h2 id="shi yong gong ju_1"><div id="tools">實用工具</div></h2>
<p>這節列出一些在你的深度學習路上可以幫得上些忙的工具。</p>
<table>
<thead>
<tr>
<th align="center"><a href="https://colab.research.google.com/notebooks/welcome.ipynb">Colaboratory</a></th>
<th align="center"><a href="https://www.tensorflow.org/guide/summaries_and_tensorboard">TensorBoard</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://colab.research.google.com/notebooks/welcome.ipynb"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/colab.jpg"/></a></td>
<td align="center"><a href="https://www.tensorflow.org/guide/summaries_and_tensorboard"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/tensorboard.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="colaboratory"><a href="https://colab.research.google.com/notebooks/welcome.ipynb">Colaboratory</a></h3>
<ul>
<li>由 Google 提供的雲端 <a href="https://jupyter.org/">Jupyter</a> 筆記本環境，讓你只要用瀏覽器就能馬上開始訓練深度學習模型。你甚至還可以使用一個免費的 <a href="https://www.nvidia.com/en-gb/data-center/tesla-k80/">Tesla K80</a> GPU 或 <a href="https://colab.research.google.com/notebooks/tpu.ipynb">TPU</a> 來加速訓練自己的模型</li>
<li>該計算環境也能與自己的 <a href="https://colab.research.google.com/notebooks/io.ipynb">Google Drive</a> 做連結，讓運算雲端化的同時將筆記本 / 模型結果都同步到自己的筆電上</li>
</ul>
<h3 id="tensorboard"><a href="https://www.tensorflow.org/guide/summaries_and_tensorboard">TensorBoard</a></h3>
<ul>
<li>TensorBoard 是一個視覺化工具，方便我們了解、除錯並最佳化自己訓練的深度學習模型</li>
<li>除了 TensorFlow 以外，其他基於 Python 的機器學習框架大多也可以透過 <a href="https://github.com/lanpa/tensorboardX">tensorboardX</a> 來使用 TensorBoard</li>
</ul>
<hr/>
<table>
<thead>
<tr>
<th align="center"><a href="https://projector.tensorflow.org/">Embedding Projector</a></th>
<th align="center"><a href="https://github.com/tensorflow/lucid">Lucid</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://projector.tensorflow.org/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/embedding-projector.jpg"/></a></td>
<td align="center"><a href="https://github.com/tensorflow/lucid"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/lucid.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="embedding projector"><a href="https://projector.tensorflow.org/">Embedding Projector</a></h3>
<ul>
<li>我們時常需要將圖片、文字轉成<a href="https://en.wikipedia.org/wiki/Tensor">高維數字向量 Embedding</a> 以供神經網路處理，而 Projector 能將此高維向量投影到 2、3 維空間上方便我們理解這些數據</li>
<li>Projector 網站讓你在線上探索幾個常見的資料集，但事實上你也可以<a href="https://www.tensorflow.org/guide/embedding">利用 Tensorboard 來視覺化自己的數據</a>。</li>
</ul>
<h3 id="lucid"><a href="https://github.com/tensorflow/lucid">Lucid</a></h3>
<ul>
<li>Lucid 是一個嘗試讓神經網路變得更容易解釋的開源專案，裡頭包含了很多視覺化神經網路的筆記本</li>
<li>你可以直接在 Colab 上執行這些筆記本並了解如何視覺化神經網路</li>
</ul>
<hr/>
<table>
<thead>
<tr>
<th align="center"><a href="https://paperswithcode.com/">Papers with Code</a></th>
<th align="center"><a href="https://pair-code.github.io/what-if-tool/">What-If Tool</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://paperswithcode.com/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/papers-with-code.jpg"/></a></td>
<td align="center"><a href="https://pair-code.github.io/what-if-tool/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/what-if-tool.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="papers with code"><a href="https://paperswithcode.com/">Papers with Code</a></h3>
<ul>
<li>將機器學習的學術論文、程式碼實作以及 SOTA 的評價排行榜全部整理匯總在一起的網站，非常適合想要持續追蹤學術及業界最新研究趨勢的人</li>
<li>在這邊可以瀏覽包含電腦視覺、自然語言處理等各大領域在不同任務上表現最好的論文、實作以及資料集</li>
</ul>
<h3 id="what-if tool"><a href="https://pair-code.github.io/what-if-tool/">What-If Tool</a></h3>
<ul>
<li>一個與 <a href="#tensorboard">TensorBoard</a> 以及 Jupyter Notebook 整合的探索工具，讓使用者不需寫程式碼就能輕鬆觀察機器學習模型的內部運作以及嘗試各種 What-if 問題（如果 ~ 會怎麼樣？）</li>
<li>基本上就是用來觀察<strong>已訓練</strong>的模型在測試資料集上的表現。利用此工具，使用者可以了解（不僅限於）以下的問題：模型在各類別數據上的表現有無差距？模型是否存在偏見？應該如何調整 Native / Positive False 的比例？</li>
<li>此工具的一大亮點在於讓非專業領域人士也能探索、理解 ML 模型表現。且只要給定模型與資料集, 就不需要每次為了 What-if 問題就寫用過即丟的程式碼</li>
</ul>
<hr/>
<table>
<thead>
<tr>
<th align="center"><a href="https://github.com/jessevig/bertviz">BertViz</a></th>
<th align="center"><a href="https://github.com/dair-ai/ml-visuals">ML Visuals</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://github.com/jessevig/bertviz"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/bertviz.jpg"/></a></td>
<td align="center"><a href="https://github.com/dair-ai/ml-visuals"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/ml-visuals.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="bertviz"><a href="https://github.com/jessevig/bertviz">BertViz</a></h3>
<ul>
<li>BertViz 是一個視覺化自注意力機制的工具，可以用來理解如 <a href="https://arxiv.org/abs/1810.04805">BERT</a>、<a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">GPT-2</a> 及 <a href="https://arxiv.org/abs/1907.11692">RoBERTa</a> 等知名 NLP 模型的內部運作</li>
<li>以下則是幾篇透過 BertViz 來直觀解說 BERT 與 GPT-2 的文章</li>
<li><a href="https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html">進擊的 BERT：NLP 界的巨人之力與遷移學習</a></li>
<li><a href="https://leemeng.tw/gpt2-language-model-generate-chinese-jing-yong-novels.html">直觀理解 GPT-2 語言模型並生成金庸武俠小說</a></li>
</ul>
<h3 id="ml visuals"><a href="https://github.com/dair-ai/ml-visuals">ML Visuals</a></h3>
<ul>
<li>ML Visuals 是一個社群開源項目，提供超過 100 個常見的機器學習概念 / 深度學習架構圖，可讓任何人在學術論文或是文章直接使用這些圖表。</li>
<li>所有圖表都可以直接從 <a href="https://docs.google.com/presentation/d/11mR1nkIR9fbHegFkcFq8z9oDQ5sjv8E3JJp1LfLGKuk/edit?usp=sharing">Google slide</a> 上觀看並使用。建議前往 <a href="https://github.com/dair-ai/ml-visuals">Github repo</a> 查看最新版本。</li>
</ul>
<h2 id="qi ta jiao cai_1"><div id="tutorials">其他教材</div></h2>
<p>除了<a href="#courses">線上課程</a>以外，網路上還有無數的學習資源。</p>
<p>這邊列出一些推薦的深度學習教材，大多數皆以數據科學家常用的 <a href="https://jupyter.org/">Jupyter</a> 筆記本的方式呈現。</p>
<p>你可以將感興趣的筆記本導入<a href="#tools">實用工具</a>裡提到的 <a href="https://colab.research.google.com/notebooks/welcome.ipynb">Colaboratory（Colab）</a>，馬上開始學習。</p>
<table>
<thead>
<tr>
<th align="center"><a href="https://research.google.com/seedbank/">Seedbank</a></th>
<th align="center"><a href="https://github.com/fchollet/deep-learning-with-python-notebooks">Deep Learning with Python</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://research.google.com/seedbank/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tutorials/seedbank.jpg"/></a></td>
<td align="center"><a href="https://github.com/fchollet/deep-learning-with-python-notebooks"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tutorials/fchollet-deep-learning-with-python.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="seedbank"><a href="https://research.google.com/seedbank/">Seedbank</a></h3>
<ul>
<li>讓你可以一覽 Colab 上超過 100 個跟機器學習相關的筆記本，並以此為基礎建立各種深度學習應用</li>
<li>熱門筆記本包含<a href="https://research.google.com/seedbank/seed/5695159920492544">神經機器翻譯</a>、<a href="https://research.google.com/seedbank/seed/5681034041491456">音樂生成</a>以及 <a href="https://research.google.com/seedbank/seed/5631986051842048">DeepDream</a></li>
<li>因為是 Google 服務，筆記本大多使用 TensorFlow 與 Keras 來實現模型</li>
</ul>
<h3 id="deep learning with python"><a href="https://github.com/fchollet/deep-learning-with-python-notebooks">Deep Learning with Python</a></h3>
<ul>
<li><a href="https://keras.io/">Keras</a> 作者 <a href="https://ai.google/research/people/105096">Fran&ccedil;ois Chollet</a> 在 <a href="https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438">Deep Learning with Python</a> 一書中用到的所有筆記本。每個筆記本裡頭都清楚地介紹該如何使用 Keras 來實現各種深度學習模型，十分適合第一次使用 Python 實現深度學習的讀者 </li>
<li><a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#top">進入 NLP 世界的最佳橋樑：寫給所有人的自然語言處理與深度學習入門指南</a>一文的 Keras 程式碼大多基於此</li>
<li>繁體中文的翻譯書籍則為 <a href="https://www.tenlong.com.tw/products/9789863125501?list_name=i-r-zh_tw">Deep learning 深度學習必讀 - Keras 大神帶你用 Python 實作</a></li>
<li>Keras 在 TensorFlow 2.0 中<a href="https://medium.com/tensorflow/standardizing-on-keras-guidance-on-high-level-apis-in-tensorflow-2-0-bad2b04c819a">為其最重要的高層次 API</a></li>
</ul>
<hr/>
<table>
<thead>
<tr>
<th align="center"><a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks">Stanford CS230 Cheatsheets</a></th>
<th align="center"><a href="https://github.com/madewithml/practicalAI">practicalAI</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tutorials/cs230-deep-learning-cheatsheet.jpg"/></a></td>
<td align="center"><a href="https://github.com/GokuMohandas/practicalAI"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tutorials/practical-ai-pytorch.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="stanford cs230 cheatsheets"><a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks">Stanford CS230 Cheatsheets</a></h3>
<ul>
<li>史丹佛大學的<a href="http://cs230.stanford.edu/">深度學習課程 CS230</a> 釋出的深度學習小抄總結了目前最新的<a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks">卷積神經網路</a>及<a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks">循環神經網路</a>知識，還包含了<a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks">訓練深度學習時需要使用到的技巧</a>，十分強大</li>
<li>此小抄最適合已經熟悉基礎知識的同學隨時複習運用。你也可以從他們的 <a href="https://github.com/afshinea/stanford-cs-230-deep-learning">Github Repo</a> 下載包含上述所有內容的<a href="https://github.com/afshinea/stanford-cs-230-deep-learning/blob/master/en/super-cheatsheet-deep-learning.pdf">超級 VIP 小抄</a></li>
<li>除了深度學習以外，你也可以查看 <a href="https://stanford.edu/~shervine/teaching/cs-229.html">CS229 機器學習課程的小抄</a></li>
</ul>
<h3 id="practicalai"><a href="https://github.com/madewithml/practicalAI">practicalAI</a></h3>
<ul>
<li>在 Github 上超過 1 萬星的 Repo。除了深度學習，也有介紹 <a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/basic_ml/01_Python.ipynb">Python 基礎</a>及 <a href="https://colab.research.google.com/github/practicalAI/practicalAI/blob/master/notebooks/basic_ml/03_Pandas.ipynb">Pandas</a> 的使用方式</li>
<li>使用 <a href="https://pytorch.org/">PyTorch</a> 框架來實現深度學習模型，且所有內容都是 Jupyter 筆記本，可以讓你在 Colab 或本地端執行</li>
</ul>
<hr/>
<table>
<thead>
<tr>
<th align="center"><a href="http://demo.allennlp.org/">AllenNLP Demo</a></th>
<th align="center"><a href="https://github.com/ageron/handson-ml2">Hands-on Machine Learning 2</a></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="http://demo.allennlp.org/"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/allennlp-demo.jpg"/></a></td>
<td align="center"><a href="https://github.com/ageron/handson-ml2"><img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tutorials/handson-ml2.jpg"/></a></td>
</tr>
</tbody>
</table>
<h3 id="allennlp demo"><a href="http://demo.allennlp.org/">AllenNLP Demo</a></h3>
<ul>
<li>清楚地展示了如<a href="https://demo.allennlp.org/machine-comprehension">機器理解</a>、<a href="https://demo.allennlp.org/named-entity-recognition">命名實體識別</a>等多個自然語言處理任務的情境。每個任務的情境包含了任務所需要的輸入、SOTA 模型的預測結果以及模型內部的注意力機制，對理解一個 NLP 任務的實際應用情境有很大幫助</li>
<li><a href="https://allennlp.org/">AllenNLP</a> 是一個由 <a href="https://allenai.org/">AI2</a> 以 <a href="https://pytorch.org/">PyTorch</a> 實現的自然語言處理函式庫</li>
</ul>
<h3 id="hands-on machine learning 2"><a href="https://github.com/ageron/handson-ml2">Hands-on Machine Learning 2</a></h3>
<ul>
<li>前 YouTube 影片分類 PM <a href="https://twitter.com/aureliengeron">Aur&eacute;lien Geron</a> 教你如何透過 Scikit-Learn、Keras 以及 TensorFlow 2 來進行機器學習以及深度學習任務與應用的筆記本彙整。</li>
<li>第二版專注在 TensorFlow 2，其 Github repo 已有超過 6 千顆星，<a href="https://github.com/ageron/handson-ml">第一版</a>則有高達 2 萬星。</li>
</ul>
<h2 id="you zhi wen zhang_1"><div id="blogs">優質文章</div></h2>
<p>這邊列舉了一些幫助我釐清重要概念的部落格以及網站，希望能加速你探索這個深度學習世界。</p>
<p>只要 Google 一下就能發現這些部落格裡頭很多文章都有中文翻譯。但為了尊重原作者，在這邊都列出原文連結。</p>
<ul>
<li><a href="https://distill.pub/about/">Distill</a><ul>
<li>用非常高水準且互動的方式來說明複雜的深度學習概念。<a href="http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html">Yoshua Bengio</a>、<a href="http://www.iangoodfellow.com/">Ian Goodfellow</a> 及 <a href="http://cs.stanford.edu/people/karpathy/">Andrej Karpathy</a> 等知名人士皆參與其中</li>
</ul>
</li>
<li><a href="http://www.r2d3.us/%E5%9C%96%E8%A7%A3%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E7%AC%AC%E4%B8%80%E7%AB%A0/">R2D3: 圖解機器學習</a><ul>
<li>利用非常直覺易懂的視覺化來說明機器學習，連結為中文版</li>
</ul>
</li>
<li><a href="http://colah.github.io/">Christopher Olah's blog</a><ul>
<li>詳細解釋不少深度學習概念。作者在<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">這篇</a>就詳細地解釋了<a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E8%A8%98%E6%86%B6%E5%8A%9B%E5%A5%BD%E7%9A%84-LSTM-%E7%B4%B0%E8%83%9E">長短期記憶 LSTM</a> 的概念與變形；在<a href="http://colah.github.io/posts/2014-07-Understanding-Convolutions/">這篇</a>則解釋何為 CNN 的卷積運算</li>
</ul>
</li>
<li><a href="https://jalammar.github.io/">Jay Alammar's blog</a><ul>
<li>以清楚易懂的視覺化解釋深度學習概念。<a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">這篇</a>用大量易懂的動畫說明<a href="https://en.wikipedia.org/wiki/Neural_machine_translation">神經機器翻譯</a>，而在<a href="https://jalammar.github.io/illustrated-bert/">這篇</a>則介紹如何利用如 <a href="https://allennlp.org/elmo">ELMo</a>、<a href="https://github.com/google-research/bert">BERT</a> 等預先訓練過的強大模型在自然語言處理進行<a href="https://en.wikipedia.org/wiki/Transfer_learning">遷移學習</a></li>
</ul>
</li>
<li><a href="http://karpathy.github.io/">Andrej Karpathy's blog</a><ul>
<li>現為 Tesla AI 負責人的 <a href="https://twitter.com/karpathy">Andrej Karpathy</a> 在<a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">這篇</a>明確說明何謂循環神經網路 RNN。文中提供不少應用實例及視覺化來幫助我們理解 RNN 模型究竟學到了什麼，是學習 RNN 的朋友幾乎一定會碰到的一篇文章</li>
</ul>
</li>
</ul>
<h2 id="jing dian lun wen"><div id="papers">經典論文</div></h2>
<p>這邊依發表時間列出深度學習領域的經典 / 重要論文。</p>
<p>為了幫助你快速掌握論文內容以及歷年的研究趨勢，每篇論文下會有非常簡短的介紹（WIP）。</p>
<p>但我們推薦有興趣的人自行閱讀論文以深入了解。</p>
<h3 id="zi ran yu yan chu li  natural language processing (nlp)">自然語言處理 Natural Language Processing (NLP)</h3>
<ul>
<li><a href="http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf">2003/02 A Neural Probabilistic Language Model</a></li>
<li><a href="https://arxiv.org/abs/1301.3781">2013/01 Efficient Estimation of Word Representations in Vector Space</a></li>
<li><a href="https://arxiv.org/abs/1308.0850">2013/08 Generating Sequences With Recurrent Neural Networks</a></li>
<li><a href="https://arxiv.org/abs/1409.0473">2014/09 Neural Machine Translation by Jointly Learning to Align and Translate</a></li>
<li><a href="https://arxiv.org/abs/1508.04025">2015/08 Effective Approaches to Attention-based Neural Machine Translation</a></li>
<li><a href="https://arxiv.org/abs/1511.01432">2015/12 Semi-supervised Sequence Learning</a><ul>
<li>推出一套無監督式的預訓練方法。使用無標籤數據訓練後的 RNN 模型在之後的監督式任務表現更好</li>
</ul>
</li>
<li><a href="https://arxiv.org/abs/1706.03762">2017/06 Attention Is All You Need</a><ul>
<li>Google 推出新的神經網路架構 <a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">Transformer</a>。這個基於自注意力機制的架構特別適合語言理解任務</li>
</ul>
</li>
<li><a href="https://arxiv.org/abs/1706.05137">2017/06 One Model To Learn Them All</a></li>
<li><a href="https://arxiv.org/abs/1708.00107">2017/08 Learned in Translation: Contextualized Word Vectors</a><ul>
<li>監督式預訓練。透過 BiLSTM 與 Encoder-Decoder 架構預先訓練機器翻譯任務並將訓練後的 Encoder 拿來做特徵擷取。將 Encoder 的輸出作為語境向量（Context Vectors, CoVe）處理下游任務</li>
</ul>
</li>
<li><a href="https://arxiv.org/abs/1801.06146">2018/01 Universal Language Model Fine-tuning for Text Classification</a></li>
<li><a href="https://arxiv.org/abs/1802.05365">2018/02 Deep contextualized word representations</a><ul>
<li><a href="https://allennlp.org/elmo">ELMo 詞向量</a>，利用兩獨立訓練的 LSTM 獲取雙向訊息</li>
</ul>
</li>
<li><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">2018/06 Improving Language Understanding by Generative Pre-Training</a><ul>
<li><a href="https://blog.openai.com/language-unsupervised/">OpenAI</a> 利用無監督式預訓練以及 Transformer 架構訓練出來的模型表現在多個 NLP 任務表現良好。約使用 8 億詞彙量的資料集</li>
</ul>
</li>
<li><a href="https://arxiv.org/abs/1810.04805">2018/10 BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a><ul>
<li>Google 暴力美學。利用深層 Transformer 架構、2 個精心設計的預訓練任務以及約 33 億詞彙量的資料集訓練後，得到表現卓越的語言代表模型，打破 11 項 NLP 任務紀錄</li>
</ul>
</li>
<li><a href="https://arxiv.org/abs/1905.02450">2019/05 MASS: Masked Sequence to Sequence Pre-training for Language Generation</a><ul>
<li>Microsoft 利用 Encoder-Decoder 架構以及連續遮罩（consecutive mask）將 BERT 推廣到自然語言生成（NLG）類型任務</li>
</ul>
</li>
<li><a href="https://arxiv.org/abs/1905.03197">2019/05 Unified Language Model Pre-training for Natural Language Understanding and Generation</a><ul>
<li>預訓練階段利用不同遮罩控制 context，同時訓練雙向 LM、單向 LM 以及 Seq2Seq LM。其產生的預訓練模型可以處理 NLU 以及 NLG 任務，並在不加入外部數據的情況下打敗 BERT 在 GLUE 的紀錄</li>
</ul>
</li>
</ul>
<h3 id="dian nao shi jue  computer vision (cv)">電腦視覺 Computer Vision (CV)</h3>
<h4 id="lei shen jing wang lu jia gou  neural network architecture">類神經網路架構 Neural Network Architecture</h4>
<ul>
<li><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf">1998/01 Gradient-Based Learning Applied to Document Recognition (LeNet-5)</a></li>
<li><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">2012/12 ImageNet Classification with Deep Convolutional Neural Networks (AlexNet)</a></li>
<li><a href="https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf">2014/06 DeepFace: Closing the Gap to Human-Level Performance in Face Verification (DeepFace)</a></li>
<li><a href="https://arxiv.org/abs/1409.1556">2014/09 Very Deep Convolutional Networks for Large-Scale Image Recognition (VGG)</a></li>
<li><a href="https://arxiv.org/abs/1409.4842">2014/09 Goint deeper with convolutions (GoogLeNet)</a></li>
<li><a href="https://arxiv.org/abs/1411.4038">2014/11 Fully Convolutional Networks for Semantic Segmentation</a></li>
<li><a href="https://arxiv.org/abs/1505.04597">2015/05 U-Net: Convolutional Networks for Biomedical Image Segmentation (U-Net)</a></li>
<li><a href="https://arxiv.org/abs/1512.03385">2015/12 Deep Residual Learning for Image Recognition (ResNet)</a></li>
<li><a href="https://arxiv.org/abs/1704.04861">2017/04 MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications (MobileNets)</a></li>
<li><a href="https://arxiv.org/abs/1707.01083">2017/07 ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices (ShuffleNet)</a></li>
</ul>
<h4 id="zi liao ji  dataset">資料集 Dataset</h4>
<ul>
<li><a href="http://www.image-net.org/papers/imagenet_cvpr09.pdf">2009/06 ImageNet: A Large-Scale Hierarchical Image Database (ImageNet)</a></li>
</ul>
<h4 id="wu ti zhen ce yu qie ge  object detection and segmentation">物體偵測與切割 Object Detection and Segmentation</h4>
<ul>
<li><a href="https://arxiv.org/abs/1311.2524">2013/11 Rich feature hierarchies for accurate object detection and semantic segmentation (R-CNN)</a></li>
<li><a href="https://arxiv.org/abs/1312.6229">2013/12 OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks (OverFeat)</a></li>
<li><a href="https://arxiv.org/abs/1504.08083">2015/04 Fast R-CNN</a></li>
<li><a href="https://arxiv.org/abs/1506.01497">2015/06 Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (Faster R-CNN)</a></li>
<li><a href="https://arxiv.org/abs/1506.02640">2015/06 You Only Look Once: Unified, Real-Time Object Detection (YOLO)</a></li>
<li><a href="https://arxiv.org/abs/1512.02325">2015/12 SSD: Single Shot MultiBox Detector (SSD)</a></li>
<li><a href="https://arxiv.org/abs/1612.08242">2016/12 YOLO9000: Better, Faster, Stronger (YOLOv2)</a></li>
<li><a href="https://arxiv.org/abs/1703.06870">2017/03 Mask R-CNN</a></li>
<li><a href="https://arxiv.org/abs/1804.02767">2018/04 YOLOv3: An Incremental Improvement (YOLOv3)</a></li>
</ul>
<h4 id="sheng cheng mo xing  generative models">生成模型 Generative Models</h4>
<ul>
<li><a href="https://arxiv.org/abs/1406.2661">2014/06 Generative Adversarial Networks (GAN)</a></li>
<li><a href="https://arxiv.org/abs/1511.06434">2015/13 Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (DCGAN)</a></li>
<li><a href="https://arxiv.org/abs/1701.07875">2017/01 Wasserstein GAN (WGAN)</a></li>
<li><a href="https://arxiv.org/abs/1703.10593">2017/03 Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks (CycleGAN)</a></li>
</ul>
<h2 id="qi ta zheng li_2"><div id="collections">其他整理</div></h2>
<p>這邊列出其他優質的資源整理網站 / Github Repo，供你繼續探索深度學習。</p>
<h3 id="deep-learning-ocean"><a href="https://github.com/osforscience/deep-learning-ocean">deep-learning-ocean</a></h3>
<ul>
<li>整理了不少深度學習資源，但最值得參考的是數據集以及論文的分類整理。</li>
</ul>
<h2 id="dai ban shi xiang_1">待辦事項</h2>
<p>還有不少內容正在整理，以下是目前我們打算增加的一些項目：</p>
<ul>
<li>深度學習中英術語對照表</li>
<li>值得追蹤的業界 / 學界影響人物清單</li>
<li>無圖的資源列表版本</li>
<li>一些 Jupyter Notebook 範例</li>
</ul>
<p>而我們也會持續將新資源加入如<a href="#tools">實用工具</a>、<a href="#blogs">優質文章</a>等列表裡頭。</p>
<h2 id="ru he gong xian">如何貢獻</h2>
<p>非常歡迎你一起加入改善這個 Repo，讓更多人有方向地學習 Deep Learning：）</p>
<p>如果你有</p>
<ul>
<li>其他值得推薦的深度學習資源</li>
<li>針對此 Repo 內容的改善建議</li>
<li>其他任何你想得到的東西</li>
</ul>
<p>都歡迎你<a href="https://github.com/leemengtaiwan/deep-learning-resources/issues/new">提出新的 Issue</a> 來讓我們知道。</p>
<p>如果是想增加新資源的話，只附上連結也是沒有問題的，謝謝！
<div class="cell border-box-sizing text_cell rendered" style="margin-top: 2rem">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<img src="/images/general/maxwell-ridgeway-685077-unsplash.jpg">
<br/>
</img></div>
</div>
<p>
        最後，如果你覺得本文實用，還請幫我分享此文並給 <a href="https://github.com/leemengtaiwan/deep-learning-resources" target="_blank">Github Repo</a> 一個小星星。
        這樣可以讓更多人注意到這些寶貴資源的存在並開始有方向的學習，謝謝！
    </p>
<p>
        有再多資源，沒有親自動手做都是無法真正地學到東西的。因此，最後的最後讓我再次強調主動學習的重要：
    </p>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3">
<blockquote>
<p>
                            告訴我資訊，我只會忘記；教導我知識，我會記得；讓我實際參與，我將能真正地學到東西。
                            <br/>
<span style="float:right">── 班傑明&middot;富蘭克林<span>
</span></span></p>
</blockquote>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered" style="margin-top: 8rem">
<p>
        所以，現在就開始學習吧！
    </p>
</div></p>

                <!-- Tags -->
                <p class="blog-content__tags">
                    <span>Post Tags</span>

                    <span class="blog-content__tag-list">
                        <a href="https://leemeng.tw/tag/shen-du-xue-xi.html" rel="tag">深度學習</a>
                        <a href="https://leemeng.tw/tag/python.html" rel="tag">Python</a>
                        <a href="https://leemeng.tw/tag/keras.html" rel="tag">Keras</a>
                        <a href="https://leemeng.tw/tag/tensorflow.html" rel="tag">TensorFlow</a>
                    </span>

                </p>























                <!-- end Tags -->


                <!-- Mail-list-subscribe -->
                <div id="article-inner-subscribe" class="blog-content__pagenav">
                    <div class="blog-content__nav">
                        <div class="blog-content__prev">
                            <a class="open-popup" rel="subscribe">
                                <span>Get Latest Arrivals</span>
                                訂閱最新文章
                            </a>
                        </div>
                        <div class="blog-content__next">
                            <p>
                                跟資料科學相關的最新文章直接送到家。</br>
                                只要加入訂閱名單，當新文章出爐時，</br>
                                你將能馬上收到通知 <i class="im im-newspaper-o" aria-hidden="true"></i>
                            </p>
                        </div>
                    </div>
                    <div class="blog-content__all">
                        <a class="open-popup btn btn--primary ">&nbsp;&nbsp;Subscribe&nbsp;&nbsp;&nbsp;</a>
                    </div>
                </div>
                <!-- end Mail-list-subscribe -->

                <!--Pagination-->
                <div id="article-inner-neighbor-pages" class="blog-content__pagenav">
                    <div class="blog-content__nav">
                        <div class="blog-content__prev">
                            <a href="https://leemeng.tw/10-key-takeaways-from-ai-for-everyone-course.html" rel="prev">
                                <span>Previous Post</span>
                                我從 AI For Everyone 學到的 10 個重要 AI 概念
                            </a>
                        </div>
                        <div class="blog-content__next">
                            <a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html" rel="next">
                                <span>Next Post</span>
                                進入 NLP 世界的最佳橋樑：寫給所有人的自然語言處理與深度學習入門指南
                            </a>
                        </div>
                    </div>

                    <div class="blog-content__all">
                        <a href="blog.html" class="btn btn--primary">
                            View All Post
                        </a>
                    </div>
                </div>
                <!-- end Pagination-->

            </div><!-- end blog-content__main -->


        </div>
        </div> <!-- end blog-content -->

    </article>

<div class="comments-wrap">
    <div id="comments" class="row">
        <div class="col-full">
            <div id="disqus_thread"></div>
        </div>
    </div>
</div>

<script type="text/javascript">
var disqus_shortname = 'leemengtaiwan';
var disqus_title = '由淺入深的深度學習資源整理';

(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


<!-- footer
================================================== -->
<footer style="background:#0a0809">
    <div class="row">
        <div class="col-full">

            <div class="footer-logo">
                <a class="footer-site-logo" href="#0"><img src="https://leemeng.tw/theme/images/logo.png" alt="Homepage"></a>
            </div>

            <ul class="footer-social">
<li><a href="https://github.com/leemengtaiwan" target="_blank">
    <i class="im im-github" aria-hidden="true"></i>
    <span>Github</span>
</a></li>
<li><a href="https://www.facebook.com/LeeMengTaiwan" target="_blank">
    <i class="im im-facebook" aria-hidden="true"></i>
    <span>Facebook</span>
</a></li>
<li><a href="https://www.instagram.com/leemengtaiwan/" target="_blank">
    <i class="im im-instagram" aria-hidden="true"></i>
    <span>Instagram</span>
</a></li>
<li><a href="https://www.linkedin.com/in/leemeng1990/" target="_blank">
    <i class="im im-linkedin" aria-hidden="true"></i>
    <span>LinkedIn</span>
</a></li>            </ul>
        </div>
    </div>
    <div class="row footer-bottom">
        <div class="col-twelve">
            <div class="go-top">
            <a class="smoothscroll" title="Back to Top" href="#top"><i class="im im-arrow-up" aria-hidden="true"></i></a>
            </div>
        </div>
    </div> <!-- end footer-bottom -->
</footer> <!-- end footer -->


        <!-- Javascript
    ================================================== -->
    <script src="https://leemeng.tw/theme/js/jquery-3.2.1.min.js"></script>
    <script src="https://leemeng.tw/theme/js/plugins.js"></script>
    <script src="https://leemeng.tw/theme/js/main_raw.js"></script>
    <script type='text/javascript' src='https://leemeng.tw/theme/js/scroll-detect.js'></script>

    <!--https://instant.page/-->
    <script src="//instant.page/1.0.0" type="module" integrity="sha384-6w2SekMzCkuMQ9sEbq0cLviD/yR2HfA/+ekmKiBnFlsoSvb/VmQFSi/umVShadQI"></script>


    <script type='text/javascript' src='https://leemeng.tw/theme/js/progress-bar.js'></script>
    <script type='text/javascript' src='https://leemeng.tw/theme/js/scroll-detect.js'></script>

    <!--show and hide left navigation by scrolling-->
    <script>
    $(document).scroll(function() {
        var y = $(this).scrollTop();
      if ( $(window).width() > 980 ) {
        if (y > 600) {
          $('#left-navigation').fadeIn(300);
        } else {
          $('#left-navigation').fadeOut(300);
        }
      }
    });
    </script>

<!--reference: https://gist.github.com/scottmagdalein/259d878ad46ed6f2cdce-->
<script type="text/javascript" src="//downloads.mailchimp.com/js/signup-forms/popup/embed.js" data-dojo-config="usePlainJson: true, isDebug: false">
</script>

<script type="text/javascript">
  function showMailingPopUp() {
    require(["mojo/signup-forms/Loader"], function(L) { L.start({"baseUrl":"mc.us18.list-manage.com","uuid":"151cb59f2de814c499c76b77a","lid":"dd1d78cc5e"})})
    document.cookie = "MCPopupClosed=; expires=Thu, 01 Jan 1970 00:00:00 UTC";
    document.cookie = "MCPopupSubscribed=; expires=Thu, 01 Jan 1970 00:00:00 UTC";
  };

  $(function() {
    $(".open-popup").on('click', function() {
      showMailingPopUp();
    });
  });
</script><!--https://darkmodejs.learn.uno/-->
<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.4.0/lib/darkmode-js.min.js"></script>
<script>
var options = {
  bottom: '32px', // default: '32px'
  right: 'unset', // default: '32px'
  left: '32px', // default: 'unset'
  time: '0.2s', // default: '0.3s'
  mixColor: '#fff', // default: '#fff'
  backgroundColor: '#fff',  // default: '#fff'
  buttonColorDark: '#100f2c',  // default: '#100f2c'
  buttonColorLight: '#fff', // default: '#fff'
  saveInCookies: true, // default: true,
  label: '🌓', // default: ''
  autoMatchOsTheme: true // default: true
}

const darkmode = new Darkmode(options);
darkmode.showWidget();
</script>
<!--reference: https://www.w3schools.com/howto/tryit.asp?filename=tryhow_js_overlay-->
<script>
function openTocNav() {
    document.getElementById("tocNav").style.width = "100%";
}

function closeTocNav() {
    document.getElementById("tocNav").style.width = "0%";
}

function toggleTocNav() {
    var current_width = document.getElementById("tocNav").style.width;
    if (current_width == "100%") {
        document.getElementById("tocNav").style.width = "0%";
    } else {
        document.getElementById("tocNav").style.width = "100%";
    }
}

function closeLeftNavImage(elementId) {
    document.getElementById(elementId).style.width = "0%";
}

function toggleLeftNavImage(elementId) {
    var current_width = document.getElementById(elementId).style.width;
    if (current_width == "100%") {
        document.getElementById(elementId).style.width = "0%";
    } else {
        document.getElementById(elementId).style.width = "100%";
    }
}

</script>


</body>
</html>