<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>LeeMeng - Lee Meng</title><link>https://leemeng.tw/</link><description></description><lastBuildDate>Mon, 25 Jan 2021 19:00:00 +0900</lastBuildDate><item><title>監控資本主義時代下的資料科學、AI 與你我的數位未來</title><link>https://leemeng.tw/data-science-ai-and-our-digital-future-in-the-age-of-surveillance-capitalism.html</link><description>&lt;p&gt;這是一篇講述監控資本主義的驚悚輕小說與科普文。處在數位時代的每個人都需要了解谷歌、臉書與推特等科技巨頭如何形塑我們的數位現實以及其背後運作的商業邏輯與經濟誘因。文中也會清晰地呈現資料科學與監控資本主義之間的緊密關係。閱讀完本文的讀者將能重新找回數位時代中最重要的注意力並專注在真正重要的事情。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Mon, 25 Jan 2021 19:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2021-01-25:/data-science-ai-and-our-digital-future-in-the-age-of-surveillance-capitalism.html</guid><category>Miscellaneous</category><category>監控資本主義</category><category>資料科學</category><category>人工智慧</category><category>深度學習</category><category>推薦系統</category></item><item><title>世上最生動的 PCA：直觀理解並應用主成分分析</title><link>https://leemeng.tw/essence-of-principal-component-analysis.html</link><description>&lt;p&gt;這篇文章用世上最生動且實務的方式帶你直觀理解機器學習領域中十分知名且強大的線性降維技巧：主成分分析 PCA。我們將重新回顧你所學過的重要線性代數概念，並實際應用這些概念將數據有效地降維並去除特徵間的關聯。你也將學會如何使用 NumPy 和 scikit-learn 等 Python 函式庫自己實作 PCA。文中也分享使用 PCA 分析線上遊戲《英雄聯盟》公開數據的有趣案例。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Mon, 06 Jan 2020 01:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2020-01-06:/essence-of-principal-component-analysis.html</guid><category>Miscellaneous</category><category>PCA</category><category>主成分分析</category><category>機器學習</category><category>線性代數</category><category>Python</category></item><item><title>給所有人的深度學習入門：直觀理解神經網路與線性代數</title><link>https://leemeng.tw/deep-learning-for-everyone-understand-neural-net-and-linear-algebra.html</link><description>&lt;p&gt;這是篇透過大量動畫幫助你直觀理解神經網路的科普文。我們將介紹基礎的神經網路與線性代數概念，以及兩者之間的緊密關係。我們也將實際透過神經網路解決二元分類任務，了解神經網路的運作原理。讀完本文，你將能夠深刻地體會神經網路與線性代數之間的緊密關係，奠定 AI 之旅的基礎。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Sun, 13 Oct 2019 22:30:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2019-10-13:/deep-learning-for-everyone-understand-neural-net-and-linear-algebra.html</guid><category>Miscellaneous</category><category>深度學習</category><category>Manim</category><category>TensorFlow</category></item><item><title>直觀理解 GPT-2 語言模型並生成金庸武俠小說</title><link>https://leemeng.tw/gpt2-language-model-generate-chinese-jing-yong-novels.html</link><description>&lt;p&gt;這篇文章將簡單向讀者介紹 OpenAI 的知名語言模型 GPT-2，並展示能夠生成金庸小說的 GPT-2 模型。文中也將透過視覺化工具 BertViz 來帶讀者直觀了解基於 Transformer 架構的 NLP 模型背後的自注意力機制。讀者也能透過文中提供的 GPT-2 模型及 Colab 筆記本自行生成全新的金庸橋段。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Sat, 07 Sep 2019 16:30:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2019-09-07:/gpt2-language-model-generate-chinese-jing-yong-novels.html</guid><category>Miscellaneous</category><category>自然語言處理</category><category>NLP</category><category>PyTorch</category></item><item><title>資料科學家的 pandas 實戰手冊：掌握 40 個實用數據技巧</title><link>https://leemeng.tw/practical-pandas-tutorial-for-aspiring-data-scientists.html</link><description>&lt;p&gt;熟練地使用 pandas 是資料科學家處理數據與分析時不可或缺的重要技能之一。透過 40 個 pandas 實用技巧，這篇文章將帶你由淺入深地掌握最基礎且重要的 pandas 能力。文中也將介紹多個適合與 pandas 一起使用的強大函式庫，提升你的數據處理能力。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Sat, 27 Jul 2019 21:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2019-07-27:/practical-pandas-tutorial-for-aspiring-data-scientists.html</guid><category>Miscellaneous</category><category>資料科學</category><category>Python</category><category>pandas</category></item><item><title>進擊的 BERT：NLP 界的巨人之力與遷移學習</title><link>https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html</link><description>&lt;p&gt;這篇是給所有人的 BERT 科普文以及操作入門手冊。文中將簡單介紹知名的語言代表模型 BERT 以及如何用其實現兩階段的遷移學習。讀者將有機會透過 PyTorch 的程式碼來直觀理解 BERT 的運作方式並實際 fine tune 一個真實存在的假新聞分類任務。閱讀完本文的讀者將能把 BERT 與遷移學習運用到其他自己感興趣的 NLP 任務。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Wed, 10 Jul 2019 09:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2019-07-10:/attack_on_bert_transfer_learning_in_nlp.html</guid><category>Miscellaneous</category><category>自然語言處理</category><category>NLP</category><category>PyTorch</category></item><item><title>淺談神經機器翻譯 &amp; 用 Transformer 與 TensorFlow 2 英翻中</title><link>https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html</link><description>&lt;p&gt;本文分為兩大部分。前半將帶讀者簡單回顧 Seq2Seq 模型、自注意力機制以及 Transformer 等近年在機器翻譯領域裡頭的重要發展與概念；後半段則將帶著讀者實作一個可以將英文句子翻譯成中文的 Transformer。透過瞭解其背後運作原理，讀者將能把類似的概念應用到如圖像描述、閱讀理解以及語音辨識等各式各樣的機器學習任務之上。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Mon, 17 Jun 2019 05:40:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2019-06-17:/neural-machine-translation-with-transformer-and-tensorflow2.html</guid><category>Miscellaneous</category><category>自然語言處理</category><category>NLP</category><category>Tensorflow</category></item><item><title>用 CartoonGAN 及 TensorFlow 2 生成新海誠與宮崎駿動畫</title><link>https://leemeng.tw/generate-anime-using-cartoongan-and-tensorflow2.html</link><description>&lt;p&gt;本文展示 3 種可以讓你馬上運用 CartoonGAN 來生成動漫的方法。其中包含了我們的 Github 專案、TensorFlow.js 應用以及一個事先為你準備好的 Colab 筆記本。有興趣的同學還可學習如何利用 TensorFlow 2.0 來訓練自己的專屬 CartoonGAN。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Sun, 05 May 2019 02:20:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2019-05-05:/generate-anime-using-cartoongan-and-tensorflow2.html</guid><category>Miscellaneous</category><category>GAN</category><category>TensorFlow</category><category>TensorFlow.js</category></item><item><title>讓 AI 寫點金庸：如何用 TensorFlow 2.0 及 TensorFlow.js 寫天龍八部</title><link>https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html</link><description>&lt;p&gt;這篇文章展示一個由 TensorFlow 2.0 以及 TensorFlow.js 實現的文本生成應用。本文也會透過深度學習專案常見的 7 個步驟，帶領讀者一步步了解如何實現一個這樣的應用。閱讀完本文，你將對開發 AI 應用的流程有些基礎的了解。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Wed, 27 Mar 2019 09:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2019-03-27:/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html</guid><category>Miscellaneous</category><category>TensorFlow</category><category>TensorFlow.js</category><category>自然語言處理</category></item><item><title>我從 AI For Everyone 學到的 10 個重要 AI 概念</title><link>https://leemeng.tw/10-key-takeaways-from-ai-for-everyone-course.html</link><description>&lt;p&gt;AI For Everyone 是由吳恩達教授開授的一堂線上課程，這篇文章則記錄了我個人在修習完這堂線上課程後整理出的 10 個最重要 AI 概念。除了將這些概念條列出來以外，本文也將逐一介紹每個概念所代表的涵意，幫助讀者快速掌握該課程裡頭的重要 AI 概念，並開始自己的 AI 之旅。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Tue, 05 Mar 2019 08:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2019-03-05:/10-key-takeaways-from-ai-for-everyone-course.html</guid><category>Miscellaneous</category><category>人工智慧</category><category>資料科學</category><category>機器學習</category></item><item><title>由淺入深的深度學習資源整理</title><link>https://leemeng.tw/deep-learning-resources.html</link><description>&lt;p&gt;這裡紀錄了我在學習深度學習時蒐集的一些線上資源。內容由淺入深，而且會一直被更新，希望能幫助你順利地開始學習：）&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Tue, 08 Jan 2019 08:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2019-01-08:/deep-learning-resources.html</guid><category>Miscellaneous</category><category>深度學習</category><category>Python</category><category>Keras</category><category>TensorFlow</category></item><item><title>進入 NLP 世界的最佳橋樑：寫給所有人的自然語言處理與深度學習入門指南</title><link>https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html</link><description>&lt;p&gt;在此文中，我們以一個假新聞分類的 Kaggle 競賽做為引子，不用深奧的數學計算式，而是直觀且高層次地理解目前常見的 NLP 手法以及基本的深度學習、機器學習概念。透過建立一個能夠分類假新聞的神經網路，你將會學到如文本數據前處理、循環神經網路以及深度學習 3 步驟等基礎知識，並在未來利用此基礎進一步探索 NLP 世界。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Mon, 24 Dec 2018 08:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-12-24:/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html</guid><category>Miscellaneous</category><category>自然語言處理</category><category>Keras</category><category>Python</category><category>深度學習</category></item><item><title>Chartify：讓數據科學家效率加倍的 Python 資料視覺化工具</title><link>https://leemeng.tw/chartify-a-simple-yet-powerful-python-data-visualization-tool-which-boost-your-productivity-as-a-data-scientist.html</link><description>&lt;p&gt;此文會展示如何利用 Chartify，一個直觀且貼心的 Python 繪圖函式庫，來對如 2018 臺北市候選人得票數、歷年各大洲來台人數等公開數據做資料視覺化。如果你想要學習利用 Python 實現資料視覺化，但還不知道怎麼開始；或是覺得目前使用的工具不太直覺，想要提升自己工作效率的話，這篇就是為你而寫的。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Mon, 26 Nov 2018 08:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-11-26:/chartify-a-simple-yet-powerful-python-data-visualization-tool-which-boost-your-productivity-as-a-data-scientist.html</guid><category>Miscellaneous</category><category>資料視覺化</category><category>Python</category></item><item><title>我在比利時 EMNLP 之旅中學到的 3 堂課</title><link>https://leemeng.tw/3-lessons-i-learnt-from-emnlp-2018-at-belgium.html</link><description>&lt;p&gt;這是一個 NLP 初心者勇闖自然語言處理的頂級學術會議 EMNLP 的故事。在這篇文章裡，我想跟你分享 3 個這次旅行中帶給我最重要的體悟。這些體悟改變了我的人生，而我也希望你能從這個故事裡頭獲得些啟發，重新思考你自己的學習，並做一些好的改變。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Mon, 19 Nov 2018 08:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-11-19:/3-lessons-i-learnt-from-emnlp-2018-at-belgium.html</guid><category>Miscellaneous</category><category>隨筆</category><category>自然語言處理</category><category>深度學習</category></item><item><title>資料科學家 L 的奇幻旅程 Vol.2 如何用資料工程當個時間旅人</title><link>https://leemeng.tw/journey-of-data-scientist-L-part-2-time-traveling-with-data-engineering.html</link><description>&lt;p&gt;「資料工程」與「時間旅行」，兩個看似毫無相關的詞能擦出什麼火花？在這篇文章裡頭，我想跟你分享一個輕鬆話題：身為資料科學家的我，是如何利用資料工程在公司裡頭當個「時間旅人」的。當然，實際上每家公司的 DS 以及 DE 的工作內容都會有所不同，了解這個事實並調整期待，將幫助你找到最適合自己的工作環境。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Fri, 09 Nov 2018 21:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-11-09:/journey-of-data-scientist-L-part-2-time-traveling-with-data-engineering.html</guid><category>Miscellaneous</category><category>日誌</category><category>資料科學</category><category>資料工程</category></item><item><title>資料科學文摘 Vol.7 數據技能、深度學習以及 AI 的倫理道德</title><link>https://leemeng.tw/data-science-digest-volume-7.html</link><description>&lt;p&gt;今天讓我跟你分享 4 篇跟數據以及人工智慧相關的文章。在第一篇文章，我們將看到如何用一個簡單、有效的方式來決定應該學習什麼「數據技能」；在第二篇文章，我們則會看到如何透過數據，了解網際網路是如何快速發展成為人們每天不可或缺的一部分。接著我們會聽聽在計算神經科學領域的先驅之一，泰瑞教授解釋何謂「深度學習」以及 AI 與人類智慧如何擦出火花；最後，我們將一窺 AI 的倫理道德議題以及著名的電車難題。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Fri, 26 Oct 2018 08:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-10-26:/data-science-digest-volume-7.html</guid><category>Miscellaneous</category><category>文摘</category><category>資料科學</category></item><item><title>資料科學文摘 Vol.6 人類壽命大進展、GAN、數據工廠以及產品分析</title><link>https://leemeng.tw/data-science-digest-volume-6.html</link><description>&lt;p&gt;這週我們一樣保持閱讀的「營養均衡」，從全球平均壽命變化的資料視覺化、深度學習最夯的「對抗生成網路」話題、產品分析框架到理解何謂「數據工廠」，我希望能讓閱讀本文摘的你，廣泛地了解各領域跟「資料」相關的議題，並進一步找出自己的興趣，加以深度探索。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Sun, 14 Oct 2018 14:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-10-14:/data-science-digest-volume-6.html</guid><category>Miscellaneous</category><category>文摘</category><category>資料科學</category></item><item><title>如何用 30 秒了解台灣發展與全球趨勢：用 GapMinder 培養正確世界觀</title><link>https://leemeng.tw/gapminder.html</link><description>&lt;p&gt;這篇文章提供你一個輕鬆探索台灣與世界的資料視覺化工具：GapMinder 中文版。除了工具本身以外，文中會透過大量動態的資訊圖表以及各國公開數據來帶你探索台灣以及世界。閱讀本文之後，你將了解全球的發展趨勢、對台灣的社會、經濟以及能源發展有個基礎認知，並重新建立一個宏觀、積極的世界觀。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Mon, 08 Oct 2018 01:50:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-10-08:/gapminder.html</guid><category>Miscellaneous</category><category>GapMinder</category><category>資料視覺化</category><category>資料科學</category></item><item><title>資料科學文摘 Vol.5 數據科學家面臨的挑戰、儀表板設計以及未來的被駭人生</title><link>https://leemeng.tw/data-science-digest-volume-5-challenges-that-data-scientists-facing-dashboard-design-and-hackable-humans.html</link><description>&lt;p&gt;真正的數據科學家面臨的 8 個挑戰是什麼？何時一個資料科學家可以說他 / 她真正地「完成」了工作？ 10 個儀表板設計的原則是什麼？何謂「被駭」人生？為了了解這些跟資料科學息息相關的問題以及可能的解答，這週我們一樣會透過閱讀幾篇文章，來分別了解幾位優秀的資料科學家、UI/UX 設計師甚至是歷史學家是怎麼思考這些問題的。如同以往的文摘，我會附上摘要並穿插自己的心得，供時間寶貴的你參考。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Mon, 17 Sep 2018 12:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-09-17:/data-science-digest-volume-5-challenges-that-data-scientists-facing-dashboard-design-and-hackable-humans.html</guid><category>Miscellaneous</category><category>文摘</category><category>資料科學</category></item><item><title>給資料科學家的 Docker 指南：3 種活用 Docker 的方式（上）</title><link>https://leemeng.tw/3-ways-you-can-leverage-the-power-of-docker-in-data-science-part-1-learn-the-basic.html</link><description>&lt;p&gt;本系列文章將分上下篇，本篇將直觀解釋 Docker 概念，並說明資料科學家能如何利用 Docker 來改善自己的開發效率；下篇則將分享作者在實際從事資料科學家時，為了解決一些數據問題而時常碰到的 3 種 Docker 使用方式。在本篇中，我們首先將透過一些簡單的比喻來直觀地理解 Docker，並讓讀者在閱讀本文後能馬上開始利用 Docker 來加速自己的開發效率，並為下篇的進階內容打好基礎。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Sat, 08 Sep 2018 19:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-09-08:/3-ways-you-can-leverage-the-power-of-docker-in-data-science-part-1-learn-the-basic.html</guid><category>Miscellaneous</category><category>資料科學</category><category>Docker</category></item><item><title>資料科學文摘 Vol.4 數據科學 MMORPG 上線！你，選好自己的角色了嗎？</title><link>https://leemeng.tw/data-science-digest-volume-4-choose-your-own-character-in-data-science-role-play-game.html</link><description>&lt;p&gt;這篇文摘透過多篇跟資料科學家相關的文章，闡述資料科學家這個職業近年可能產生，或者是已經正在發生的一些職涯趨勢。透過掌握大局觀，讓對資料科學領域感興趣的讀者能夠理性地思考自己未來如何進入這塊領域，並在符合自己興趣以及能力的情況下，發揮自己最大的價值。我們將探討在這個什麼職業都跟數據扯上關係的年代，你要如何在「全球數據科學 MMORPG」裡頭，找出自己的定位以及角色。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Wed, 29 Aug 2018 00:30:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-08-29:/data-science-digest-volume-4-choose-your-own-character-in-data-science-role-play-game.html</guid><category>Miscellaneous</category><category>文摘</category><category>資料科學</category></item><item><title>一段 Airflow 與資料工程的故事：談如何用 Python 追漫畫連載</title><link>https://leemeng.tw/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html</link><description>&lt;p&gt;Airflow 是一個以 Python 開發的工作流管理系統，也是資料工程不可或缺的利器之一。近年不管是資料科學家、資料工程師還是任何需要處理數據的軟體工程師，Airflow 都是他們用來建構 ETL 以及處理批量資料的首選之一。這篇文章希望以一個簡易的漫畫連載通知 App 作為引子，讓讀者直觀地了解 Airflow 背後的運作原理、建立資料工程的知識基礎，並在閱讀本文後發揮自己的創意，實際應用 Airflow 來解決並自動化自己及企業的數據問題。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Tue, 21 Aug 2018 23:30:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-08-21:/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html</guid><category>Miscellaneous</category><category>Python</category><category>Airflow</category><category>資料工程</category><category>Selenium</category><category>Slack</category></item><item><title>資料科學文摘 Vol.3 Pandas、Docker 以及數據時代的反思</title><link>https://leemeng.tw/data-science-digest-volume-3.html</link><description>&lt;p&gt;不同於上週的文摘，這週的選文比較技術以及實作導向。本週將導讀 3 篇使用 Python 以及 Pandas 的文章，並鼓勵讀者實際動手學習。我們也會看到如何使用 Docker 來讓資料科學變得更簡單，並提供一個有趣的貓咪圖片辨識 App 給有興趣的讀者參考。最後，讓我們分別看看哈佛商業評論以及美國前首席資料科學家 DJ Patil 談談如何讓資料科學在企業內普及，以及數據時代我們面臨的各種道德議題。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Fri, 10 Aug 2018 21:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-08-10:/data-science-digest-volume-3.html</guid><category>Miscellaneous</category><category>文摘</category><category>Pandas</category><category>SQL</category><category>Docker</category><category>資料科學</category></item><item><title>資料科學文摘 Vol.2 產品理解以及 DS / DE 之路</title><link>https://leemeng.tw/data-science-digest-volume-2.html</link><description>&lt;p&gt;這週一樣會透過導讀一些優質文章，讓讀者了解 3 個問題：為何一個專業的資料科學家需要具備「產品理解」？ 何謂「顧客流失分析」？ 我們該如何使用 Python（XGBoost）來建立簡單的預測模型以改善產品？ 此外，我們也將簡單介紹在資料科學領域中逐漸崛起的「資料工程師」，其職責以及專業跟「資料科學家」有何不同。最後也會分享一些與資料科學家/資料工程師相關的文章。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Fri, 03 Aug 2018 14:20:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-08-03:/data-science-digest-volume-2.html</guid><category>Miscellaneous</category><category>文摘</category><category>資料科學</category><category>資料工程</category><category>Python</category></item><item><title>資料科學文摘 Vol.1 AutoML、Airflow 及 DAU</title><link>https://leemeng.tw/data-science-digest-volume-1.html</link><description>&lt;p&gt;這週介紹幾篇機器學習、資料工程及 App 分析的優質文章以及重點摘要，關鍵字包含：AutoML、Airflow 以及 DAU / MAU。希望讓更多人能更快地掌握資料科學領域的知識，找出自己有興趣的領域專研，並激盪出更多的討論。透過閱讀大量的相關文章並從它們學習及模仿，我們可以更快地，且有效率地成為一個稱職的資料科學家。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Sun, 29 Jul 2018 18:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-07-29:/data-science-digest-volume-1.html</guid><category>Miscellaneous</category><category>文摘</category><category>資料科學</category><category>資料工程</category><category>機器學習</category></item><item><title>資料科學家 L 的奇幻旅程 Vol.1 新人不得不問的 2 個問題</title><link>https://leemeng.tw/journey-of-data-scientist-L-part-1-two-must-ask-questions-when-on-board.html</link><description>&lt;p&gt;為了讓有志成為資料科學家，或是單純想要了解的讀者們能理解資料科學是如何實際被企業應用，以及讓自己多一點反思的機會，趁著最近開始在 SmartNews 的新工作，我打算開始紀錄自己平常的工作內容以及一些經驗分享。作為系列文的第一篇文章，我們將探討一個資料科學家在進入新公司熟悉環境的時候，除了問該裝什麼工具以外，可以問的兩個重要問題。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Sat, 07 Jul 2018 20:30:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-07-07:/journey-of-data-scientist-L-part-1-two-must-ask-questions-when-on-board.html</guid><category>Miscellaneous</category><category>資料科學</category><category>data-science</category><category>日誌</category></item><item><title>從彼此學習 - 淺談機器學習以及人類學習</title><link>https://leemeng.tw/some-thought-on-learning-from-machine-learning.html</link><description>&lt;p&gt;說到近年最熱門的機器學習或者人工智慧，因為知識背景以及觀點的不同，幾乎每個人都有不一樣的見解。雖然我們有千百種定義、無數的專業術語，這篇文章希望用直觀的方式以及具體的例子，讓讀者能夠在跳入一大堆 ML 的教學文章以及線上課程之前，能以一個更高層次且人性化的角度理解機器學習，並進而思考要如何開啟自己的機器學習旅程。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Sat, 16 Jun 2018 17:20:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-06-16:/some-thought-on-learning-from-machine-learning.html</guid><category>Miscellaneous</category><category>機器學習</category><category>machine learning</category></item><item><title>從經驗中學習 - 直觀理解貝氏定理及其應用</title><link>https://leemeng.tw/intuitive-understandind-of-bayes-rules-and-learn-from-experience.html</link><description>&lt;p&gt;貝氏定理（Bayes' theorem）是機率論中，一個概念簡單卻非常強大的定理。有了機率論的存在，人們才能理性且合理地評估未知事物發生的可能性（例：今天的下雨機率有多少？我中樂透的可能性有多高？），並透過貝氏定理搭配經驗法則來不斷地改善目前的認知，協助我們做更好的決策。這篇將利用生活上我們（或人工智慧）常需要考慮的事情當作引子，如今天的下雨機率是多少？來直觀地了解貝氏定理是怎麼被應用在各式各樣的地方。我們甚至可以效仿貝氏定理的精神，讓自己能更理性地評估未知並從經驗中學習。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Fri, 25 May 2018 15:30:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-05-25:/intuitive-understandind-of-bayes-rules-and-learn-from-experience.html</guid><category>Miscellaneous</category><category>貝氏定理</category><category>機率</category><category>機器學習</category></item><item><title>揭開資料科學的神秘面紗</title><link>https://leemeng.tw/demystify-the-hype-of-data-science-and-its-value.html</link><description>&lt;p&gt;市面上有大量資料科學相關課程、書籍供我們自由學習，但你有想過為何我們需要學習資料科學嗎？為什麼資料科學現在那麼夯？我們應該拿資料科學來做什麼？抽離技術實作或者分析手法的討論，這篇文章試著用簡單的經濟學解釋其背後原因。希望閱讀完本文的讀者能了解為何資料科學在資訊時代扮演重要角色，以及我們要怎麼有效率地把握「資料科學力」以創造更大的價值。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Fri, 11 May 2018 21:10:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-05-11:/demystify-the-hype-of-data-science-and-its-value.html</guid><category>Miscellaneous</category><category>資料科學</category><category>data-science</category></item><item><title>為何資料科學家需要學習 SQL</title><link>https://leemeng.tw/why-you-need-to-learn-sql-as-a-data-scientist.html</link><description>&lt;p&gt;這篇將簡單討論資料科學家必備的能力之一：結構化查詢語言（SQL）在概念上跟命令式程式語言如 Python 有什麼不同之處，以及在什麼樣的情況下我們會想要利用 SQL 做資料分析。這篇注重在為何你會想要使用 SQL 做資料分析，而非 SQL 本身功能的教學。如果要學習 SQL 本身，可以參考本文最後面的推薦閱讀。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Mon, 30 Apr 2018 23:50:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-04-30:/why-you-need-to-learn-sql-as-a-data-scientist.html</guid><category>Miscellaneous</category><category>資料科學</category><category>SQL</category><category>data-science</category></item><item><title>資料科學家為何需要了解資料工程</title><link>https://leemeng.tw/why-you-need-to-learn-data-engineering-as-a-data-scientist.html</link><description>&lt;p&gt;透過描述資料科學家的一天日常，本文將簡單介紹資料工程（Data Engineering）的概念、其如何跟資料科學相關。以及最重要的，作為一個資料科學家應該如何學習並善用這些知識來創造最大價值。身為一個資料科學家，擁有資料工程的知識可以提升工作效率，點亮你的方向並加速專案前進。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Mon, 23 Apr 2018 22:55:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-04-23:/why-you-need-to-learn-data-engineering-as-a-data-scientist.html</guid><category>Miscellaneous</category><category>資料科學</category><category>資料工程</category><category>data-science</category><category>data engineering</category></item><item><title>淺談資料視覺化以及 ggplot2 實踐</title><link>https://leemeng.tw/data-visualization-from-matplotlib-to-ggplot2.html</link><description>&lt;p&gt;這篇主要描述自己以往在利用 Python 做資料視覺化時常犯的思維瑕疵，而該思維如何在接觸 R 的 ggplot2 以後得到改善。本文會試著說明資料視覺化的本質為何，以及在設計視覺化時，概念上應該包含什麼要素以及步驟。最後展示如何透過 ggplot2 活用前述的概念，來實際做資料視覺化。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Sat, 14 Apr 2018 15:10:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-04-14:/data-visualization-from-matplotlib-to-ggplot2.html</guid><category>Miscellaneous</category><category>R</category><category>visualization</category><category>ggplot2</category><category>資料視覺化</category></item><item><title>利用 Kinesis 處理串流資料並建立資料湖</title><link>https://leemeng.tw/use-kinesis-streams-and-firehose-to-build-a-data-lake.html</link><description>&lt;p&gt;所謂的資料湖指的是一企業裡頭所有形式的資料的集合。這些資料包含原始資料，以及經過轉換的衍生資料。資料湖的核心概念是將所有可用的資料全部整合在一個邏輯上相近的地方以供企業自由結合並做各式各樣的運用。資料湖可以用很多方式建立，這裏我們主要介紹如何利用 Amazon Kinesis 將串流資料載入資料湖。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Wed, 04 Apr 2018 21:30:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-04-04:/use-kinesis-streams-and-firehose-to-build-a-data-lake.html</guid><category>Miscellaneous</category><category>資料工程</category><category>python</category><category>aws</category><category>kinesis</category></item><item><title>AWS Data Migration Service - 從 MongoDB 遷移到 Redshift</title><link>https://leemeng.tw/replicate-data-from-mongodb-to-redshift-using-aws-data-migration-service.html</link><description>&lt;p&gt;同樣一份資料因應不同的使用案例，可能需要使用不同的存取方式。而針對這些不同的存取方式，我們通常需要選擇最適合的資料庫來最佳化使用者體驗。這篇文章將簡單介紹如何使用 AWS Database Migration Service來快速地達到我們的目標：將 MongoDB 資料遷移到 Redshift 上。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Tue, 27 Mar 2018 18:30:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-03-27:/replicate-data-from-mongodb-to-redshift-using-aws-data-migration-service.html</guid><category>Miscellaneous</category><category>aws</category><category>資料庫</category><category>資料工程</category></item><item><title>Designing Data-Intensive Applications (1) - 序言</title><link>https://leemeng.tw/designing-data-intensive-applications-1-preface.html</link><description>&lt;p&gt;最近在拜讀 Martin Kleppmann 的 Designing Data-Intensive Applications， 覺得受益匪淺，且我也相信透過 Feynman Technique 將學到的東西用最淺顯易懂的方式表達能幫助自己內化這些知識，遂嘗試把閱讀後的心得記錄在此。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Sat, 24 Mar 2018 15:33:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-03-24:/designing-data-intensive-applications-1-preface.html</guid><category>Miscellaneous</category><category>資料工程</category></item><item><title>Google Data Studio 基礎</title><link>https://leemeng.tw/google-data-studio-basics.html</link><description>&lt;p&gt;Google Data Studio 是 Google 推出的一個儀表板服務，讓我們可以利用多種連結器將儲存在如 Google Analytics、 Google 試算表及 Google BigQuery 等特定資料來源的資料做出漂亮的 visualization ，用資料講故事而不用自己設計 UI。這篇把學到的一些技巧以及使用心得記錄下來。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Tue, 13 Mar 2018 16:34:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-03-13:/google-data-studio-basics.html</guid><category>Miscellaneous</category><category>資料科學</category><category>data-science</category><category>資料視覺化</category></item><item><title>Pelican 實戰手冊(主題篇)</title><link>https://leemeng.tw/build-a-pelican-powered-blog-like-a-pro.html</link><description>&lt;p&gt;Pelican 是一個用 Python 寫的靜態網頁生成器, 可以幫我們把 reStructedText, Markdown file 甚至 Jupyer notebook 轉成靜態的 HTML 檔案。 有些人可能已經注意到這個部落格是用 Pelican 所寫成並且 host 在 Github 上的。這篇主要紀錄如何使用 Jinja2 自訂主題。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Mon, 05 Mar 2018 15:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-03-05:/build-a-pelican-powered-blog-like-a-pro.html</guid><category>Miscellaneous</category><category>資料科學</category><category>data-science</category><category>日誌</category></item><item><title>BeautifulSoup 筆記</title><link>https://leemeng.tw/beautifulsoup-cheat-sheet.html</link><description>&lt;p&gt;Beautifulsoup 是一個可以幫助我們 parse HTML 的函式庫，不管是在寫爬蟲還是做 HTML 檔案的處理都很方便。這篇主要紀錄使用 beautifulsoup 時常用的指令。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Fri, 02 Mar 2018 15:34:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-03-02:/beautifulsoup-cheat-sheet.html</guid><category>Miscellaneous</category><category>python</category><category>beautifulsoup</category><category>html</category></item><item><title>Seaborn 筆記</title><link>https://leemeng.tw/seaborn-cheat-sheet.html</link><description>&lt;p&gt;這篇記錄我在使用 seaborn 做資料分析還有 visualization 時常用的 code. 一般慣例會把 seaborn 更名成 sns for reference.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Fri, 02 Mar 2018 00:10:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-03-02:/seaborn-cheat-sheet.html</guid><category>Miscellaneous</category><category>python</category><category>seaborn</category><category>資料視覺化</category></item><item><title>SQLite 筆記</title><link>https://leemeng.tw/sqlite-note.html</link><description>&lt;p&gt;這篇主要紀錄使用 SQLite shell 下 SQL Query 的指令。基本上在 shell 裡頭都是用 dot-command, 使用 .help 可以顯示所有可用的指令。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Fri, 23 Feb 2018 22:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2018-02-23:/sqlite-note.html</guid><category>Miscellaneous</category><category>SQL</category><category>SQLite</category><category>資料庫</category></item><item><title>Find Word Semantic by Using Word2vec in TensorFlow</title><link>https://leemeng.tw/find-word-semantic-by-using-word2vec-in-tensorflow.html</link><description>&lt;p&gt;Naive Word2vec implementation using Tensorflow&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Sat, 30 Sep 2017 18:30:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2017-09-30:/find-word-semantic-by-using-word2vec-in-tensorflow.html</guid><category>Deep Learning</category><category>Python</category><category>TensorFlow</category><category>Word2Vec</category><category>NLP</category><category>VSM</category></item><item><title>Simple Convolutional Neural Network using TensorFlow</title><link>https://leemeng.tw/simple-convolutional-neural-network-using-tensorflow.html</link><description>&lt;p&gt;The goal here is to practice building convolutional neural networks to classify notMNIST characters using TensorFlow. As image size become bigger and bigger, it become unpractical to train fully-connected NN because there will be just too many parameters and thus the model will overfit very soon. And CNN solve this problem by weight sharing. We will start by building a CNN with two convolutional layers connected by a fully connected layer and then try also pooling layer and other thing to improve the model performance.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Tue, 26 Sep 2017 18:30:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2017-09-26:/simple-convolutional-neural-network-using-tensorflow.html</guid><category>Deep Learning</category><category>Python</category><category>Tensorflow</category><category>Deep Learning</category><category>Convolutional Neural Network</category><category>CNN</category><category>Deep Learning by Google</category><category>Machine Learning Engineer by kaggle</category><category>Udacity</category></item><item><title>Regularization for Multi-layer Neural Networks in Tensorflow</title><link>https://leemeng.tw/regularization-for-multi-layer-neural-networks-in-tensorflow.html</link><description>&lt;p&gt;The goal of this assignment is to explore regularization techniques.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Mon, 25 Sep 2017 16:00:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2017-09-25:/regularization-for-multi-layer-neural-networks-in-tensorflow.html</guid><category>Deep Learning</category><category>Tensorflow</category><category>Python</category><category>Deep Learning</category><category>Regularization</category><category>Deep Learning by Google</category><category>Machine Learning Engineer by kaggle</category><category>Udacity</category></item><item><title>Using TensorFlow to Train a Shallow NN with Stochastic Gradient Descent</title><link>https://leemeng.tw/using-tensorflow-to-train-a-shallow-nn-with-stochastic-gradient-descent.html</link><description>&lt;p&gt;The goal here is to progressively train deeper and more accurate models using TensorFlow. We will first load the notMNIST dataset which we have done data cleaning. For the classification problem, we will first train two logistic regression models use simple gradient descent, stochastic gradient descent (SGD) respectively for optimization to see the difference between these optimizers.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Thu, 21 Sep 2017 23:50:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2017-09-21:/using-tensorflow-to-train-a-shallow-nn-with-stochastic-gradient-descent.html</guid><category>Deep Learning</category><category>Python</category><category>TensorFlow</category><category>Deep Learning</category><category>Neural Networks</category><category>Optimization</category><category>NotMNIST</category><category>Machine Learning</category><category>Image Recognition</category><category>SGD</category><category>Gradient Descent</category><category>Deep Learning by Google</category><category>Machine Learning Engineer by kaggle</category><category>Udacity</category></item><item><title>Simple Image Recognition using NotMNIST dataset</title><link>https://leemeng.tw/simple-image-recognition-using-notmnist-dataset.html</link><description>&lt;p&gt;Today we're going to do some simple image recogintion using NotMNIST dataset. But before creating model for prediction, it's more important to explore, clean and normalize our dataset in order to make the learning go smoother when we actually build predictive models.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Tue, 19 Sep 2017 20:30:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2017-09-19:/simple-image-recognition-using-notmnist-dataset.html</guid><category>Machine learning</category><category>Python</category><category>Matplotlib</category><category>Data Preprocessing</category><category>Data Cleaning</category><category>NotMNIST</category><category>Sklearn</category><category>Machine Learning</category><category>Image Recognition</category><category>Udacity</category></item><item><title>Purpose of this blog</title><link>https://leemeng.tw/purpose-of-this-blog.html</link><description>&lt;p&gt;第一篇文章做一點 blog 的簡介，打算把自己在學 data science 還有 machine learning 過程中寫的筆記還有在 MOOC 上課的 code (主要是 jupyter notebook) 記錄下來方便自己以後搜尋。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lee Meng</dc:creator><pubDate>Sun, 17 Sep 2017 12:30:00 +0900</pubDate><guid isPermaLink="false">tag:leemeng.tw,2017-09-17:/purpose-of-this-blog.html</guid><category>Miscellaneous</category><category>python</category><category>pelican</category><category>資料科學</category><category>blogging</category></item></channel></rss>