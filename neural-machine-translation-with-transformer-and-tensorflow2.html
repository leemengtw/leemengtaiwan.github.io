<!DOCTYPE html>
<!--[if lt IE 9 ]><html class="no-js oldie" lang="zh-hant-tw"> <![endif]-->
<!--[if IE 9 ]><html class="no-js oldie ie9" lang="zh-hant-tw"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<html class="no-js" lang="zh-hant-tw">
<!--<![endif]-->

<head>

    <!--- basic page needs
    ================================================== -->
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="author" content="Lee Meng" />
<title>LeeMeng - 淺談神經機器翻譯 & 用 Transformer 與 TensorFlow 2 英翻中</title>
    <!--- article-specific meta data
    ================================================== -->
        <meta name="description" content="本文分為兩大部分。前半將帶讀者簡單回顧 Seq2Seq 模型、自注意力機制以及 Transformer 等近年在機器翻譯領域裡頭的重要發展與概念；後半段則將帶著讀者實作一個可以將英文句子翻譯成中文的 Transformer。透過瞭解其背後運作原理，讀者將能把類似的概念應用到如圖像描述、閱讀理解以及語音辨識等各式各樣的機器學習任務之上。" />
        <meta name="keywords" content="自然語言處理, NLP, Tensorflow" />
        <meta name="tags" content="自然語言處理" />
        <meta name="tags" content="NLP" />
        <meta name="tags" content="Tensorflow" />


    <!--- Open Graph Object metas
    ================================================== -->
        <meta property="og:image" content="https://leemeng.tw/theme/images/background/Tour_de_babel.jpg" />
        <meta property="og:type" content="article" />
        <meta property="og:url" content="https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html" />
        <meta property="og:title" content="淺談神經機器翻譯 & 用 Transformer 與 TensorFlow 2 英翻中" />
        <meta property="og:description" content="本文分為兩大部分。前半將帶讀者簡單回顧 Seq2Seq 模型、自注意力機制以及 Transformer 等近年在機器翻譯領域裡頭的重要發展與概念；後半段則將帶著讀者實作一個可以將英文句子翻譯成中文的 Transformer。透過瞭解其背後運作原理，讀者將能把類似的概念應用到如圖像描述、閱讀理解以及語音辨識等各式各樣的機器學習任務之上。" />

    <!-- mobile specific metas
    ================================================== -->
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- CSS
    ================================================== -->
    <!--for customized css in individual page-->
        <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/bootstrap.min.css">

    <!--for showing toc navigation which slide in from left-->
        <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/toc-nav.css">

    <!--for responsive embed youtube video-->
        <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/embed_youtube.css">

    <!--for prettify dark-mode result-->
        <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/darkmode.css">

    <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/base.css">
    <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/vendor.css">
    <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/main.css">
    <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/ipython.css">
    <link rel="stylesheet" type="text/css" href='https://leemeng.tw/theme/css/progress-bar.css' />


    <!--TiqueSearch-->
    <link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400">
    <link rel="stylesheet" href="https://leemeng.tw/theme/tipuesearch/css/normalize.css">
    <link rel="stylesheet" href="https://leemeng.tw/theme/tipuesearch/css/tipuesearch.css">

    <!-- script
    ================================================== -->
    <script src="https://leemeng.tw/theme/js/modernizr.js"></script>
    <script src="https://leemeng.tw/theme/js/pace.min.js"></script>


    <!-- favicons
    ================================================== -->
    <link rel="shortcut icon" href="../theme/images/favicon.ico" type="image/x-icon"/>
    <link rel="icon" href="../theme/images/favicon.ico" type="image/x-icon"/>

<!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-106559980-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments)};
  gtag('js', new Date());

  gtag('config', 'UA-106559980-1');
</script>



</head>


<body id="top">

    <!-- header
    ================================================== -->
    <header class="s-header">

        <div class="header-logo">
            <a class="site-logo" href="../index.html"><img src="https://leemeng.tw/theme/images/logo.png" alt="Homepage"></a>
        </div>
<!--navigation bar ref: http://jinja.pocoo.org/docs/2.10/tricks/-->



<nav class="header-nav-wrap">
    <ul class="header-nav">
        <li>
            <a href="../index.html#home">Home</a>
        </li>
        <li>
            <a href="../index.html#about">About</a>
        </li>
        <li>
            <a href="../index.html#projects">Projects</a>
        </li>
        <li class="current">
            <a href="../blog.html">Blog</a>
        </li>
        <li>
            <a href="https://demo.leemeng.tw">Demo</a>
        </li>
        <li>
            <a href="../books.html">Books</a>
        </li>
        <li>
            <a href="../index.html#contact">Contact</a>
        </li>

    </ul>

    <!--<div class="search-container">-->
        <!--<form action="../search.html">-->
            <!--<input type="text" placeholder="Search.." name="search">-->
            <!--<button type="submit"><i class="im im-magnifier" aria-hidden="true"></i></button>-->
        <!--</form>-->
    <!--</div>-->

</nav>
        <a class="header-menu-toggle" href="#0"><span>Menu</span></a>

    </header> <!-- end s-header -->



    <!--TOC navigation displayed when clicked from left-navigation button-->
    <div id="tocNav" class="overlay" onclick="closeTocNav()">
      <div class="overlay-content">
        <div id="toc"><ul><li><a class="toc-href" href="#" title="淺談神經機器翻譯 &amp; 用 Transformer 與 TensorFlow 2 英翻中">淺談神經機器翻譯 &amp; 用 Transformer 與 TensorFlow 2 英翻中</a><ul><li><a class="toc-href" href="#一些你需先具備的基礎知識" title="一些你需先具備的基礎知識">一些你需先具備的基礎知識</a></li><li><a class="toc-href" href="#機器翻譯近代史" title="機器翻譯近代史">機器翻譯近代史</a><ul><li><a class="toc-href" href="#統計機器翻譯：基於短語的翻譯" title="統計機器翻譯：基於短語的翻譯">統計機器翻譯：基於短語的翻譯</a></li><li><a class="toc-href" href="#神經機器翻譯：Encoder-Decoder-模型" title="神經機器翻譯：Encoder-Decoder 模型">神經機器翻譯：Encoder-Decoder 模型</a></li><li><a class="toc-href" href="#Encoder-Decoder-模型-+-注意力機制" title="Encoder-Decoder 模型 + 注意力機制">Encoder-Decoder 模型 + 注意力機制</a></li><li><a class="toc-href" href="#Transformer：Seq2Seq-模型-+-自注意力機制" title="Transformer：Seq2Seq 模型 + 自注意力機制">Transformer：Seq2Seq 模型 + 自注意力機制</a></li></ul></li><li><a class="toc-href" href="#師傅引進門，修行在個人_1" title="師傅引進門，修行在個人">師傅引進門，修行在個人</a></li><li><a class="toc-href" href="#11-個重要-Transformer-概念回顧" title="11 個重要 Transformer 概念回顧">11 個重要 Transformer 概念回顧</a></li><li><a class="toc-href" href="#安裝函式庫並設置環境" title="安裝函式庫並設置環境">安裝函式庫並設置環境</a></li><li><a class="toc-href" href="#建立輸入管道" title="建立輸入管道">建立輸入管道</a><ul><li><a class="toc-href" href="#下載並準備資料集" title="下載並準備資料集">下載並準備資料集</a></li><li><a class="toc-href" href="#切割資料集" title="切割資料集">切割資料集</a></li><li><a class="toc-href" href="#建立中文與英文字典" title="建立中文與英文字典">建立中文與英文字典</a></li><li><a class="toc-href" href="#前處理數據" title="前處理數據">前處理數據</a></li></ul></li><li><a class="toc-href" href="#理解-Transformer-之旅：跟著多維向量去冒險_1" title="理解 Transformer 之旅：跟著多維向量去冒險">理解 Transformer 之旅：跟著多維向量去冒險</a><ul><li><a class="toc-href" href="#視覺化原始句子" title="視覺化原始句子">視覺化原始句子</a></li><li><a class="toc-href" href="#視覺化-3-維詞嵌入張量" title="視覺化 3 維詞嵌入張量">視覺化 3 維詞嵌入張量</a></li><li><a class="toc-href" href="#遮罩：Transformer-的祕密配方" title="遮罩：Transformer 的祕密配方">遮罩：Transformer 的祕密配方</a></li><li><a class="toc-href" href="#Scaled-dot-product-attention：一種注意函式" title="Scaled dot product attention：一種注意函式">Scaled dot product attention：一種注意函式</a></li><li><a class="toc-href" href="#直觀理解遮罩在注意函式中的效果" title="直觀理解遮罩在注意函式中的效果">直觀理解遮罩在注意函式中的效果</a></li><li><a class="toc-href" href="#Multi-head-attention：你看你的，我看我的" title="Multi-head attention：你看你的，我看我的">Multi-head attention：你看你的，我看我的</a></li></ul></li><li><a class="toc-href" href="#打造-Transformer：疊疊樂時間_1" title="打造 Transformer：疊疊樂時間">打造 Transformer：疊疊樂時間</a><ul><li><a class="toc-href" href="#Position-wise-Feed-Forward-Networks" title="Position-wise Feed-Forward Networks">Position-wise Feed-Forward Networks</a></li><li><a class="toc-href" href="#Encoder-layer：Encoder-小弟" title="Encoder layer：Encoder 小弟">Encoder layer：Encoder 小弟</a></li><li><a class="toc-href" href="#Decoder-layer：Decoder-小弟" title="Decoder layer：Decoder 小弟">Decoder layer：Decoder 小弟</a></li><li><a class="toc-href" href="#Positional-encoding：神奇數字" title="Positional encoding：神奇數字">Positional encoding：神奇數字</a></li><li><a class="toc-href" href="#Encoder" title="Encoder">Encoder</a></li><li><a class="toc-href" href="#Decoder" title="Decoder">Decoder</a></li><li><a class="toc-href" href="#第一個-Transformer" title="第一個 Transformer">第一個 Transformer</a></li></ul></li><li><a class="toc-href" href="#定義損失函數與指標_1" title="定義損失函數與指標">定義損失函數與指標</a></li><li><a class="toc-href" href="#設置超參數" title="設置超參數">設置超參數</a></li><li><a class="toc-href" href="#設置-Optimizer" title="設置 Optimizer">設置 Optimizer</a></li><li><a class="toc-href" href="#實際訓練以及定時存檔" title="實際訓練以及定時存檔">實際訓練以及定時存檔</a></li><li><a class="toc-href" href="#實際進行英翻中" title="實際進行英翻中">實際進行英翻中</a></li><li><a class="toc-href" href="#視覺化注意權重" title="視覺化注意權重">視覺化注意權重</a></li><li><a class="toc-href" href="#在你離開之前" title="在你離開之前">在你離開之前</a></li></ul></li></ul></div>
      </div>
    </div>

    <!--custom images with icon shown on left nav-->
    <!--the details are set in `pelicanconf.py` as `LEFT_NAV_IMAGES`-->

            <div id="leftNavImage_transformer" class="overlay" style="background-color:white" onclick="closeLeftNavImage('leftNavImage_transformer')">
              <div class="overlay-content">
                <img src="https://leemeng.tw/theme/images/left-nav/transformer.jpg">
              </div>
            </div>


    <article class="blog-single">

        <!-- page header/blog hero, use custom cover image if available
        ================================================== -->
            <div class="page-header page-header--single page-hero" style="background-image:url(https://leemeng.tw/theme/images/background/Tour_de_babel.jpg)">

            <div class="row page-header__content narrow">
                <article class="col-full">
                    <div class="page-header__info">
                        <div class="page-header__cat">
                            <a href="https://leemeng.tw/tag/zi-ran-yu-yan-chu-li.html" rel="tag">自然語言處理</a>
                            <a href="https://leemeng.tw/tag/nlp.html" rel="tag">NLP</a>
                            <a href="https://leemeng.tw/tag/tensorflow.html" rel="tag">Tensorflow</a>
                        </div>
                    </div>
                    <h1 class="page-header__title">
                        <a href="https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html" title="">
                            淺談神經機器翻譯 & 用 Transformer 與 TensorFlow 2 英翻中
                        </a>
                    </h1>
                    <ul class="page-header__meta">
                        <li class="date">2019-06-17 (Mon)</li>
                        <li class="page-view">
                            42,984 views
                        </li>
                    </ul>

                </article>
            </div>

        </div> <!-- end page-header -->

        <div class="KW_progressContainer">
            <div class="KW_progressBar"></div>
        </div>

        <div class="row blog-content" style="position: relative">
<div id="left-navigation">

    <div id="search-wrap">
        <i class="im im-magnifier" aria-hidden="true"></i>
        <div id="search">
            <form action="../search.html">
            <div class="tipue_search_right"><input type="text" name="q" id="tipue_search_input" pattern=".{2,}" title="想搜尋什麼呢？（請至少輸入兩個字）" required></div>
            </form>
        </div>
    </div>

    <div id="toc-wrap">
        <a title="顯示/隱藏 文章章節">
            <i class="im im-menu" aria-hidden="true" onclick="toggleTocNav()"></i>
        </a>
    </div>

    <div id="social-wrap" style="cursor: pointer">
        <a class="open-popup" title="訂閱最新文章">
            <i class="im im-newspaper-o" aria-hidden="true"></i>
        </a>
    </div>
    <div id="social-wrap">
        <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html" target="_blank" title="分享到 Facebook">
            <i class="im im-facebook" aria-hidden="true"></i>
        </a>
    </div>
    <div id="social-wrap">
        <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A//leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html&title=%E6%B7%BA%E8%AB%87%E7%A5%9E%E7%B6%93%E6%A9%9F%E5%99%A8%E7%BF%BB%E8%AD%AF%20%26%20%E7%94%A8%20Transformer%20%E8%88%87%20TensorFlow%202%20%E8%8B%B1%E7%BF%BB%E4%B8%AD&summary=%E6%9C%AC%E6%96%87%E5%88%86%E7%82%BA%E5%85%A9%E5%A4%A7%E9%83%A8%E5%88%86%E3%80%82%E5%89%8D%E5%8D%8A%E5%B0%87%E5%B8%B6%E8%AE%80%E8%80%85%E7%B0%A1%E5%96%AE%E5%9B%9E%E9%A1%A7%20Seq2Seq%20%E6%A8%A1%E5%9E%8B%E3%80%81%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A9%9F%E5%88%B6%E4%BB%A5%E5%8F%8A%20Transformer%20%E7%AD%89%E8%BF%91%E5%B9%B4%E5%9C%A8%E6%A9%9F%E5%99%A8%E7%BF%BB%E8%AD%AF%E9%A0%98%E5%9F%9F%E8%A3%A1%E9%A0%AD%E7%9A%84%E9%87%8D%E8%A6%81%E7%99%BC%E5%B1%95%E8%88%87%E6%A6%82%E5%BF%B5%EF%BC%9B%E5%BE%8C%E5%8D%8A%E6%AE%B5%E5%89%87%E5%B0%87%E5%B8%B6%E8%91%97%E8%AE%80%E8%80%85%E5%AF%A6%E4%BD%9C%E4%B8%80%E5%80%8B%E5%8F%AF%E4%BB%A5%E5%B0%87%E8%8B%B1%E6%96%87%E5%8F%A5%E5%AD%90%E7%BF%BB%E8%AD%AF%E6%88%90%E4%B8%AD%E6%96%87%E7%9A%84%20Transformer%E3%80%82%E9%80%8F%E9%81%8E%E7%9E%AD%E8%A7%A3%E5%85%B6%E8%83%8C%E5%BE%8C%E9%81%8B%E4%BD%9C%E5%8E%9F%E7%90%86%EF%BC%8C%E8%AE%80%E8%80%85%E5%B0%87%E8%83%BD%E6%8A%8A%E9%A1%9E%E4%BC%BC%E7%9A%84%E6%A6%82%E5%BF%B5%E6%87%89%E7%94%A8%E5%88%B0%E5%A6%82%E5%9C%96%E5%83%8F%E6%8F%8F%E8%BF%B0%E3%80%81%E9%96%B1%E8%AE%80%E7%90%86%E8%A7%A3%E4%BB%A5%E5%8F%8A%E8%AA%9E%E9%9F%B3%E8%BE%A8%E8%AD%98%E7%AD%89%E5%90%84%E5%BC%8F%E5%90%84%E6%A8%A3%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E4%BB%BB%E5%8B%99%E4%B9%8B%E4%B8%8A%E3%80%82&source=https%3A//leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html" target="_blank" title="分享到 LinkedIn">
            <i class="im im-linkedin" aria-hidden="true"></i>
        </a>
    </div>
    <div id="social-wrap">
        <a href="https://twitter.com/intent/tweet?text=%E6%B7%BA%E8%AB%87%E7%A5%9E%E7%B6%93%E6%A9%9F%E5%99%A8%E7%BF%BB%E8%AD%AF%20%26%20%E7%94%A8%20Transformer%20%E8%88%87%20TensorFlow%202%20%E8%8B%B1%E7%BF%BB%E4%B8%AD&url=https%3A//leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html&hashtags=zi-ran-yu-yan-chu-li,nlp,tensorflow" target="_blank" title="分享到 Twitter">
            <i class="im im-twitter" aria-hidden="true"></i>
        </a>
    </div>


    <!--custom images with icon shown on left nav-->
            <div id="left-nav-image-wrap-transformer">
                <a title="顯示/隱藏 Transformer 架構圖">
                    <i class="im im-picture-o" aria-hidden="true" onclick="toggleLeftNavImage('leftNavImage_transformer')"></i>
                </a>
            </div>


</div>

            <div class="col-full blog-content__main">

                <div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<style>
   pre {
      overflow-x: auto;
      word-wrap: break-word;
   }
</style>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        那時，全世界的語言都一樣。人們說：『來吧，我們要建一座塔，塔頂通天，為了揚我們的名，免得我們被分散到世界各地。』耶和華說：『看哪！他們成爲一樣的人民、用同樣的語言。如今既蓋起塔來，以後就沒有他們無法完成的事情了。我們下去！在那裏變亂他們的口音，使他們的言語彼此不通。』
                        <br/>
<span style="float:right;margin-right: 1.5rem">─ 《創世記》第十一章</span>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>這是聖經中著名的<a href="https://zh.wikipedia.org/wiki/%E5%B7%B4%E5%88%A5%E5%A1%94">巴別塔</a>橋段，用來解釋為何當今世上有那麼多種語言。當年的上帝或許過於杞人憂天，但近年多虧了<a href="https://zh.wikipedia.org/zh-hant/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">深度學習</a>，<a href="https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91">機器翻譯</a>的快速發展讓人不禁覺得，或許巴別塔很快就不再只是虛幻傳說了。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/google-translate.jpg" style="mix-blend-mode: initial;">
<source src="https://leemeng.tw/images/transformer/google-translate.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        以往被視為非常困難的中 -&gt; 英翻譯如今在深度學習的加持下也有不錯的水準
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>機器翻譯的研究之所以如此重要且迷人，是因為它將有機會讓未來任何人都不受語言的限制，獲得世界上任何他或她想要的資訊與知識。</p>
<p>在這篇文章的前半部分，我們會先花點時間來回顧<a href="https://en.wikipedia.org/wiki/Neural_machine_translation">神經機器翻譯</a>裡頭的一些重要概念。接著在具備這些概念以及<a href="#%E5%B8%AB%E5%82%85%E5%BC%95%E9%80%B2%E9%96%80%EF%BC%8C%E4%BF%AE%E8%A1%8C%E5%9C%A8%E5%80%8B%E4%BA%BA">其他背景知識</a>的前提之下，利用最新的 <a href="https://www.tensorflow.org/">TensorFlow 2</a> 來實作一個可以將英文句子翻譯成中文的神經網路架構：<a href="https://www.tensorflow.org/beta/tutorials/text/transformer">Transformer</a>。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/transformer/transformer-high-level-view.png" style="mix-blend-mode: initial;"/>
</center>
<center>
                        利用 Transformer 將法文句子翻譯成英文
                        （<a href="http://jalammar.github.io/illustrated-transformer/" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>這是一個非常簡化的示意圖。Transformer 實際上是一種基於自注意力機制的 <a href="https://youtu.be/ZjfjPzXw6og?t=3208">Seq2Seq 模型</a>，近年在<a href="https://paperswithcode.com/task/image-captioning">圖像描述</a>、<a href="https://zh.wikipedia.org/wiki/%E8%81%8A%E5%A4%A9%E6%A9%9F%E5%99%A8%E4%BA%BA">聊天機器人</a>、<a href="https://zh.wikipedia.org/zh-hant/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB">語音辨識</a>以及機器翻譯等各大領域大發異彩。但因為其相對複雜，到現在還是有種現象：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        了解 Transformer 相關技術的人已經用了好一陣子且用得很開心，不知道的人還是不知道。
                        <br/>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>當然這並不僅限於 Transformer，因為深度學習牽涉的研究範圍實在太廣了。透過這篇文章，我希望能幫助你開始了解神經機器翻譯以及 Transformer 的相關知識。</p>
<p>當我們完成實作並訓練出一個 Transformer 以後，除了可以英翻中以外，我們還能清楚地了解其是如何利用強大的<a href="https://www.youtube.com/watch?v=jd9DtlR90ak&amp;feature=youtu.be">注意力機制</a>（我們在 <a href="#Encoder-Decoder-模型-+-注意力機制">Encoder-Decoder 模型 + 注意力機制</a>一節會仔細探討此概念）來做到精準且自然的翻譯。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/transformer/en-to-ch-attention-map.png"/>
</center>
<center>
                        Transformer 在將英文句子翻譯成中文時會「關注」需要注意的英文詞彙來生成對應的中文字詞
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>除了翻譯出來的中文正確無誤以外，從上圖你可以發現很有趣的現象。</p>
<p>給定左側的英文，Transformer 在生成其對應的中文翻譯時都會給每個英文詞彙不同的「注意程度」。小方格越亮則代表模型在生成某中文字時放越多的注意力在左側對應的英文詞彙上。</p>
<p>仔細看你會發現這個已經訓練好的 Transformer 在翻譯：</p>
<ul>
<li>「必」、「須」時會關注「must」</li>
<li>「希」、「望」時會關注「hope」</li>
<li>「公」、「民」時會關注「citizens」</li>
</ul>
<p>乍看之下好像稀鬆平常，但事實上我們在訓練模型時並不會告訴它這些詞彙之間的對應關係或是任何語言學的知識。我們就只是餵給它多組相同意思的中英句子，並讓它自己學會怎麼做翻譯。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        好黑魔法，不學嗎？
                        <br/>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在英翻中的情境下，神經網路要做的事情就是讀入左側的英文句子，接著生成右側的中文句子（繁中對英文的翻譯資料集稀少，此文將以簡體為例）</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/transformer/en-zh-training-sentences.jpg" style="mix-blend-mode: initial;"/>
</center>
<center>
                        訓練資料是多組相同語義的成對中英句子（當然仍需前處理）
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="一些你需先具備的基礎知識">一些你需先具備的基礎知識<a class="anchor-link" href="#一些你需先具備的基礎知識">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>我在文中會盡量言簡意賅地介紹所有你需要了解的深度學習概念，並附上相關連結供你參考。但就像在<a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html">天龍八部</a>或是眾多武俠小說都有提過的重要準則：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        武功修習有先後順序，勿求一步登天。
                        <br/>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>儘管在 <a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf">2017 年就已被提出</a>，本文即將探討並實作的 <a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf">Transformer</a> 仍算是相當進階的神經網路架構。因此具備以下的基礎知識能幫助你更順利地理解本文內容：</p>
<ul>
<li>一點點<a href="https://demo.leemeng.tw/">卷積神經網路</a>的概念</li>
<li>清楚理解<a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html">循環神經網路</a>的運算方式</li>
<li>基本的<a href="http://research.sinica.edu.tw/nlp-natural-language-processing-chinese-knowledge-information/">自然語言處理</a>知識</li>
<li>基本的<a href="https://youtu.be/uUrt8xgdMbs?list=PLJV_el3uVTsNmr39gwbyV-0KjULUsN7fW">線性代數</a>如矩陣相乘運算</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/transformer/nlp-intro.jpg" style="mix-blend-mode: initial;"/>
</center>
<center>
                        中研院這篇文章清楚地說明了自然語言處理在中文上的研究與應用
                        （圖片來源：<a href="http://research.sinica.edu.tw/nlp-natural-language-processing-chinese-knowledge-information/" target="_blank">研之有物</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>希望這樣的要求沒把你嚇跑，因為事實上你大約需要好幾倍的相關知識來成功實作 Transformer。<a href="#%E5%B8%AB%E5%82%85%E5%BC%95%E9%80%B2%E9%96%80%EF%BC%8C%E4%BF%AE%E8%A1%8C%E5%9C%A8%E5%80%8B%E4%BA%BA">儘管在實作前你會看到一些額外要求</a>，本文的前半部分還是相當平易近人的，還請放心閱讀。</p>
<p>當你想要深入了解某些細節的時候，可以參考這節附上的連結或是文內說明概念時附上的圖片來源。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        想更深入了解文中講述的各種概念，點擊相關的「圖片來源」就對了。
                        <br/>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>前言很長，但好戲才在後頭。如果你已經準備好進入神經機器翻譯的世界的話，現在就讓我們正式開始這趟旅程吧！</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="機器翻譯近代史">機器翻譯近代史<a class="anchor-link" href="#機器翻譯近代史">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>鑑往知來。了解一點機器翻譯的歷史以及 Transformer 是怎麼跑出來的會對實作很有幫助。</p>
<p>機器翻譯（<strong>M</strong>achine <strong>T</strong>ranslation）本身的概念<a href="https://zh.wikipedia.org/zh-tw/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91#%E6%AD%B7%E5%8F%B2">最早可追溯到 17 世紀</a>。自從那開始，人們嘗試並研究了各式各樣的方法，寫了一大堆規則、蒐集了數以萬計的翻譯結果來嘗試自動化翻譯。隨著時代演進，我們有了：</p>
<ul>
<li>基於規則的機器翻譯 RBMT</li>
<li>基於範例的機器翻譯 EBMT</li>
<li>統計機器翻譯 SMT</li>
<li>近年的神經機器翻譯 NMT</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/transformer/mt-history.jpg" style="mix-blend-mode: initial;"/>
</center>
<center>
                        近代機器翻譯發展簡史
                        （<a href="https://www.freecodecamp.org/news/a-history-of-machine-translation-from-the-cold-war-to-deep-learning-f1d335ce8b5/" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>很多遠古時代的東西我們不會討論，而 NMT 當然是本文的重點。不過在那之前讓我們非常簡短地看一下 SMT。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="統計機器翻譯：基於短語的翻譯">統計機器翻譯：基於短語的翻譯<a class="anchor-link" href="#統計機器翻譯：基於短語的翻譯">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>機器翻譯的歷史很長，但一直要到 21 世紀初期<a href="https://zh.wikipedia.org/wiki/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91">統計機器翻譯（<strong>S</strong>tatistical <strong>M</strong>achine <strong>T</strong>ranslation，簡稱 SMT）</a>技術成熟以後，機器翻譯的品質才稍微使人滿意。其中最知名的例子當屬 <a href="https://ai.googleblog.com/2006/04/statistical-machine-translation-live.html">Google 在 2006 年發布的 SMT 翻譯系統</a>。</p>
<p>不限於 Google，當時不少最先進的 SMT 系統都採用了<a href="https://en.wikipedia.org/wiki/Statistical_machine_translation#Phrase-based_translation">基於短語的機器翻譯（Phrase-Based MT）</a> 演算法。PBMT 最大的特色是先將來源語言（Source Language）的句子切成短語或是詞彙，接著大致上獨立地將這些詞彙翻譯成目標語言（Target Language）。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/transformer/pbmt.jpg" style="mix-blend-mode: initial;"/>
</center>
<center>
                        基於短語的 SMT（Phrase-Based SMT）
                        （<a href="https://www.freecodecamp.org/news/a-history-of-machine-translation-from-the-cold-war-to-deep-learning-f1d335ce8b5/" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>PBMT 的翻譯結果相較於早年基於規則（Rule-Based）的手法已經進步很多，但仍然需要大量的<a href="https://zh.wikipedia.org/wiki/%E5%B9%B3%E8%A1%8C%E8%AF%AD%E6%96%99">平行語料</a>、對齊語料來取得較好的結果。且因為是以短語為單位在做翻譯，這些短語拼湊出來的句子仍然不夠自然。</p>
<p>如果你跟我一樣有用過早年的 Google 翻譯，應該還能隱約記得當年那些充斥著「機械感」的翻譯結果。</p>
<p>（如果你有當年 Google 翻譯結果的截圖的話歡迎提供）</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="神經機器翻譯：Encoder-Decoder-模型">神經機器翻譯：Encoder-Decoder 模型<a class="anchor-link" href="#神經機器翻譯：Encoder-Decoder-模型">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>顧名思義，神經機器翻譯 NMT 即代表使用<a href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">類神經網路（Neural Network）</a>來做機器翻譯。</p>
<p>不管是英文、法文還是中文，一個自然語言的句子基本上可以被視為一個有時間順序的序列數據（Sequence Data）。而<a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E6%9C%89%E8%A8%98%E6%86%B6%E7%9A%84%E5%BE%AA%E7%92%B0%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF_1">我們曾提過 RNN 很適合用來處理有時間關係的序列數據</a>。給定一個向量序列，RNN 就是回傳一個一樣長度的向量序列作為輸出。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/nlp-kaggle-intro/rnn-animate.gif" style="mix-blend-mode: initial;"/>
</center>
<center>
                        RNN 很適合拿來處理具有時間順序的序列數據（下方的詞在丟入 RNN 前會被轉成詞向量）
                        （<a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E6%9C%89%E8%A8%98%E6%86%B6%E7%9A%84%E5%BE%AA%E7%92%B0%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF_1" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>當我們把來源語言以及目標語言的句子都視為一個獨立的序列以後，機器翻譯事實上就是一個<a href="https://youtu.be/ZjfjPzXw6og">序列生成（Sequence Generation）</a>任務：對一個輸入序列（來源語言）做些有意義的轉換與處理以後，輸出一個新的序列（目標語言）。</p>
<p>而在深度學習時代，我們一般會使用以 RNN 為基礎的 <a href="https://youtu.be/ZjfjPzXw6og?t=3208">Encoder-Decoder 架構（又被稱作 Sequence to Sequence / Seq2Seq 模型）</a>來做序列生成：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/seq2seq-animate.jpg" style="mix-blend-mode: initial;">
<source src="https://leemeng.tw/images/transformer/seq2seq-animate.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        一個以 RNN 為基礎的 Encoder-Decoder / Seq2Seq 模型將法文翻譯成英文的步驟
                        （<a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Seq2Seq 模型裡頭 Encoder 跟 Decoder 是各自獨立的 RNN。Encoder 把輸入的句子做處理後所得到的隱狀態向量（圖中的 <code>Hidden State#3</code>）交給 Decoder 來生成目標語言。</p>
<p>你可以想像兩個語義相同的法英句子雖然使用的語言、語順不一樣，但因為它們有相同的語義，Encoder 在將整個<strong>法文</strong>句子濃縮成一個嵌入空間（Embedding Space）中的向量後，Decoder 能利用隱含在該向量中的語義資訊來重新生成具有相同意涵的<strong>英文</strong>句子。</p>
<p>這樣的模型就像是在模擬人類做翻譯的<a href="https://zh.wikipedia.org/zh-tw/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91#%E7%BF%BB%E8%AD%AF%E6%B5%81%E7%A8%8B">兩個主要過程</a>：</p>
<ul>
<li>（Encoder）解譯來源文字的文意</li>
<li>（Decoder）重新編譯該文意至目標語言</li>
</ul>
<p>當然人類在做翻譯時有更多步驟、也會考慮更多東西，但 Seq2Seq 模型的表現已經很不錯了。</p>
<p>有些人閱讀到這裡可能會問：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        如果我們利用 Seq2Seq 模型將多種語言的句子都轉換到某個嵌入空間裡頭，該空間會長成什麼樣子呢？是相同語言的句子靠得比較近，還是不同語言但擁有同語義的句子會靠得比較近呢？
                        <br/>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>這是一個很好的研究問題。</p>
<p>而如果我們試著把這個問題圖像化，則結果可能長得像這樣：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/transformer/multi-lang-emb.jpg" style="mix-blend-mode: initial;"/>
</center>
<center>
                        大哉問：神經網路將句子轉換完所形成的向量空間比較靠近左邊還是右邊？
                        （<a href="https://youtu.be/ulLx2iPTIcs?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;t=1035" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>圖中的點代表不同句子，不同顏色則代表不同語言。如果結果是左邊，代表神經網路並沒有創出一個「語義」空間，而只是把不同語言都投射到該嵌入空間裡頭的不同位置，接著才在該空間裡進行不同語言之間的轉換（中轉英、英轉法 etc.）。</p>
<p>我們比較想要的是右邊的情況：無關語言，只要句子的語義接近，彼此的距離就相近的語義空間。</p>
<p>而 <a href="https://aclweb.org/anthology/Q17-1024">Google 在 2016 年的研究結果</a>發現，在此空間裡頭語言相異但擁有同語義的句子之間的距離 <code>d1</code>，要比同語言但不同語義的句子之間的距離 <code>d2</code> 要小得多（即  <code>d1 &lt;&lt; d2</code>）。</p>
<p>換句話說，在此空間中同語義的句子會靠得比較近，我們實際得到的空間比較像右邊。</p>
<p>而如果我們將這些句子做 <a href="https://distill.pub/2016/misread-tsne/">t-SNE</a> ，甚至可以得到這樣的結果：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/gnmt-multilingual.jpg" style="mix-blend-mode: initial;">
<source src="https://leemeng.tw/images/transformer/gnmt-multilingual.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        在 Seq2Seq 模型創造出來的「語義」空間裡頭，不同語言但同語義的句子彼此相當接近
                        （<a href="https://projector.tensorflow.org/" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>此研究告訴我們，只要對自然語言做正確的轉換，就能將語言相異但同語義的句子都轉換成彼此距離相近的語義向量，並以此做出好的翻譯。</p>
<p>以下是我隨意挑選出來的一組句子，它們在該空間裡的距離相近：</p>
<div class="highlight"><pre><span></span>英文：
From low-cost pharmacy brand moisturizers to high-priced cosmetics brand moisturizers, competition is fierce.

日文：
低価格の薬品ブランドの保湿剤から高価な百貨店の化粧品ブランドのためには, 競争が激しい

韓文：
싸구려백화점화장품브랜드 moisturizers 에 저렴한약국브랜드 moisturizers 에서 , 경쟁이큰있습니다
</pre></div>
<p>這些句子都代表著類似的意思：「從低價的保濕劑到高價的化妝品牌，競爭都十分激烈」。</p>
<p>如果你想進一步了解這個視覺化結果，可以閱讀 <a href="https://youtu.be/ulLx2iPTIcs?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;t=789">Google Brain 的詳細解說</a>或是上 <a href="https://projector.tensorflow.org/">Embedding Projector</a> 自己試看看。</p>
<p>另外值得注意的是，機器翻譯本身是一種<a href="https://youtu.be/ZjfjPzXw6og?t=2816">有條件的序列生成任務（Conditional Sequence Generation）</a>：給定一個特定的輸入句子（文字序列），依此條件輸出另外一個句子（文字序列）。這跟在<a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html">讓 AI 寫點金庸</a>一文中會隨機生成天龍八部文章的<a href="https://zh.wikipedia.org/wiki/%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B">語言模型（Language Model）</a>是有所差異的：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/lstm-sequence-generation.jpg" style="mix-blend-mode: initial;">
<source src="https://leemeng.tw/images/transformer/lstm-sequence-generation.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        隨機序列生成的例子：一個以 LSTM 實作的簡單語言模型
                        （<a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>一般來說，語言模型可以在不給定任何輸入的情況下生成非常隨機的文字序列；但針對機器翻譯這種有條件的序列生成任務，我們通常希望給定相同輸入，輸出的結果越穩定越好（或是每次都一模一樣）。</p>
<p>我們在<a href="#TODO">實作的時候</a>會看到怎麼達成這件事情。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Encoder-Decoder-模型-+-注意力機制">Encoder-Decoder 模型 + 注意力機制<a class="anchor-link" href="#Encoder-Decoder-模型-+-注意力機制">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>好啦，你現在應該已經了解如何使用 Seq2Seq 模型來做 NMT 了，不過現在讓我們再次複習其運作方式。這次我們把用 RNN 實作的 Encoder / Decoder 在每個時間點做的事情從左到右一字排開：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/seq2seq-unrolled-no-attention.jpg" style="mix-blend-mode: initial;">
<source src="https://leemeng.tw/images/transformer/seq2seq-unrolled-no-attention.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        以 RNN 為基礎的 Seq2Seq 模型做 NMT 的流程
                        （<a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>基本款的 Seq2Seq 模型表現得不錯，但其實有可以改善的地方。你有看出來了嗎？上圖的輸入句子只有 3 個詞彙，但如果我們想輸入一個很長的句子呢？</p>
<p>我們前面曾提過 Seq2Seq 模型裡的一個重要假設是 Encoder 能把輸入句子的語義 / 文本脈絡全都壓縮成<strong>一個</strong>固定維度的語義向量。之後 Decoder 只要利用該向量裡頭的資訊就能重新生成具有相同意義，但不同語言的句子。</p>
<p>但你可以想像當我們只有一個向量的時候，是不太可能把一個很長的句子的所有資訊打包起來的。</p>
<p>這時候怎麼辦呢？</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        與其只把 Encoder 處理完句子產生的最後「一個」向量交給 Decoder 並要求其從中萃取整句資訊，不如將 Encoder 在處理每個詞彙後所生成的「所有」輸出向量都交給 Decoder，讓 Decoder 自己決定在生成新序列的時候要把「注意」放在 Encoder 的哪些輸出向量上面。
                        <br/>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>這事實上就是<a href="https://www.youtube.com/watch?v=jd9DtlR90ak&amp;feature=youtu.be">注意力機制（Attention Mechanism）</a>的中心思想：提供更多資訊給 Decoder，並透過類似資料庫存取的概念，令其自行學會該怎麼提取資訊。兩篇核心論文分別在 <a href="https://arxiv.org/abs/1409.0473">2014 年 9 月</a>及 <a href="https://arxiv.org/abs/1508.04025">2015 年 8 月</a>釋出，概念不難但威力十分強大。</p>
<p>以下就是將注意力機制加到 Seq2Seq 模型後的結果：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/seq2seq-unrolled-with-attention.jpg" style="mix-blend-mode: initial;">
<source src="https://leemeng.tw/images/transformer/seq2seq-unrolled-with-attention.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        注意力機制讓 Decoder 在生成新序列時能查看 Encoder 裡所有可能有用的隱狀態向量
                        （<a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>你可以拉回去跟沒有注意力機制的 Seq2Seq 模型比較一下差異。</p>
<p>現在你會看到 Encoder 把處理完每個詞彙所產生的向量都交給 Decoder 了。且透過注意力機制，Decoder 在生成新序列的每個元素時都能<strong>動態地</strong>考慮自己要看哪些 Encoder 的向量（還有決定從中該擷取多少資訊），因此這種運用注意力機制的 Seq2Seq 架構又被稱作<a href="https://youtu.be/ZjfjPzXw6og?t=3528">動態的條件序列生成（Dynamic Conditional Generation）</a>。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/seq2seq_detail.jpg" style="mix-blend-mode: initial;">
<source src="https://leemeng.tw/images/transformer/seq2seq_detail.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        法翻英時，Decoder 在生成每個英文詞彙時都在 Encoder 的每個輸出向量上放不同的注意程度
                        （<a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>實際構想並證明其有效的研究者們十分厲害，且其概念也挺符合人類直覺的，對吧？</p>
<p>為了方便讀者理解，上面動畫實際上隱藏了一些細節：</p>
<ul>
<li>呈現算好的注意程度而不是計算過程</li>
<li>Encoder / 跟 Decoder 的實際架構</li>
</ul>
<p>既然是深度學習，Encoder / Decoder 一般來說都是由多個 <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">LSTM</a> / <a href="https://en.wikipedia.org/wiki/Gated_recurrent_unit">GRU</a> 等 RNN Layers 所疊起來的。而注意力機制在這種情境下實際的運作方式如下：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/transformer/attention_mechanism_luong.jpg" style="mix-blend-mode: initial;"/>
</center>
<center>
                        英翻法情境下，Decoder 在第一個時間點進行的注意力機制
                        （<a href="https://github.com/tensorflow/nmt#background-on-the-attention-mechanism" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>左右兩邊分別是 Encoder 與 Decoder ，縱軸則是多層的神經網路區塊 / 層。</p>
<p>雖然上張動畫是法翻英（這邊是英翻法），但該動畫也是以一樣的概念將圖中的注意權重（attention weights ）視覺化出來（注意權重和為 1）。</p>
<p>現在讓我們看一下注意力機制實際的計算步驟。在 Decoder 的每個時間點，我們都會進行注意力機制以讓 Decoder 從 Encoder 取得語境資訊：</p>
<ol>
<li>拿 Decoder 當下的紅色隱狀態向量 <code>ht</code> 跟 Encoder 所有藍色隱狀態向量 <code>hs</code> 做比較，利用 <code>score</code> 函式計算出 <code>ht</code> 對每個 <code>hs</code> 的注意程度</li>
<li>以此注意程度為權重，<strong>加權平均</strong>所有 Encoder 隱狀態 <code>hs</code> 以取得上下文向量 <code>context vector</code></li>
<li>將此上下文向量與 Decoder 隱狀態結合成一個注意向量 <code>attention vector</code> 並作為該時間的輸出</li>
<li>該注意向量會作為 Decoder 下個時間點的輸入</li>
</ol>
<p>定義 <code>score</code> 函式的方式不少，現在就先讓我們假設有這麼一個函式。</p>
<p>至此為止，你應該已經能夠看懂注意力機制的計算公式：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/transformer/attention-equation.jpg" style="mix-blend-mode: initial;"/>
</center>
<center>
                        注意力機制前 3 步驟的數學式子
                        （<a href="https://github.com/tensorflow/nmt#background-on-the-attention-mechanism" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>而之所以稱為注意權重（attention weights），是因為注意力機制可以被視為是一個學習來源語言和目標語言<strong>每一個單詞之間關係</strong>的小型神經網路，而這些權重是該神經網路的參數。</p>
<p>我們在<a href="#TODO">後面的章節</a>會實際看到，在訓練還沒開始前，這些權重都是隨機且無意義的。是透過訓練，神經網路才知道該為這些權重賦予什麼值。</p>
<p>你也會發現我在文中提及多次的「注意程度」就是這裡的「注意權重」，而前者是一種擬人化的說法。你可以想像這些權重值讓當下的 Decoder 曉得該放多少關注在 Encoder 個別的隱狀態身上，並依此從它們身上取得上下文資訊（步驟 2）。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        而事實上神經網路並沒有意識，因此也不會有感知層次上的「注意」。它學到的是讓注意力機制產生最好結果的「參數權重」，而不是我們人類想像的「注意程度」。只有人類可以賦予神經網路裡頭的計算意義。
                        <br/>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>有點扯遠了，畢竟這裡應該沒有人文學系的讀者。</p>
<p>讓我們拉回注意力機制。</p>
<p>將此機制加入 Seq2Seq 模型後，NMT 系統的翻譯水準再次起飛。Google 在 2016 年推出的 <a href="https://ai.googleblog.com/2016/09/a-neural-network-for-machine.html">Google Neural Machine Translation system（GNMT）</a> 是一個知名的案例。除了注意力機制以外，GNMT <a href="https://arxiv.org/abs/1609.08144">在 Encoder 跟 Decoder 都採用了多達 8 層的 LSTM 神經網路</a>，讓更多人見識到深度學習的威力。</p>
<p>跟 Google 10 年前推出的 PBMT 系統比起來，翻譯錯誤率平均下降了 60 %。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/nmt-model-fast.jpg" style="mix-blend-mode: initial;">
<source src="https://leemeng.tw/images/transformer/nmt-model-fast.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        利用注意力機制的 GNMT 讓 Decoder 在生成「Knowledge」時能放注意力在 Encoder 處理完「知」與「識」的兩個輸出向量 e0 &amp; e1
                        （<a href="https://ai.googleblog.com/2016/09/a-neural-network-for-machine.html" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>上圖為 GNMT 做中翻英的過程。Encoder 跟 Decoder 之間的線條代表注意力（Attention），線條越粗代表下面的 Decoder 在生成某英文字時越關注上方的某些中文字。模型自己學會在翻譯時該看來源句子中的哪些資訊，很聰明，不是嗎？</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>因為其卓越的翻譯品質，在 GNMT 推出的那段時間，搭配注意力機制的 Seq2Seq 模型基本上就是拿來做 NMT 系統的不二人選。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/transformer/nmt-vs-pbmt.png" style="mix-blend-mode: initial;"/>
</center>
<center>
                        NMT、PBMT 以及人類在中英翻譯時的結果比較
                        （<a href="https://ai.googleblog.com/2016/09/a-neural-network-for-machine.html" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>話說當年 Google 導入 GNMT 時釋出了 8 個語言之間的對應翻譯，<a href="https://blog.google/products/translate/found-translation-more-accurate-fluent-sentences-google-translate/">涵蓋了約 1/3 的世界人口以及超過 35 % 的 Google 翻譯查詢</a>，是機器翻譯發展的一個重要里程碑。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Transformer：Seq2Seq-模型-+-自注意力機制">Transformer：Seq2Seq 模型 + 自注意力機制<a class="anchor-link" href="#Transformer：Seq2Seq-模型-+-自注意力機制">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>好酒沉甕底，萬眾矚目的時刻來了。</p>
<p>標題已經破梗。你已經知道我們將探討本文主角 Transformer，且理論上越後面出來的 BOSS 越強。</p>
<p>但你現在可能在想：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        Seq2Seq 模型搭配注意力機制感覺已經很猛了，難道還有什麼可以改善的嗎？
                        <br/>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>答案是肯定的 Yes。</p>
<p>不過這次問題不是出在 Encoder 跟 Decoder 中間交換的資訊不夠，也不是 Seq2Seq 架構本身有什麼問題，問題是出在我們是用 <strong>RNN</strong> 來實作 Encoder 以及 Decoder。</p>
<p><a href="http://colah.github.io/posts/2015-09-NN-Types-FP/">循環神經網路 RNN</a> 時常被拿來處理序列數據，但其運作方式存在著一個困擾研究者已久的問題：無法有效地平行運算。以一個有 4 個元素的輸入序列為例：</p>
<div class="highlight"><pre><span></span>[a1, a2, a3, a4]
</pre></div>
<p>要獲得最後一個時間點的輸出向量 <code>b4</code> 得把整個輸入序列跑過一遍才行：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/transformer/rnn-vs-self-attn-layer.jpg" style="mix-blend-mode: initial;"/>
</center>
<center>
                        自注意層可以做到跟雙向 RNN 一樣的事情，還可以平行運算
                        （<a href="https://www.youtube.com/watch?v=ugWDIIOHtPA" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://arxiv.org/abs/1706.03762">Google 在 2017 年 6 月的一篇論文：Attention Is All You Need</a> 裡參考了注意力機制，提出了<strong>自</strong>注意力機制（Self-Attention mechanism）。這個機制不只跟 RNN 一樣可以處理序列數據，還可以平行運算。</p>
<p>以剛剛的輸入序列 <code>a[]</code> 為例：</p>
<div class="highlight"><pre><span></span>[a1, a2, a3, a4]
</pre></div>
<p>一個自注意層（Self-Attention Layer）可以利用矩陣運算在等同於 RNN 的一個時間點內就回傳所有 <code>bi</code> ，且每個 <code>bi</code> 都包含了整個輸入序列的資訊。相比之下，RNN 得經過 4 個時間點依序看過 <code>[a1, a2, a3, a4]</code> 以後才能取得序列中最後一個元素的輸出 <code>b4</code> 。</p>
<p>雖然我們還沒講到實際的運作過程，但在給定一個輸入序列的情境下，自注意力機制的基本精神就是：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        在建立序列中每個元素的 repr. 時，同時去「注意」並擷取同個序列中其他元素的語義資訊。接著將這些語義資訊合併成上下文資訊並當作自己的 repr. 回傳。
                        <br/>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>repr. 為 <a href="https://dictionary.cambridge.org/zht/%E8%A9%9E%E5%85%B8/%E8%8B%B1%E8%AA%9E-%E6%BC%A2%E8%AA%9E-%E7%B9%81%E9%AB%94/representation">representation</a> 縮寫，在本文的機器翻譯情境裡頭，其意味著可以用來描述某個詞彙、句子意涵的多維實數張量。</p>
<p>雖然我們一直強調自注意力機制的平行能力，如果你還記得我們在<a href="#Encoder-Decoder-模型-+-注意力機制">上一節</a>講述的注意力機制，就會發現在 Seq2Seq 架構裡頭自注意力機制跟注意力機制講的根本是同樣一件事情：</p>
<ul>
<li>注意力機制讓 Decoder 在生成輸出元素的 repr. 時關注 Encoder 的輸出序列，從中獲得上下文資訊</li>
<li>自注意力機制讓 Encoder 在生成輸入元素的 repr. 時關注自己序列中的其他元素，從中獲得上下文資訊</li>
<li>自注意力機制讓 Decoder 在生成輸出元素的 repr. 時關注自己序列中的其他元素，從中獲得上下文資訊</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>我們發現一個非常重要的模式：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        注意力機制跟自注意力機制都是讓序列 q 關注序列 k 來將上下文資訊 v 匯總到序列 q 的 repr. 裡頭，只是使用的序列不同。
                        <br/>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>這也是為何<a href="#Scaled-dot-product-attention：一種注意函式">在後面實作時我們只需要一個注意函式</a>就好了。總之透過新設計的自注意力機制以及原有的注意力機制，<a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need 論文</a>作者們打造了一個完全不需使用 RNN 的 Seq2Seq 模型：Transformer。以下是 Transformer 中非常簡化的 Encoder-Decoder 版本，讓我們找找哪邊用到了（自）注意力機制：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/transformer/Transformer_decoder.png" style="mix-blend-mode: initial;"/>
</center>
<center>
                        在 Transformer 裡頭共有 3 個地方用到（自）注意力機制
                        （<a href="http://jalammar.github.io/illustrated-transformer/" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在 Transformer 裡頭，Decoder 利用注意力機制關注 Encoder 的輸出序列（Encoder-Decoder Attention），而 Encoder 跟 Decoder 各自利用自注意力機制關注自己處理的序列（Self-Attention）。無法平行運算的 RNN 完全消失，名符其實的 Attention is all you need.</p>
<p>以下則是 Transformer 實際上將英文句子翻譯到法文的過程：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/transformer-nmt-encode-decode.jpg" style="mix-blend-mode: initial;">
<source src="https://leemeng.tw/images/transformer/transformer-nmt-encode-decode.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        用 Transformer 將英文句子翻譯到法文的例子
                        （<a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>以 Transformer 實作的 NMT 系統基本上可以分為 6 個步驟：</p>
<ol>
<li>Encoder 為輸入序列裡的每個詞彙產生初始的 repr. （即詞向量），以空圈表示</li>
<li>利用自注意力機制將序列中所有詞彙的語義資訊各自匯總成每個詞彙的 repr.，以實圈表示</li>
<li>Encoder 重複 N 次自注意力機制，讓每個詞彙的 repr. 彼此持續修正以完整納入上下文語義</li>
<li>Decoder 在生成每個法文字時也運用了自注意力機制，關注自己之前已生成的元素，將其語義也納入之後生成的元素</li>
<li>在自注意力機制後，Decoder 接著利用注意力機制關注 Encoder 的所有輸出並將其資訊納入當前生成元素的 repr.</li>
<li>Decoder 重複步驟 4, 5 以讓當前元素完整包含整體語義</li>
</ol>
<p>上面動畫的 N 為 3，代表著 Encoder 與 Decoder 的層數。這是一個可以依照任務調整的超參數。</p>
<p>如果你看懂這張圖的資訊流動，就等於瞭解 Transformer 的核心精神了，恭喜！如果仍然有不明瞭的地方，可以搭配我上面的說明多看幾遍動畫或是直接閱讀 <a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">Google AI 部落格的原文介紹</a>。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/transformer/en-ge-bleu-comparison.png" style="mix-blend-mode: initial;"/>
</center>
<center>
                        Transformer 釋出時與其他模型在英德翻譯資料集上的比較
                        （<a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>自注意力機制解開了 RNN 加在 GPU 上的拘束器。作者們用了 8 個 <a href="https://www.nvidia.com.tw/object/tesla-p100-tw.html">NVIDIA P100 GPU</a>，花了 3 天半訓練了一個 Transformer，而該模型在 <a href="http://statmt.org/wmt14/">WMT 2014</a>  英法 / 英德翻譯都取得了最高水準的成績。</p>
<p>跟其他模型相比，這訓練時間跟其創造的優異成績在當時可以說是逆天的存在。自此「大注意時代」展開，該論文至今超過 1800 次引用，所有研究領域都被自注意力機制相關的論文洗了一波。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<img src="https://leemeng.tw/images/transformer/ramona-flwrs-1310216-unsplash.jpg"/>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>沒能趕上開心洗論文的最佳時機也別傷心難過，對我們來說仍然有個十分重要的訊息：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        多數以 RNN 做過的研究，都可以用自注意力機制來取代；多數用 Seq2Seq 架構實現過的應用，也都可以用 Transformer 來替換。模型訓練速度更快，結果可能更好。
                        <br/>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>這也是我決定寫這篇文章的理由之一。雖然本文是以機器翻譯的角度來介紹 Transformer，但事實上只要是能用 RNN 或 Seq2Seq 模型進行的研究領域，你都會看到已經有大量跟（自）注意力機制或是 Transformer 有關的論文了：</p>
<ul>
<li>文本摘要（Text Summarization）</li>
<li>圖像描述（Image Captioning）</li>
<li>閱讀理解（Reading Comprehension）</li>
<li>語音辨識（Voice Recognition）</li>
<li>語言模型（Language Model）</li>
<li>聊天機器人（Chat Bot）</li>
<li>其他任何可以用 RNN 的潛在應用</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/transformer/bert-and-gpt-post.jpg"/>
</center>
<center>
                        知名的 BERT 與 GPT-2 都是 Transformer 的延伸
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>當然不是每個人都喜歡或需要看論文。如果你只是想要應用 Transformer 也沒問題。我在<a href="https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html">進擊的 BERT：NLP 界的巨人之力與遷移學習</a>一文詳細說明你可以如何用 Transformer-based 的語言代表模型進行遷移學習（transfer learning），輕鬆利用前人智慧來完成手上的 NLP 任務； <a href="https://openai.com/blog/better-language-models/">OpenAI 的 GPT</a> 則是非常厲害的語言模型，能產生非常順暢的文章。你可以參考我的 GPT-2 文章：<a href="https://leemeng.tw/gpt2-language-model-generate-chinese-jing-yong-novels.html">直觀理解 GPT-2 語言模型並生成金庸武俠小說</a>。</p>
<p>這些都是 Transformer 的應用。想了解更多，我推薦李宏毅教授最近<a href="https://www.youtube.com/watch?v=UYPa347-DdE">講解 ELMO、BERT 以及 GPT 的 YouTube 影片</a>，十分通俗易懂 ：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="resp-container">
<iframe allow="accelerometer; 
                            autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" class="resp-iframe" frameborder="0" src="https://www.youtube-nocookie.com/embed/UYPa347-DdE">
</iframe>
</div>
<center>
                        李宏毅教授講解目前 NLP 領域的最新研究是如何讓機器讀懂文字的
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>如果你接下來想往深度學習領域發展（尤其是自然語言處理這塊），了解（自）注意力機制以及 Transformer 的運作方式幾乎可以說是必經之路。就算沒打算自己手刻 Transformer，你現在應該也稍微能夠體會現代的神經網路到底在在對自然語言做些什麼了。</p>
<p>至此本文的上半部分結束。在下半段我們將實作一個能進行英翻中的 Transformer。等等會說明一項要你完成的事情，不過現在先離開位置喝點東西、讓眼睛跟腦袋休息一下吧！</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<img src="https://leemeng.tw/images/transformer/adam-jaime-119551-unsplash.jpg"/>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="師傅引進門，修行在個人_1">師傅引進門，修行在個人<a class="anchor-link" href="#師傅引進門，修行在個人">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>你回來了嗎？還是等不及待地想繼續往下閱讀？</p>
<p>接下來我們會進入實際的程式實作。但跟前半段相比難度呈指數型上升，因此我只推薦符合以下條件的讀者閱讀：</p>
<ul>
<li>想透過實作 Transformer 來徹底了解其內部運作原理的人</li>
<li>願意先花 1 小時了解 Transformer 的細節概念與理論的人</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>你馬上就會知道 1 個小時代表什麼意思。如果你覺得這聽起來很 ok，那可以繼續閱讀。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<img src="https://leemeng.tw/images/transformer/obama-not-bad.jpg"/>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在<a href="#機器翻譯近代史">機器翻譯近代史</a>一章我們已經花了不少篇幅講解了許多在實作 Transformer 時會有幫助的重要概念，其中包含：</p>
<ul>
<li><a href="#神經機器翻譯：Encoder-Decoder-模型">Seq2Seq 模型的運作原理</a></li>
<li><a href="#Encoder-Decoder-模型-+-注意力機制">注意力機制的概念與計算過程</a></li>
<li><a href="#Transformer：Seq2Seq-模型-+-自注意力機制">自注意力機制與 Transformer 的精神</a></li>
</ul>
<p>壞消息是，深度學習裡頭理論跟實作的差異常常是很大的。儘管這些背景知識對理解 Transformer 的精神非常有幫助，對從來沒有用過 <a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html">RNN 實現文本生成</a>或是以<a href="https://www.tensorflow.org/alpha/tutorials/text/nmt_with_attention"> Seq2Seq 模型 + 注意力機制實現過 NMT</a> 的人來說，要在第一次就正確實現 Transformer 仍是一個巨大的挑戰。</p>
<p>就算不說理論跟實作的差異，讓我們看看 <a href="https://www.tensorflow.org/alpha/tutorials/text/transformer">TensorFlow 官方釋出的最新 Transformer 教學</a>裡頭有多少內容：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/tf-tutorial-oveview.jpg">
<source src="https://leemeng.tw/images/transformer/tf-tutorial-oveview.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        TensorFlow 官方的 Transformer 教學
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>上面是我用這輩子最快的速度捲動該頁面再加速後的結果，可以看出內容還真不少。儘管中文化很重要，我在這篇文章裡不會幫你把其中的敘述翻成中文（畢竟你的英文可能比我好）</p>
<p>反之，我將利用 TensorFlow 官方的程式碼，以最適合「初心者」理解的實作順序來講述 Transformer 的重要技術細節及概念。在閱讀本文之後，你將有能力自行理解 TensorFlow 官方教學以及其他網路上的實作（比方說 HarvardNLP 以 <a href="https://pytorch.org/">Pytorch</a> 實現的 <a href="http://nlp.seas.harvard.edu//2018/04/03/attention.html#additional-components-bpe-search-averaging">The Annotated Transformer</a>）。</p>
<p>但在實作前有件事情要請你完成：觀看個 YouTube 影片。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="resp-container">
<iframe allow="accelerometer; 
                            autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" class="resp-iframe" frameborder="0" src="https://www.youtube-nocookie.com/embed/ugWDIIOHtPA">
</iframe>
</div>
<center>
                        教授講解 self-attention 計算方式及 Transformer 的運作原理，強力推薦
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>現在閱讀此文的讀者真的很幸福。</p>
<p>李宏毅教授前陣子才在<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html">他 2019 年的台大機器學習課程</a>發佈了 <a href="https://www.youtube.com/watch?v=ugWDIIOHtPA">Transformer 的教學影片</a>，而這可以說是世界上最好的中文教學影片。如果你真的想要深入理解 Transformer，在實作前至少把上面的影片看完吧！你可以少走很多彎路。</p>
<p>實作時我會盡量重述關鍵概念，但如果有先看影片你會比較容易理解我在碎碎念什麼。如果看完影片你的小宇宙開始發光發熱，也可以先讀讀 <a href="https://arxiv.org/abs/1706.03762">Transformer 的原始論文</a>，跟很多學術論文比起來相當好讀，真心不騙。</p>
<p>重申一次，除非你已經了解基本注意力機制的運算以及 Transformer 的整體架構，否則我不建議繼續閱讀。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<img src="https://leemeng.tw/images/transformer/you-should-not-pass.jpg"/>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="11-個重要-Transformer-概念回顧">11 個重要 Transformer 概念回顧<a class="anchor-link" href="#11-個重要-Transformer-概念回顧">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>怎麼樣？你應該已經從教授的課程中學到不少重要概念了吧？我不知道你還記得多少，但讓我非常簡單地幫你複習一下。</p>
<ol>
<li><p>自注意層（Self-Attention Layer）跟 RNN 一樣，輸入是一個序列，輸出一個序列。但是該層可以平行計算，且輸出序列中的每個向量都已經看了整個序列的資訊。</p>
</li>
<li><p>自注意層將輸入序列 <code>I</code> 裡頭的每個位置的向量 <code>i</code> 透過 3 個線性轉換分別變成 3 個向量：<code>q</code>、<code>k</code> 和 <code>v</code>，並將每個位置的 <code>q</code> 拿去跟序列中其他位置的 <code>k</code> 做匹配，算出匹配程度後利用 softmax 層取得介於 0 到 1 之間的權重值，並以此權重跟每個位置的 <code>v</code> 作加權平均，最後取得該位置的輸出向量 <code>o</code>。全部位置的輸出向量可以同時平行計算，最後輸出序列 <code>O</code>。</p>
</li>
<li><p>計算匹配程度（注意）的方法不只一種，只要能吃進 2 個向量並吐出一個數值即可。但在 Transformer 論文原文是將 2 向量做 dot product 算匹配程度。</p>
</li>
<li><p>我們可以透過大量矩陣運算以及 GPU 將概念 2 提到的注意力機制的計算全部平行化，加快訓練效率（也是本文實作的重點）。</p>
</li>
<li><p>多頭注意力機制（Multi-head Attention）是將輸入序列中的每個位置的 <code>q</code>、<code>k</code> 和 <code>v</code> 切割成多個 <code>qi</code>、<code>ki</code> 和 <code>vi</code> 再分別各自進行注意力機制。各自處理完以後把所有結果串接並視情況降維。這樣的好處是能讓各個 head 各司其職，學會關注序列中不同位置在不同 representaton spaces 的資訊。</p>
</li>
<li><p>自注意力機制這樣的計算的好處是「天涯若比鄰」：序列中每個位置都可以在 O(1) 的距離內關注任一其他位置的資訊，運算效率較雙向 RNN 優秀。</p>
</li>
<li><p>自注意層可以取代 Seq2Seq 模型裡頭以 RNN 為基礎的 Encoder / Decoder，而實際上全部替換掉後就（大致上）是 Transformer。</p>
</li>
<li><p>自注意力機制預設沒有「先後順序」的概念，而這也是為何其可以快速平行運算的原因。在進行如機器翻譯等序列生成任務時，我們需要額外加入位置編碼（Positioning Encoding）來加入順序資訊。而在 Transformer 原論文中此值為手設而非訓練出來的模型權重。</p>
</li>
<li><p>Transformer 是一個 Seq2Seq 模型，自然包含了 Encoder / Decoder，而 Encoder 及 Decoder 可以包含多層結構相同的 blocks，裡頭每層都會有 multi-head attention 以及 Feed Forward Network。</p>
</li>
<li><p>在每個 Encoder / Decoder block 裡頭，我們還會使用殘差連結（Residual Connection）以及 Layer Normalization。這些能幫助模型穩定訓練。</p>
</li>
<li><p>Decoder 在關注 Encoder 輸出時會需要遮罩（mask）來避免看到未來資訊。我們後面會看到，事實上還會需要其他遮罩。</p>
</li>
</ol>
<p>這些應該是你在看完影片後學到的東西。如果你想要快速複習，這裡則是<a href="https://bit.ly/2QT4loG">教授課程的 PDF 檔</a>。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>另外你之後也可以隨時透過左側導覽的圖片 icon 來快速回顧 Transformer 的整體架構以及教授添加的註解。我相信在實作的時候它可以幫得上點忙：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/transformer-left-nav.jpg">
<source src="https://leemeng.tw/images/transformer/transformer-left-nav.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>有了這些背景知識以後，在理解程式碼時會輕鬆許多。你也可以一邊執行 <a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/text/transformer.ipynb">TensorFlow 官方的 Colab 筆記本</a>一邊參考底下實作。</p>
<p>好戲登場！</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="安裝函式庫並設置環境">安裝函式庫並設置環境<a class="anchor-link" href="#安裝函式庫並設置環境">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在這邊我們引進一些常用的 <a href="https://www.python.org/">Python</a> 函式庫，這應該不需要特別說明。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">clear_output</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>比較值得注意的是我們將以<a href="https://pypi.org/project/tf-nightly-2.0-preview/">最新的 TensorFlow 2 Beta 版本</a>來實作本文的 Transformer。另外也會透過 <a href="https://www.tensorflow.org/datasets">TensorFlow Datasets</a> 來使用前人幫我們準備好的英中翻譯資料集：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install tensorflow-gpu<span class="o">==</span><span class="m">2</span>.0.0-beta0
<span class="n">clear_output</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_datasets</span> <span class="k">as</span> <span class="nn">tfds</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>2.0.0-beta0
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>另外為了避免 TensorFlow 吐給我們太多不必要的資訊，在此文中我也將改變 logging 等級。<a href="https://www.tensorflow.org/alpha/guide/effective_tf2#api_cleanup">在 TensorFlow 2 裡頭因為 <code>tf.logging</code> 被 deprecated</a>，我們可以直接用 <code>logging</code>  模組來做到這件事情：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="s2">"error"</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>我們同時也讓 numpy 不要顯示科學記號。這樣可以讓我們之後在做一些 Tensor 運算的時候版面能乾淨一點。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>接著定義一些之後在儲存檔案時會用到的路徑變數：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">output_dir</span> <span class="o">=</span> <span class="s2">"nmt"</span>
<span class="n">en_vocab_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">"en_vocab"</span><span class="p">)</span>
<span class="n">zh_vocab_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">"zh_vocab"</span><span class="p">)</span>
<span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">"checkpoints"</span><span class="p">)</span>
<span class="n">log_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s1">'logs'</span><span class="p">)</span>
<span class="n">download_dir</span> <span class="o">=</span> <span class="s2">"tensorflow-datasets/downloads"</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">output_dir</span><span class="p">):</span>
  <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="建立輸入管道">建立輸入管道<a class="anchor-link" href="#建立輸入管道">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>現行的 GPU 以及 TPU 能透過平行運算幫我們顯著地縮短訓練一個 step 所需的時間。而為了讓平行計算能發揮最佳性能，我們需要最佳化<a href="https://www.tensorflow.org/guide/performance/datasets?hl=zh_cn">輸入管道（Input pipeline）</a>，以在當前訓練步驟完成之前就準備好下一個時間點 GPU 要用的數據。</p>
<p>而我們將透過 <a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data">tf.data API</a> 以及前面導入的 <a href="https://www.tensorflow.org/datasets">TensorFlow Datasets</a> 來建置高效的輸入管道，並將<a href="http://www.statmt.org/wmt19/">機器翻譯競賽 WMT 2019</a> 的中英資料集準備好。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="下載並準備資料集">下載並準備資料集<a class="anchor-link" href="#下載並準備資料集">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>首先看看 <code>tfds</code> 裡頭 WMT 2019 的中英翻譯有哪些資料來源：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tmp_builder</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">builder</span><span class="p">(</span><span class="s2">"wmt19_translate/zh-en"</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">tmp_builder</span><span class="o">.</span><span class="n">subsets</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>{NamedSplit('train'): ['newscommentary_v14',
                       'wikititles_v1',
                       'uncorpus_v1',
                       'casia2015',
                       'casict2011',
                       'casict2015',
                       'datum2015',
                       'datum2017',
                       'neu2017'],
 NamedSplit('validation'): ['newstest2018']}
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>可以看到在 WMT 2019 裡中英對照的數據來源還算不少。其中幾個很好猜到其性質：</p>
<ul>
<li>聯合國數據：<code>uncorpus_v1</code></li>
<li>維基百科標題：<code>wikititles_v1</code></li>
<li>新聞評論：<code>newscommentary_v14</code></li>
</ul>
<p>雖然大量數據對訓練神經網路很有幫助，本文為了節省訓練 Transformer 所需的時間，在這裡我們就只選擇一個資料來源當作資料集。至於要選哪個資料來源呢？</p>
<p>聯合國的數據非常龐大，而維基百科標題通常內容很短，<a href="http://www.casmacat.eu/corpus/news-commentary.html">新聞評論</a>感覺是一個相對適合的選擇。我們可以在設定檔 <code>config</code> 裡頭指定新聞評論這個資料來源並請 TensorFlow Datasets 下載：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">translate</span><span class="o">.</span><span class="n">wmt</span><span class="o">.</span><span class="n">WmtConfig</span><span class="p">(</span>
  <span class="n">version</span><span class="o">=</span><span class="n">tfds</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Version</span><span class="p">(</span><span class="s1">'0.0.3'</span><span class="p">,</span> <span class="n">experiments</span><span class="o">=</span><span class="p">{</span><span class="n">tfds</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Experiment</span><span class="o">.</span><span class="n">S3</span><span class="p">:</span> <span class="kc">False</span><span class="p">}),</span>
  <span class="n">language_pair</span><span class="o">=</span><span class="p">(</span><span class="s2">"zh"</span><span class="p">,</span> <span class="s2">"en"</span><span class="p">),</span>
  <span class="n">subsets</span><span class="o">=</span><span class="p">{</span>
    <span class="n">tfds</span><span class="o">.</span><span class="n">Split</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span> <span class="p">[</span><span class="s2">"newscommentary_v14"</span><span class="p">]</span>
  <span class="p">}</span>
<span class="p">)</span>
<span class="n">builder</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">builder</span><span class="p">(</span><span class="s2">"wmt_translate"</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="n">builder</span><span class="o">.</span><span class="n">download_and_prepare</span><span class="p">(</span><span class="n">download_dir</span><span class="o">=</span><span class="n">download_dir</span><span class="p">)</span>
<span class="n">clear_output</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/tfds-demo.jpg" style="mix-blend-mode: initial;">
<source src="https://leemeng.tw/images/transformer/tfds-demo.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>上面的指令約需 2 分鐘完成，而在過程中 <code>tfds</code> 幫我們完成不少工作：</p>
<ul>
<li>下載包含原始數據的壓縮檔</li>
<li>解壓縮得到 CSV 檔案</li>
<li>逐行讀取該 CSV 裡頭所有中英句子</li>
<li>將不符合格式的 row 自動過濾</li>
<li>Shuffle 數據</li>
<li>將原數據轉換成 <a href="https://www.tensorflow.org/alpha/guide/data#consuming_tfrecord_data">TFRecord 數據</a>以加速讀取</li>
</ul>
<p>多花點時間把相關 <a href="https://www.tensorflow.org/datasets/datasets#wmt19_translate">API 文件</a>看熟，你就能把清理、準備數據的時間花在建構模型以及跑實驗上面。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="切割資料集">切割資料集<a class="anchor-link" href="#切割資料集">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>雖然我們只下載了一個新聞評論的數據集，裡頭還是有超過 30 萬筆的中英平行句子。為了減少訓練所需的時間，讓我們使用 <code>tfds.Split</code> 定義一個將此數據集切成多個部分的 <code>split</code>：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">train_perc</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">val_prec</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">drop_prec</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">-</span> <span class="n">train_perc</span> <span class="o">-</span> <span class="n">val_prec</span>

<span class="n">split</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">Split</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">subsplit</span><span class="p">([</span><span class="n">train_perc</span><span class="p">,</span> <span class="n">val_prec</span><span class="p">,</span> <span class="n">drop_prec</span><span class="p">])</span>
<span class="n">split</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>(NamedSplit('train')(tfds.percent[0:20]),
 NamedSplit('train')(tfds.percent[20:21]),
 NamedSplit('train')(tfds.percent[21:100]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>這個 <code>split</code> 請 <code>tfds</code> 將剛剛處理好的新聞評論資料集再進一步切成 3 個部分，數據量分佈如下：</p>
<ul>
<li>Split 1：20% 數據</li>
<li>Split 2：1% 數據</li>
<li>Split 3：79% 數據</li>
</ul>
<p>我們將前兩個 splits 拿來當作訓練以及驗證集，剩餘的部分（第 3 個 split）捨棄不用：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">examples</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">as_dataset</span><span class="p">(</span><span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span> <span class="n">as_supervised</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_examples</span><span class="p">,</span> <span class="n">val_examples</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">examples</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_examples</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">val_examples</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;_OptionsDataset shapes: ((), ()), types: (tf.string, tf.string)&gt;
&lt;_OptionsDataset shapes: ((), ()), types: (tf.string, tf.string)&gt;
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>你可以在<a href="https://github.com/tensorflow/datasets/blob/master/docs/splits.md">這邊</a>找到更多跟 <code>split</code> 相關的用法。</p>
<p>這時候 <code>train_examples</code> 跟 <code>val_examples</code> 都已經是 <a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset">tf.data.Dataset</a>。我們在<a href="#前處理數據">前處理數據</a>一節會看到這些數據在被丟入神經網路前需要經過什麼轉換，不過現在先讓我們簡單讀幾筆數據出來看看：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">en</span><span class="p">,</span> <span class="n">zh</span> <span class="ow">in</span> <span class="n">train_examples</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">en</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">zh</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'-'</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>tf.Tensor(b'Making Do With More', shape=(), dtype=string)
tf.Tensor(b'\xe5\xa4\x9a\xe5\x8a\xb3\xe5\xba\x94\xe5\xa4\x9a\xe5\xbe\x97', shape=(), dtype=string)
----------
tf.Tensor(b'If the Putins, Erdo\xc4\x9fans, and Orb\xc3\xa1ns of the world want to continue to benefit economically from the open international system, they cannot simply make up their own rules.', shape=(), dtype=string)
tf.Tensor(b'\xe5\xa6\x82\xe6\x9e\x9c\xe6\x99\xae\xe4\xba\xac\xe3\x80\x81\xe5\x9f\x83\xe5\xb0\x94\xe5\xa4\x9a\xe5\xae\x89\xe5\x92\x8c\xe6\xac\xa7\xe5\xb0\x94\xe7\x8f\xad\xe5\xb8\x8c\xe6\x9c\x9b\xe7\xbb\xa7\xe7\xbb\xad\xe4\xba\xab\xe6\x9c\x89\xe5\xbc\x80\xe6\x94\xbe\xe5\x9b\xbd\xe9\x99\x85\xe4\xbd\x93\xe7\xb3\xbb\xe6\x8f\x90\xe4\xbe\x9b\xe7\x9a\x84\xe7\xbb\x8f\xe6\xb5\x8e\xe5\x88\xa9\xe7\x9b\x8a\xef\xbc\x8c\xe5\xb0\xb1\xe4\xb8\x8d\xe8\x83\xbd\xe7\xae\x80\xe5\x8d\x95\xe5\x9c\xb0\xe5\x88\xb6\xe5\xae\x9a\xe8\x87\xaa\xe5\xb7\xb1\xe7\x9a\x84\xe8\xa7\x84\xe5\x88\x99\xe3\x80\x82', shape=(), dtype=string)
----------
tf.Tensor(b'This ceiling can be raised only in a deep depression or other exceptional circumstances, allowing for counter-cyclical policy so long as it is agreed that the additional deficit is cyclical, rather than structural.', shape=(), dtype=string)
tf.Tensor(b'\xe5\x8f\xaa\xe6\x9c\x89\xe5\x9c\xa8\xe5\x8f\x91\xe7\x94\x9f\xe6\xb7\xb1\xe5\xba\xa6\xe8\x90\xa7\xe6\x9d\xa1\xe6\x88\x96\xe5\x85\xb6\xe4\xbb\x96\xe5\x8f\x8d\xe5\xb8\xb8\xe4\xba\x8b\xe4\xbb\xb6\xe6\x97\xb6\xef\xbc\x8c\xe8\xbf\x99\xe4\xb8\x80\xe4\xb8\x8a\xe9\x99\x90\xe6\x89\x8d\xe8\x83\xbd\xe5\x81\x9a\xe5\x87\xba\xe8\xb0\x83\xe6\x95\xb4\xef\xbc\x8c\xe4\xbb\xa5\xe4\xbe\xbf\xe8\xae\xa9\xe5\x8f\x8d\xe5\x91\xa8\xe6\x9c\x9f\xe6\x94\xbf\xe7\xad\x96\xe5\xae\x9e\xe6\x96\xbd\xe8\xb6\xb3\xe5\xa4\x9f\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\xef\xbc\x8c\xe4\xbd\xbf\xe4\xba\xba\xe4\xbb\xac\xe4\xb8\x80\xe8\x87\xb4\xe8\xae\xa4\xe4\xb8\xba\xe5\xa2\x9e\xe5\x8a\xa0\xe7\x9a\x84\xe8\xb5\xa4\xe5\xad\x97\xe6\x98\xaf\xe5\x91\xa8\xe6\x9c\x9f\xe6\x80\xa7\xe7\x9a\x84\xef\xbc\x8c\xe8\x80\x8c\xe4\xb8\x8d\xe6\x98\xaf\xe7\xbb\x93\xe6\x9e\x84\xe6\x80\xa7\xe7\x9a\x84\xe3\x80\x82', shape=(), dtype=string)
----------
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>跟預期一樣，每一個例子（每一次的 <code>take</code>）都包含了 2 個以 unicode 呈現的 <code>tf.Tensor</code>。它們有一樣的語義，只是一個是英文，一個是中文。</p>
<p>讓我們將這些 Tensors 實際儲存的字串利用 <code>numpy()</code> 取出並解碼看看：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">sample_examples</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">10</span>

<span class="k">for</span> <span class="n">en_t</span><span class="p">,</span> <span class="n">zh_t</span> <span class="ow">in</span> <span class="n">train_examples</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
  <span class="n">en</span> <span class="o">=</span> <span class="n">en_t</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">"utf-8"</span><span class="p">)</span>
  <span class="n">zh</span> <span class="o">=</span> <span class="n">zh_t</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">"utf-8"</span><span class="p">)</span>
  
  <span class="nb">print</span><span class="p">(</span><span class="n">en</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">zh</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'-'</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
  
  <span class="c1"># 之後用來簡單評估模型的訓練情況</span>
  <span class="n">sample_examples</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">en</span><span class="p">,</span> <span class="n">zh</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>Making Do With More
多劳应多得
----------
If the Putins, Erdoğans, and Orb&aacute;ns of the world want to continue to benefit economically from the open international system, they cannot simply make up their own rules.
如果普京、埃尔多安和欧尔班希望继续享有开放国际体系提供的经济利益，就不能简单地制定自己的规则。
----------
This ceiling can be raised only in a deep depression or other exceptional circumstances, allowing for counter-cyclical policy so long as it is agreed that the additional deficit is cyclical, rather than structural.
只有在发生深度萧条或其他反常事件时，这一上限才能做出调整，以便让反周期政策实施足够的长度，使人们一致认为增加的赤字是周期性的，而不是结构性的。
----------
Fascist and communist regimes of the past, which followed a similar instrumentalist approach to democracy, come to mind here.
在此我们想起了过去的法西斯主义和共产主义。 它们都相似地将民主作为实现其目的的工具。
----------
This phase culminated with the collapse of communism in 1989, but the chance to overcome the Continent&rsquo;s historical divisions now required a redefinition of the European project.
这种状态随着1989年共产主义崩溃而达至巅峰，但是克服欧洲大陆历史性分裂的机遇现在需要重新定义欧洲计划。
----------
The eurozone&rsquo;s collapse (and, for all practical purposes, that of the EU itself) forces a major realignment of European politics.
欧元区的瓦解强迫欧洲政治进行一次重大改组。
----------
With energy and enthusiasm, Burden turned that operation into a thriving health (not health-care) agency that covers three cities and about 300,000 people on the western edge of Los Angeles.
在能量与激情的推动下，波顿将BCHD打造成了欣欣向荣的健康（而非医疗）机构，其服务范围覆盖了洛杉矶西侧三座城市的30万人。
----------
The result could be a world of fragmented blocs &ndash; an outcome that would undermine not only global prosperity, but also cooperation on shared challenges.
其结果可能是一个四分五裂的世界 &mdash; &mdash; 这一结果不但会破坏全球繁荣，也会破坏面对共同挑战的合作。
----------
Among the questions being asked by NGOs, the UN, and national donors is how to prevent the recurrence of past mistakes.
现在NGO们、联合国和捐助国们问得最多的一个问题就是如何避免再犯过去的错误。
----------
Managing the rise of NCDs will require long-term thinking, and government leaders will have to make investments that might pay off only after they are no longer in office.
管理NCD的增加需要长期思维，政府领导人必须进行要在他们离任多年后才能收回成本的投资。
----------
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>想像一下沒有對應的中文，要閱讀這些英文得花多少時間。你可以試著消化其中幾句中文與其對應的英文句子，並比較一下所需要的時間差異。</p>
<p>雖然只是隨意列出的 10 個中英句子，你應該跟我一樣也能感受到機器翻譯研究的重要以及其能帶給我們的價值。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="建立中文與英文字典">建立中文與英文字典<a class="anchor-link" href="#建立中文與英文字典">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>就跟大多數 NLP 專案相同，有了原始的中英句子以後我們得分別為其建立字典來將每個詞彙轉成索引（Index）。<code>tfds.features.text</code> 底下的 <code>SubwordTextEncoder</code> 提供非常方便的 API 讓我們掃過整個訓練資料集並建立字典。</p>
<p>首先為英文語料建立字典：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="k">try</span><span class="p">:</span>
  <span class="n">subword_encoder_en</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">SubwordTextEncoder</span><span class="o">.</span><span class="n">load_from_file</span><span class="p">(</span><span class="n">en_vocab_file</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"載入已建立的字典： </span><span class="si">{en_vocab_file}</span><span class="s2">"</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">"沒有已建立的字典，從頭建立。"</span><span class="p">)</span>
  <span class="n">subword_encoder_en</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">SubwordTextEncoder</span><span class="o">.</span><span class="n">build_from_corpus</span><span class="p">(</span>
      <span class="p">(</span><span class="n">en</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">en</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">train_examples</span><span class="p">),</span> 
      <span class="n">target_vocab_size</span><span class="o">=</span><span class="mi">2</span><span class="o">**</span><span class="mi">13</span><span class="p">)</span> <span class="c1"># 有需要可以調整字典大小</span>
  
  <span class="c1"># 將字典檔案存下以方便下次 warmstart</span>
  <span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">save_to_file</span><span class="p">(</span><span class="n">en_vocab_file</span><span class="p">)</span>
  

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"字典大小：</span><span class="si">{subword_encoder_en.vocab_size}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"前 10 個 subwords：</span><span class="si">{subword_encoder_en.subwords[:10]}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>載入已建立的字典： /content/gdrive/My Drive/nmt/en_vocab
字典大小：8135
前 10 個 subwords：[', ', 'the_', 'of_', 'to_', 'and_', 's_', 'in_', 'a_', 'that_', 'is_']

CPU times: user 41 ms, sys: 7.43 ms, total: 48.4 ms
Wall time: 391 ms
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>如果你的語料庫（corpus） 不小，要掃過整個資料集並建立一個字典得花不少時間。因此實務上我們會先使用 <code>load_from_file</code> 函式嘗試讀取之前已經建好的字典檔案，失敗才 <code>build_from_corpus</code>。</p>
<p>這招很基本，但在你需要重複處理巨大語料庫時非常重要。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>subword_encoder_en</code> 則是利用 <a href="https://arxiv.org/pdf/1609.08144.pdf">GNMT 當初推出的 wordpieces</a> 來進行斷詞，而簡單來說其產生的子詞（subword）介於這兩者之間：</p>
<ul>
<li>用英文字母分隔的斷詞（character-delimited）</li>
<li>用空白分隔的斷詞（word-delimited）</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在掃過所有英文句子以後，<code>subword_encoder_en</code> 建立一個有 8135 個子詞的字典。我們可以用該字典來幫我們將一個英文句子轉成對應的索引序列（index sequence）：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">sample_string</span> <span class="o">=</span> <span class="s1">'Taiwan is beautiful.'</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sample_string</span><span class="p">)</span>
<span class="n">indices</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>[2700, 7911, 10, 2942, 7457, 1163, 7925]</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>這樣的索引序列你應該已經見怪不怪了。我們在<a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html">以前的 NLP 入門文章</a>也使用 <code>tf.keras</code> 裡頭的 <code>Tokenizer</code> 做過類似的事情。</p>
<p>接著讓我們將這些索引還原，看看它們的長相：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="si">{0:10}{1:6}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">"Index"</span><span class="p">,</span> <span class="s2">"Subword"</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">15</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
  <span class="n">subword</span> <span class="o">=</span> <span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">idx</span><span class="p">])</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="si">{0:5}{1:6}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">' '</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">+</span> <span class="n">subword</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>Index     Subword
---------------
 2700     Taiwan
 7911      
   10     is 
 2942     bea
 7457     uti
 1163     ful
 7925     .
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>當 subword tokenizer 遇到從沒出現過在字典裡的詞彙，會將該詞拆成多個子詞（subwords）。比方說上面句中的 <code>beautiful</code> 就被拆成 <code>bea uti ful</code>。這也是為何這種斷詞方法比較不怕沒有出現過在字典裡的字（out-of-vocabulary words）。</p>
<p>另外別在意我為了對齊寫的 <code>print</code> 語法。重點是我們可以用 <code>subword_encoder_en</code> 的 <code>decode</code> 函式再度將索引數字轉回其對應的子詞。編碼與解碼是 2 個完全可逆（invertable）的操作：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">sample_string</span> <span class="o">=</span> <span class="s1">'Taiwan is beautiful.'</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sample_string</span><span class="p">)</span>
<span class="n">decoded_string</span> <span class="o">=</span> <span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">decoded_string</span> <span class="o">==</span> <span class="n">sample_string</span>
<span class="n">pprint</span><span class="p">((</span><span class="n">sample_string</span><span class="p">,</span> <span class="n">decoded_string</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>('Taiwan is beautiful.', 'Taiwan is beautiful.')
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>酷！接著讓我們如法炮製，為中文也建立一個字典：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="k">try</span><span class="p">:</span>
  <span class="n">subword_encoder_zh</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">SubwordTextEncoder</span><span class="o">.</span><span class="n">load_from_file</span><span class="p">(</span><span class="n">zh_vocab_file</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"載入已建立的字典： </span><span class="si">{zh_vocab_file}</span><span class="s2">"</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">"沒有已建立的字典，從頭建立。"</span><span class="p">)</span>
  <span class="n">subword_encoder_zh</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">SubwordTextEncoder</span><span class="o">.</span><span class="n">build_from_corpus</span><span class="p">(</span>
      <span class="p">(</span><span class="n">zh</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">zh</span> <span class="ow">in</span> <span class="n">train_examples</span><span class="p">),</span> 
      <span class="n">target_vocab_size</span><span class="o">=</span><span class="mi">2</span><span class="o">**</span><span class="mi">13</span><span class="p">,</span> <span class="c1"># 有需要可以調整字典大小</span>
      <span class="n">max_subword_length</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># 每一個中文字就是字典裡的一個單位</span>
  
  <span class="c1"># 將字典檔案存下以方便下次 warmstart </span>
  <span class="n">subword_encoder_zh</span><span class="o">.</span><span class="n">save_to_file</span><span class="p">(</span><span class="n">zh_vocab_file</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"字典大小：</span><span class="si">{subword_encoder_zh.vocab_size}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"前 10 個 subwords：</span><span class="si">{subword_encoder_zh.subwords[:10]}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>載入已建立的字典： /content/gdrive/My Drive/nmt/zh_vocab
字典大小：4201
前 10 個 subwords：['的', '，', '。', '国', '在', '是', '一', '和', '不', '这']

CPU times: user 27.6 ms, sys: 121 &micro;s, total: 27.7 ms
Wall time: 337 ms
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在使用 <code>build_from_corpus</code> 函式掃過整個中文資料集時，我們將 <code>max_subword_length</code> 參數設置為 1。這樣可以讓每個漢字都會被視為字典裡頭的一個單位。畢竟跟英文的 abc 字母不同，一個漢字代表的意思可多得多了。而且如果使用 n-gram 的話可能的詞彙組合太多，在小數據集的情況非常容易遇到不存在字典裡頭的字。</p>
<p>另外所有漢字也就大約 4000 ~ 5000 個可能，作為一個分類問題（classification problem）還是可以接受的。</p>
<p>讓我們挑個中文句子來測試看看：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">sample_string</span> <span class="o">=</span> <span class="n">sample_examples</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">subword_encoder_zh</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sample_string</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sample_string</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>多劳应多得
[48, 557, 116, 48, 81]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>好的，我們把中英文斷詞及字典的部分都搞定了。現在給定一個例子（example，在這邊以及後文指的都是一組包含同語義的中英平行句子），我們都能將其轉換成對應的索引序列了：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">en</span> <span class="o">=</span> <span class="s2">"The eurozone&rsquo;s collapse forces a major realignment of European politics."</span>
<span class="n">zh</span> <span class="o">=</span> <span class="s2">"欧元区的瓦解强迫欧洲政治进行一次重大改组。"</span>

<span class="c1"># 將文字轉成為 subword indices</span>
<span class="n">en_indices</span> <span class="o">=</span> <span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">en</span><span class="p">)</span>
<span class="n">zh_indices</span> <span class="o">=</span> <span class="n">subword_encoder_zh</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">zh</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"[英中原文]（轉換前）"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">en</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">zh</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'-'</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"[英中序列]（轉換後）"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">en_indices</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">zh_indices</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>[英中原文]（轉換前）
The eurozone&rsquo;s collapse forces a major realignment of European politics.
欧元区的瓦解强迫欧洲政治进行一次重大改组。

--------------------

[英中序列]（轉換後）
[17, 965, 11, 6, 1707, 676, 8, 211, 2712, 6683, 249, 3, 85, 1447, 7925]
[45, 206, 171, 1, 847, 197, 236, 604, 45, 90, 17, 130, 102, 36, 7, 284, 80, 18, 212, 265, 3]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>接著讓我們針對這些索引序列（index sequence）做一些前處理。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="前處理數據">前處理數據<a class="anchor-link" href="#前處理數據">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在處理序列數據時我們時常會在一個序列的前後各加入一個特殊的 token，以標記該序列的開始與完結，而它們常有許多不同的稱呼：</p>
<ul>
<li>開始 token、<strong>B</strong>egin <strong>o</strong>f <strong>S</strong>entence、BOS、<code>&lt;start&gt;</code></li>
<li>結束 token、<strong>E</strong>nd <strong>o</strong>f <strong>S</strong>entence、EOS、<code>&lt;end&gt;</code></li>
</ul>
<p>這邊我們定義了一個將被 <code>tf.data.Dataset</code> 使用的 <code>encode</code> 函式，它的輸入是一筆包含 2 個 <code>string</code> Tensors 的例子，輸出則是 2 個包含 BOS / EOS 的索引序列：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="n">en_t</span><span class="p">,</span> <span class="n">zh_t</span><span class="p">):</span>
  <span class="c1"># 因為字典的索引從 0 開始，</span>
  <span class="c1"># 我們可以使用 subword_encoder_en.vocab_size 這個值作為 BOS 的索引值</span>
  <span class="c1"># 用 subword_encoder_en.vocab_size + 1 作為 EOS 的索引值</span>
  <span class="n">en_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
      <span class="n">en_t</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="o">+</span> <span class="p">[</span><span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
  <span class="c1"># 同理，不過是使用中文字典的最後一個索引 + 1</span>
  <span class="n">zh_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">subword_encoder_zh</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">subword_encoder_zh</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
      <span class="n">zh_t</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="o">+</span> <span class="p">[</span><span class="n">subword_encoder_zh</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
  
  <span class="k">return</span> <span class="n">en_indices</span><span class="p">,</span> <span class="n">zh_indices</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>因為 <code>tf.data.Dataset</code> 裡頭都是在操作 Tensors（而非 Python 字串），所以這個 <code>encode</code> 函式預期的輸入也是 TensorFlow 裡的 <a href="https://www.tensorflow.org/guide/eager">Eager Tensors</a>。但只要我們使用 <code>numpy()</code> 將 Tensor 裡的實際字串取出以後，做的事情就跟上一節完全相同。</p>
<p>讓我們從訓練集裡隨意取一組中英的 Tensors 來看看這個函式的實際輸出：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">en_t</span><span class="p">,</span> <span class="n">zh_t</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_examples</span><span class="p">))</span>
<span class="n">en_indices</span><span class="p">,</span> <span class="n">zh_indices</span> <span class="o">=</span> <span class="n">encode</span><span class="p">(</span><span class="n">en_t</span><span class="p">,</span> <span class="n">zh_t</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'英文 BOS 的 index：'</span><span class="p">,</span> <span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'英文 EOS 的 index：'</span><span class="p">,</span> <span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'中文 BOS 的 index：'</span><span class="p">,</span> <span class="n">subword_encoder_zh</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'中文 EOS 的 index：'</span><span class="p">,</span> <span class="n">subword_encoder_zh</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">輸入為 2 個 Tensors：'</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">((</span><span class="n">en_t</span><span class="p">,</span> <span class="n">zh_t</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'-'</span> <span class="o">*</span> <span class="mi">15</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'輸出為 2 個索引序列：'</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">((</span><span class="n">en_indices</span><span class="p">,</span> <span class="n">zh_indices</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>英文 BOS 的 index： 8135
英文 EOS 的 index： 8136
中文 BOS 的 index： 4201
中文 EOS 的 index： 4202

輸入為 2 個 Tensors：
(&lt;tf.Tensor: id=306, shape=(), dtype=string, numpy=b'Making Do With More'&gt;,
 &lt;tf.Tensor: id=307, shape=(), dtype=string, numpy=b'\xe5\xa4\x9a\xe5\x8a\xb3\xe5\xba\x94\xe5\xa4\x9a\xe5\xbe\x97'&gt;)
---------------
輸出為 2 個索引序列：
([8135, 4682, 19, 717, 7911, 298, 2701, 7980, 8136],
 [4201, 48, 557, 116, 48, 81, 4202])
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>你可以看到不管是英文還是中文的索引序列，前面都加了一個代表 BOS 的索引（分別為 8135 與 4201），最後一個索引則代表 EOS（分別為 8136 與 4202）</p>
<p>但如果我們將 <code>encode</code> 函式直接套用到整個訓練資料集時會產生以下的錯誤訊息：</p>
<div class="highlight"><pre><span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_examples</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">encode</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<img src="https://leemeng.tw/images/transformer/tf-dataset-map-error.jpg" style="mix-blend-mode: initial;"/>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>這是因為目前 <code>tf.data.Dataset.map</code> 函式裡頭的計算是在<a href="https://www.tensorflow.org/guide/graphs">計算圖模式（Graph mode）</a>下執行，所以裡頭的 Tensors 並不會有 <a href="https://www.tensorflow.org/alpha/guide/eager">Eager Execution</a> 下才有的 <code>numpy</code> 屬性。</p>
<p>解法是使用 <a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/py_function">tf.py_function</a> 將我們剛剛定義的 <code>encode</code> 函式包成一個以 eager 模式執行的 TensorFlow Op：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">tf_encode</span><span class="p">(</span><span class="n">en_t</span><span class="p">,</span> <span class="n">zh_t</span><span class="p">):</span>
  <span class="c1"># 在 `tf_encode` 函式裡頭的 `en_t` 與 `zh_t` 都不是 Eager Tensors</span>
  <span class="c1"># 要到 `tf.py_funtion` 裡頭才是</span>
  <span class="c1"># 另外因為索引都是整數，所以使用 `tf.int64`</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">py_function</span><span class="p">(</span><span class="n">encode</span><span class="p">,</span> <span class="p">[</span><span class="n">en_t</span><span class="p">,</span> <span class="n">zh_t</span><span class="p">],</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">])</span>

<span class="c1"># `tmp_dataset` 為說明用資料集，說明完所有重要的 func，</span>
<span class="c1"># 我們會從頭建立一個正式的 `train_dataset`</span>
<span class="n">tmp_dataset</span> <span class="o">=</span> <span class="n">train_examples</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tf_encode</span><span class="p">)</span>
<span class="n">en_indices</span><span class="p">,</span> <span class="n">zh_indices</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">tmp_dataset</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">en_indices</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">zh_indices</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stderr output_text">
<pre>W0616 23:46:10.571188 140648854296320 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
W0616 23:46:10.573221 140648854296320 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
</pre>
</div>
</div>
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>tf.Tensor([8135 4682   19  717 7911  298 2701 7980 8136], shape=(9,), dtype=int64)
tf.Tensor([4201   48  557  116   48   81 4202], shape=(7,), dtype=int64)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>有點 tricky 但任務完成！注意在套用 <code>map</code> 函式以後，<code>tmp_dataset</code> 的輸出已經是兩個索引序列，而非原文字串。</p>
<p>為了讓 Transformer  快點完成訓練，讓我們將長度超過 40 個 tokens 的序列都去掉吧！我們在底下定義了一個布林（boolean）函式，其輸入為一個包含兩個英中序列 <code>en, zh</code> 的例子，並在只有這 2 個序列的長度都小於 40 的時候回傳真值（True）：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="mi">40</span>

<span class="k">def</span> <span class="nf">filter_max_length</span><span class="p">(</span><span class="n">en</span><span class="p">,</span> <span class="n">zh</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">MAX_LENGTH</span><span class="p">):</span>
  <span class="c1"># en, zh 分別代表英文與中文的索引序列</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">en</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_length</span><span class="p">,</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">zh</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_length</span><span class="p">)</span>

<span class="c1"># tf.data.Dataset.filter(func) 只會回傳 func 為真的例子</span>
<span class="n">tmp_dataset</span> <span class="o">=</span> <span class="n">tmp_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">filter_max_length</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>簡單檢查是否有序列超過我們指定的長度，順便計算過濾掉過長序列後剩餘的訓練集筆數：</p>
<div class="highlight"><pre><span></span><span class="c1"># 因為我們數據量小可以這樣 count</span>
<span class="n">num_examples</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">en_indices</span><span class="p">,</span> <span class="n">zh_indices</span> <span class="ow">in</span> <span class="n">train_dataset</span><span class="p">:</span>
  <span class="n">cond1</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">en_indices</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">MAX_LENGTH</span>
  <span class="n">cond2</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">zh_indices</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">MAX_LENGTH</span>
  <span class="k">assert</span> <span class="n">cond1</span> <span class="ow">and</span> <span class="n">cond2</span>
  <span class="n">num_examples</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"所有英文與中文序列長度都不超過 </span><span class="si">{MAX_LENGTH}</span><span class="s2"> 個 tokens"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"訓練資料集裡總共有 </span><span class="si">{num_examples}</span><span class="s2"> 筆數據"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>訓練資料集裡總共有 29914 筆數據
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>過濾掉較長句子後還有接近 3 萬筆的訓練例子，看來不用擔心數據太少。</p>
<p>最後值得注意的是每個例子裡的索引序列長度不一，這在建立 batch 時可能會發生問題。不過別擔心，輪到 <code>padded_batch</code> 函式出場了：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>
<span class="c1"># 將 batch 裡的所有序列都 pad 到同樣長度</span>
<span class="n">tmp_dataset</span> <span class="o">=</span> <span class="n">tmp_dataset</span><span class="o">.</span><span class="n">padded_batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">padded_shapes</span><span class="o">=</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">en_batch</span><span class="p">,</span> <span class="n">zh_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">tmp_dataset</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"英文索引序列的 batch"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">en_batch</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'-'</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"中文索引序列的 batch"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">zh_batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stderr output_text">
<pre>W0616 23:46:10.753194 140648845903616 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
W0616 23:46:10.760091 140648845903616 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
W0616 23:46:10.768630 140648845903616 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
</pre>
</div>
</div>
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>英文索引序列的 batch
tf.Tensor(
[[8135 4682   19 ...    0    0    0]
 [8135   17  965 ... 8136    0    0]
 [8135 6602    2 ...    0    0    0]
 ...
 [8135 1097  270 ...    0    0    0]
 [8135 1713   70 ...    0    0    0]
 [8135 2731 4553 ...    0    0    0]], shape=(64, 34), dtype=int64)
--------------------
中文索引序列的 batch
tf.Tensor(
[[4201   48  557 ...    0    0    0]
 [4201   45  206 ...    0    0    0]
 [4201   58    5 ...  683    3 4202]
 ...
 [4201   29  120 ...    0    0    0]
 [4201  297  161 ...    0    0    0]
 [4201  279  149 ... 4202    0    0]], shape=(64, 40), dtype=int64)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>padded_batch</code> 函式能幫我們將每個 batch 裡頭的序列都補 0 到跟當下 batch 裡頭最長的序列一樣長。</p>
<p>比方說英文 batch 裡最長的序列為 34；而中文 batch 裡最長的序列則長達 40 個 tokens，剛好是我們前面設定過的序列長度上限。</p>
<p>好啦，現在讓我們從頭建立訓練集與驗證集，順便看看這些中英句子是如何被轉換成它們的最終形態的：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">BUFFER_SIZE</span> <span class="o">=</span> <span class="mi">15000</span>

<span class="c1"># 訓練集</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_examples</span>  <span class="c1"># 輸出：(英文句子, 中文句子)</span>
                 <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tf_encode</span><span class="p">)</span> <span class="c1"># 輸出：(英文索引序列, 中文索引序列)</span>
                 <span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">filter_max_length</span><span class="p">)</span> <span class="c1"># 同上，且序列長度都不超過 40</span>
                 <span class="o">.</span><span class="n">cache</span><span class="p">()</span> <span class="c1"># 加快讀取數據</span>
                 <span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">BUFFER_SIZE</span><span class="p">)</span> <span class="c1"># 將例子洗牌確保隨機性</span>
                 <span class="o">.</span><span class="n">padded_batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="c1"># 將 batch 裡的序列都 pad 到一樣長度</span>
                               <span class="n">padded_shapes</span><span class="o">=</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
                 <span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">))</span> <span class="c1"># 加速</span>
<span class="c1"># 驗證集</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="p">(</span><span class="n">val_examples</span>
               <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tf_encode</span><span class="p">)</span>
               <span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">filter_max_length</span><span class="p">)</span>
               <span class="o">.</span><span class="n">padded_batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> 
                             <span class="n">padded_shapes</span><span class="o">=</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>建構訓練資料集時我們還添加了些沒提過的函式。它們的用途大都是用來提高輸入效率，並不會影響到輸出格式。如果你想深入了解這些函式的運作方式，可以參考 <a href="https://www.tensorflow.org/guide/performance/datasets?hl=zh_cn">tf.data 的官方教學</a>。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>現在讓我們看看最後建立出來的資料集長什麼樣子：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">en_batch</span><span class="p">,</span> <span class="n">zh_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"英文索引序列的 batch"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">en_batch</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'-'</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"中文索引序列的 batch"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">zh_batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>英文索引序列的 batch
tf.Tensor(
[[8135  222    1 ...    0    0    0]
 [8135 3812  162 ...    0    0    0]
 [8135 6267  838 ...    0    0    0]
 ...
 [8135   17 1042 ...    0    0    0]
 [8135 7877 1165 ...    0    0    0]
 [8135 6414 7911 ...    0    0    0]], shape=(128, 40), dtype=int64)
--------------------
中文索引序列的 batch
tf.Tensor(
[[4201  109   54 ...    3 4202    0]
 [4201   30    4 ...    0    0    0]
 [4201  402    4 ...    0    0    0]
 ...
 [4201  626  515 ...    0    0    0]
 [4201   49  249 ...    0    0    0]
 [4201  905  209 ...    0    0    0]], shape=(128, 40), dtype=int64)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>嘿！我們建立了一個可供訓練的輸入管道（Input pipeline）！</p>
<p>你會發現訓練集：</p>
<ul>
<li>一次回傳大小為 128 的 2 個 batch，分別包含 128 個英文、中文的索引序列</li>
<li>序列開頭皆為 BOS，英文的 BOS 索引是 8135；中文的 BOS 索引則為 4201</li>
<li>兩語言 batch 裡的序列都被「拉長」到我們先前定義的最長序列長度：40</li>
</ul>
<p>驗證集也是相同的輸出形式。</p>
<p>現在你應該可以想像我們在每個訓練步驟會拿出來的數據長什麼樣子了：2 個 shape 為 (batch_size, seq_len) 的 Tensors，而裡頭的每一個索引數字都代表著一個中 / 英文子詞（或是 BOS / EOS）。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在這一節我們建立了一個通用資料集。「通用」代表不限於 Transformer，你也能用<a href="https://www.tensorflow.org/beta/tutorials/text/nmt_with_attention">一般搭配注意力機制的 Seq2Seq 模型</a>來處理這個資料集並做中英翻譯。</p>
<p>但從下節開始讓我們把這個數據集先擺一邊，將注意力全部放到 Transformer 身上並逐一實作其架構裡頭的各個元件。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="理解-Transformer-之旅：跟著多維向量去冒險_1">理解 Transformer 之旅：跟著多維向量去冒險<a class="anchor-link" href="#理解-Transformer-之旅：跟著多維向量去冒險">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在實作 Transformer 及注意力機制這種高度平行運算的模型時，你將需要一點「空間想像力」，能夠想像最高高達 4 維的向量是怎麼在 Transformer 的各個元件被處理與轉換的。</p>
<p>如果你跟我一樣腦袋並不是那麼靈光的話，這可不是一件簡單的事情。不過別擔心，從這節開始我會把 Transfomer （主要針對注意力機制）裡頭的矩陣運算過程視覺化（visualize）出來，讓你在這個多維空間裡頭也能悠遊自在。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/transformer/the-matrix-world.jpg"/>
</center>
<center>
                        Welcome to matrix, 準備進入多維空間
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>就好像一般你在寫程式時會追蹤某些變數在函式裡頭的變化，一個直觀理解 Transformer 的方法是將幾個句子丟入其中，並觀察 Transformer 對它們做了些什麼轉換。</p>
<p>首先讓我們建立兩個要拿來持續追蹤的中英平行句子：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">demo_examples</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">"It is important."</span><span class="p">,</span> <span class="s2">"这很重要。"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"The numbers speak for themselves."</span><span class="p">,</span> <span class="s2">"数字证明了一切。"</span><span class="p">),</span>
<span class="p">]</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">demo_examples</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>[('It is important.', '这很重要。'),
 ('The numbers speak for themselves.', '数字证明了一切。')]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>接著利用<a href="#建立輸入管道">之前建立資料集的方法</a>將這 2 組中英句子做些前處理並以 Tensor 的方式讀出：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">demo_examples</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span>
    <span class="p">[</span><span class="n">en</span> <span class="k">for</span> <span class="n">en</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">demo_examples</span><span class="p">],</span> <span class="p">[</span><span class="n">zh</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">zh</span> <span class="ow">in</span> <span class="n">demo_examples</span><span class="p">]</span>
<span class="p">))</span>

<span class="c1"># 將兩個句子透過之前定義的字典轉換成子詞的序列（sequence of subwords）</span>
<span class="c1"># 並添加 padding token: &lt;pad&gt; 來確保 batch 裡的句子有一樣長度</span>
<span class="n">demo_dataset</span> <span class="o">=</span> <span class="n">demo_examples</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tf_encode</span><span class="p">)</span>\
  <span class="o">.</span><span class="n">padded_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">padded_shapes</span><span class="o">=</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

<span class="c1"># 取出這個 demo dataset 裡唯一一個 batch</span>
<span class="n">inp</span><span class="p">,</span> <span class="n">tar</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">demo_dataset</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'inp:'</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">''</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'tar:'</span><span class="p">,</span> <span class="n">tar</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>inp: tf.Tensor(
[[8135  105   10 1304 7925 8136    0    0]
 [8135   17 3905 6013   12 2572 7925 8136]], shape=(2, 8), dtype=int64)

tar: tf.Tensor(
[[4201   10  241   80   27    3 4202    0    0    0]
 [4201  162  467  421  189   14    7  553    3 4202]], shape=(2, 10), dtype=int64)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>上節建立的數據集屍骨未寒，你應該還記得 <code>inp</code>  shape 裡頭第一個維度的 <code>2</code> 代表著這個 batch 有 2 個句子，而第二維度的 <code>8</code> 則代表著句子的長度（單位：子詞）；<code>tar</code> 則為中文子詞序列（subword sequence），不過因為中文我們以漢字為單位作斷詞，長度一般會比對應的英文句子來的長（shape 中的 <code>10</code>）。</p>
<p>2 維矩陣還很容易想像，但我擔心等到你進入 3 維空間後就會想放棄人生了。所以還是先讓我們用人類比較容易理解的方式來呈現這些數據。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="視覺化原始句子">視覺化原始句子<a class="anchor-link" href="#視覺化原始句子">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>如果我們把這 2 個 batch 用你比較熟悉的方式呈現的話會長這樣：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/inp_tar.jpg">
<source src="https://leemeng.tw/images/transformer/inp_tar.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>這樣清楚多了不是嗎？現在點擊播放鍵，將索引序列還原成原始的子詞序列。</p>
<p>你可以清楚地看到每個<strong>原始</strong>句子前後都有 <code>&lt;start&gt;</code> 與 <code>&lt;end&gt;</code>。而為了讓同個 batch 裡頭的序列長度相同，我們在較短的序列後面也補上足夠的 0，代表著 <code>&lt;pad&gt;</code>。</p>
<p>這個視覺化非常簡單，但十分強大。我現在要你記住一些本文會使用的慣例：</p>
<ul>
<li>不管<a href="https://zh.wikipedia.org/wiki/%E5%BC%B5%E9%87%8F">張量（Tensor）</a>變幾維，其第一個維度 <code>shape[0]</code> 永遠代表 <code>batch_size</code>，也就代表著句子的數目</li>
<li>不同句子我們用不同顏色表示，方便你之後對照這些句子在轉換前後的差異</li>
<li>x 軸（橫軸）代表張量的最後一個維度 <code>shape[-1]</code>，以上例來說分別為 <code>8</code> 和 <code>10</code></li>
<li>x, y 軸上的標籤分別代表倒數兩個維度 <code>shape[-2]</code> 及 <code>shape[-1]</code> 其所代表的物理含義，如圖中的<strong>句子</strong>與<strong>子詞</strong></li>
<li>圖中張量的 <code>name</code> 會對應到程式碼裡頭定義的變數名稱，方便你對照並理解實作邏輯。我也會秀出張量的 shape  幫助你想像該向量在多維空間的長相。一個簡單的例子是：<code>(batch_size, tar_seq_len)</code> </li>
</ul>
<p>這些準則與資訊現在看似多餘，但我保證你很快就會需要它們。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="視覺化-3-維詞嵌入張量">視覺化 3 維詞嵌入張量<a class="anchor-link" href="#視覺化-3-維詞嵌入張量">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在將索引序列丟入神經網路之前，我們一般會做<a href="https://zh.wikipedia.org/wiki/%E8%AF%8D%E5%B5%8C%E5%85%A5">詞嵌入（word embedding）</a>，將一個維度為字典大小的高維離散空間「嵌入」到低維的連續空間裡頭。</p>
<p>讓我們為英文與中文分別建立一個詞嵌入層並實際對 <code>inp</code> 及 <code>tar</code> 做轉換：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="c1"># + 2 是因為我們額外加了 &lt;start&gt; 以及 &lt;end&gt; tokens</span>
<span class="n">vocab_size_en</span> <span class="o">=</span> <span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">2</span>
<span class="n">vocab_size_zh</span> <span class="o">=</span> <span class="n">subword_encoder_zh</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">2</span>

<span class="c1"># 為了方便 demo, 將詞彙轉換到一個 4 維的詞嵌入空間</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">embedding_layer_en</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size_en</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
<span class="n">embedding_layer_zh</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size_zh</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>

<span class="n">emb_inp</span> <span class="o">=</span> <span class="n">embedding_layer_en</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="n">emb_tar</span> <span class="o">=</span> <span class="n">embedding_layer_zh</span><span class="p">(</span><span class="n">tar</span><span class="p">)</span>
<span class="n">emb_inp</span><span class="p">,</span> <span class="n">emb_tar</span>
</pre></div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>emb_inp: tf.Tensor(
[[[ 0.00695511 -0.03370368 -0.03656032 -0.03336458]
  [-0.02707888 -0.03917687 -0.01213828  0.00909697]
  [ 0.0355427   0.04111305  0.00751223 -0.01974255]
  [ 0.02443342 -0.03273199  0.01267544  0.03127003]
  [-0.04879753 -0.00119017 -0.00157104  0.01117355]
  [-0.02148524 -0.03413673  0.00708324  0.0121879 ]
  [-0.00680635  0.02136201 -0.02036932 -0.04211974]
  [-0.00680635  0.02136201 -0.02036932 -0.04211974]]

 [[ 0.00695511 -0.03370368 -0.03656032 -0.03336458]
  [-0.0325227  -0.03433502 -0.01849879  0.01439226]
  [ 0.00144588 -0.00377025 -0.00798036 -0.04099905]
  [ 0.04524285  0.02524642 -0.00924555 -0.01368124]
  [-0.0159062   0.01108797 -0.0177028  -0.0435766 ]
  [ 0.00240784 -0.04652226  0.01821991 -0.04349295]
  [-0.04879753 -0.00119017 -0.00157104  0.01117355]
  [-0.02148524 -0.03413673  0.00708324  0.0121879 ]]], shape=(2, 8, 4), dtype=float32)
--------------------
emb_tar: tf.Tensor(
[[[-0.0441955  -0.01026772  0.03740635  0.02017349]
  [ 0.02129837 -0.00746276  0.03881821 -0.01586295]
  [-0.01179456  0.02825376  0.00738146  0.02963744]
  [ 0.01171205  0.04350302 -0.01190796  0.02526634]
  [ 0.03814722 -0.03364048 -0.03744673  0.04369817]
  [ 0.0280853   0.01269842  0.04268574 -0.04069148]
  [ 0.04029209 -0.00619308 -0.04934603  0.02242902]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]]

 [[-0.0441955  -0.01026772  0.03740635  0.02017349]
  [-0.00359621 -0.01380367 -0.02875998 -0.03855735]
  [ 0.04516688 -0.04480755 -0.03278694 -0.0093614 ]
  [ 0.04131394 -0.04065727 -0.04330624 -0.03341667]
  [ 0.03572228 -0.04500845  0.0470326   0.03095007]
  [-0.03566641 -0.03730996 -0.00597564 -0.03933349]
  [ 0.01850356  0.03993076  0.02729526 -0.04848848]
  [-0.02294568 -0.02494572 -0.0136737  -0.04278342]
  [ 0.0280853   0.01269842  0.04268574 -0.04069148]
  [ 0.04029209 -0.00619308 -0.04934603  0.02242902]]], shape=(2, 10, 4), dtype=float32)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>注意你的詞嵌入層的隨機初始值會跟我不同，結果可能會有一點差異。</p>
<p>但重點是你能在腦海中理解這兩個 3 維張量嗎？花了幾秒鐘？我相信在座不乏各路高手，而且事實上在這一行混久了，你也必須能直覺地理解這個表示方式。</p>
<p>但如果有更好的呈現方式幫助我們理解數據，何樂而不為呢？讓我們再次視覺化這兩個 3 維詞嵌入張量：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/emb_inp_tar.jpeg">
<source src="https://leemeng.tw/images/transformer/emb_inp_tar.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>依照前面提過的準則，張量中第一個維度的 <code>2</code> 代表著句子數 <code>batch_size</code>。在 3 維空間裡頭，我會將不同句子畫在 z 軸上，也就是你現在把臉貼近 /  遠離螢幕這個維度。你同時也能用不同顏色來區分句子。</p>
<p>緊跟著句子的下一個維度則一樣是本來的子詞（subword）。只是現在每個子詞都已從一個索引數字被轉換成一個 4 維的詞嵌入向量，因此每個子詞都以 y 軸來表示。最後一維則代表著詞嵌入空間的維度，一樣以 x 軸來表示。</p>
<p>現在再次點擊播放鍵。</p>
<p>在學會怎麼解讀這個 3 維詞嵌入張量以後，你就能明白為何 <code>emb_tar</code> 第一個中文句子裡頭的倒數 3 行（row) 都長得一樣了：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"tar[0]:"</span><span class="p">,</span> <span class="n">tar</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">3</span><span class="p">:])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"emb_tar[0]:"</span><span class="p">,</span> <span class="n">emb_tar</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">3</span><span class="p">:])</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>tar[0]: tf.Tensor([0 0 0], shape=(3,), dtype=int64)
--------------------
emb_tar[0]: tf.Tensor(
[[-0.00285894  0.02392108 -0.03126474  0.01345349]
 [-0.00285894  0.02392108 -0.03126474  0.01345349]
 [-0.00285894  0.02392108 -0.03126474  0.01345349]], shape=(3, 4), dtype=float32)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>它們都是 <code>&lt;pad&gt;</code> token（以 <code>0</code> 表示），理當有一樣的詞嵌入向量。</p>
<p>不同顏色也讓我們可以很直觀地理解一個句子是怎麼從一個 1 維向量被轉換到 2 維的。你後面就會發現，你將需要能夠非常直覺地理解像是 <code>emb_tar</code> 這種 3 維張量裡頭每個維度所代表的意義。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="遮罩：Transformer-的祕密配方">遮罩：Transformer 的祕密配方<a class="anchor-link" href="#遮罩：Transformer-的祕密配方">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>我們在前面並沒有仔細談過遮罩（masking）的概念，但事實上它可以說是在實作 Transformer 時最重要卻也最容易被搞砸的一環。它讓 Transformer 在進行自注意力機制（Self-Attention Mechanism）時不至於偷看到不該看的。</p>
<p>在 Transformer 裡頭有兩種 masks：</p>
<ul>
<li>padding mask</li>
<li>look ahead mask</li>
</ul>
<p>padding mask 是讓 Transformer 用來識別序列實際的內容到哪裡。此遮罩負責的就是將序列中被補 0 的地方（也就是 <code>&lt;pad&gt;</code>）的位置蓋住，讓 Transformer 可以避免「關注」到這些位置。</p>
<p>look ahead mask 人如其名，是用來確保 Decoder 在進行自注意力機制時每個子詞只會「往前看」：關注（包含）自己之前的字詞，不會不小心關注「未來」Decoder 產生的子詞。我們後面還會看到 look ahead mask 的詳細介紹，但不管是哪一種遮罩向量，那些值為 1 的位置就是遮罩存在的地方。</p>
<p>因為 padding mask 的概念相對簡單，讓我們先看這種遮罩：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">create_padding_mask</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span>
  <span class="c1"># padding mask 的工作就是把索引序列中為 0 的位置設為 1</span>
  <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">mask</span><span class="p">[:,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span> <span class="c1">#　broadcasting</span>

<span class="n">inp_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="n">inp_mask</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: id=193029, shape=(2, 1, 1, 8), dtype=float32, numpy=
array([[[[0., 0., 0., 0., 0., 0., 1., 1.]]],


       [[[0., 0., 0., 0., 0., 0., 0., 0.]]]], dtype=float32)&gt;</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>登登！我們的第一個 4 維張量！不過別緊張，我們在中間加了 2 個新維度是為了之後可以做 <a href="https://www.numpy.org/devdocs/user/theory.broadcasting.html">broadcasting</a>，現在可以忽視。喔！不過如果這是你第一次聽到 broadcasting，我強烈建議你現在就閱讀 <a href="https://www.numpy.org/devdocs/user/theory.broadcasting.html">numpy 官方的簡短教學</a>了解其概念。我們後面也會看到實際的 broadcasting 例子。</p>
<p>回到我們的 <code>inp_mask</code> 遮罩。現在我們可以先將額外的維度去掉以方便跟 <code>inp</code> 作比較：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"inp:"</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"tf.squeeze(inp_mask):"</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">inp_mask</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>inp: tf.Tensor(
[[8135  105   10 1304 7925 8136    0    0]
 [8135   17 3905 6013   12 2572 7925 8136]], shape=(2, 8), dtype=int64)
--------------------
tf.squeeze(inp_mask): tf.Tensor(
[[0. 0. 0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0.]], shape=(2, 8), dtype=float32)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>你可以看到 <code>inp_mask</code> 將 <code>inp</code> 裡頭為 <code>0</code> 的對應位置設為 1 凸顯出來，這樣之後其他函式就知道要把哪邊「遮住」。 讓我們看看被降到 2 維的 <code>inp_mask</code> 是怎麼被套用在 <code>inp</code> 身上的：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/padding_mask.jpg">
<source src="https://leemeng.tw/images/transformer/padding_mask.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>很好懂，不是嗎？但這只是小暖身，等到之後要將遮罩 broadcast 到 3、4 維張量的時候你可能會黑人問號，所以最好做點心理準備（笑</p>
<p>至於另外一種遮罩 look ahead mask，等我們說明完下節的注意函式以後你會比較容易理解它的作用，所以先賣個關子。現在讓我們進入 Tranformer 最核心的部分：注意力機制。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Scaled-dot-product-attention：一種注意函式">Scaled dot product attention：一種注意函式<a class="anchor-link" href="#Scaled-dot-product-attention：一種注意函式">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>我們在文中以及教授的影片已經多次看到，所謂的注意力機制（或稱注意函式，attention function）概念上就是拿一個查詢（query）去跟一組 key-values 做運算，最後產生一個輸出。只是我們會利用矩陣運算同時讓多個查詢跟一組 key-values 做運算，最大化計算效率。</p>
<p>而不管是查詢（query）、鍵值（keys）還是值（values）或是輸出，全部都是向量（vectors）。該輸出是 values 的加權平均，而每個 value  獲得的權重則是由當初 value 對應的 key 跟 query 計算匹配程度所得來的。（<a href="https://arxiv.org/pdf/1706.03762.pdf">論文原文</a>稱此計算匹配程度的函式為 compatibility function）</p>
<p>將此運算以圖表示的話則會長得像這樣：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/transformer/scaled-dot-product.jpg" style="mix-blend-mode: initial;"/>
</center>
<center>
                        左右兩邊大致上講的是一樣的事情，不過右側省略 Scale 以及 Mask 步驟，而左側則假設我們已經拿到經過線性轉換的 Q, K, V
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>我們是第一次秀出論文裡頭的圖片（左），但右邊你應該不陌生才對。</p>
<p>Scaled dot product attention 跟以往 multiplicative attention 一樣是先將維度相同的 Q 跟 K 做<a href="https://zh.wikipedia.org/wiki/%E7%82%B9%E7%A7%AF">點積</a>：將對應維度的值兩兩相乘後相加得到單一數值，接著把這些數值除以一個 scaling factor <code>sqrt(dk)</code> ，然後再丟入 <a href="https://www.youtube.com/watch?v=mlaLLQofmR8">softmax 函式</a>得到相加為 1 的注意權重（attention weights）。</p>
<p>最後以此權重對 V 作加權平均得到輸出結果。</p>
<p>除以 scaling factor 的目的是為了讓點積出來的值不會因為 Q 以及 K 的維度 <code>dk</code> 太大而跟著太大（舌頭打結）。因為太大的點積值丟入 softmax 函式有可能使得其梯度變得極小，導致訓練結果不理想。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/transformer/softmax-function.jpg"/>
</center>
<center>
                        Softmax 函式讓某個 Q 與多個 K 之間的匹配值和為 1
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>說完概念，讓我們看看 Transformer 論文中的這個注意函式怎麼運作吧！首先我們得先準備這個函式的輸入 Q, K, V 才行。我們在 <a href="#Multi-head-attention：你看你的，我看我的">Multi-head attention</a> 一節會看到，在進行 scaled dot product attention 時會需要先將 Q、K 以及 V 分別做一次線性轉換，但現在讓我們先忽略這部分。</p>
<p>這邊我們可以拿已經被轉換成詞嵌入空間的英文張量 <code>emb_inp</code> 來充當左圖中的 Q 以及 K，讓它自己跟自己做匹配。V 則讓我隨機產生一個 binary 張量（裡頭只有 1 或 0）來當作每個 K 所對應的值，方便我們直觀解讀 scaled dot product attention 的輸出結果：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 設定一個 seed 確保我們每次都拿到一樣的隨機結果</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">9527</span><span class="p">)</span>

<span class="c1"># 自注意力機制：查詢 `q` 跟鍵值 `k` 都是 `emb_inp`</span>
<span class="n">q</span> <span class="o">=</span> <span class="n">emb_inp</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">emb_inp</span>
<span class="c1"># 簡單產生一個跟 `emb_inp` 同樣 shape 的 binary vector</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">emb_inp</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">v</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: id=193043, shape=(2, 8, 4), dtype=float32, numpy=
array([[[1., 0., 0., 0.],
        [0., 1., 0., 1.],
        [0., 0., 0., 1.],
        [1., 0., 1., 0.],
        [1., 0., 1., 0.],
        [0., 1., 0., 1.],
        [0., 0., 1., 0.],
        [0., 1., 0., 1.]],

       [[1., 0., 1., 1.],
        [1., 0., 1., 0.],
        [1., 0., 0., 0.],
        [1., 0., 1., 0.],
        [0., 1., 0., 1.],
        [1., 1., 1., 1.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]]], dtype=float32)&gt;</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>好啦，我想你現在應該能快速地解讀 3 維張量了，但還是讓我雞婆點，將現在的 Q, K, V 都畫出來讓你參考：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<img src="https://leemeng.tw/images/transformer/q_k_v.jpg"/>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>注意顏色。雖然我們將拿 Q 跟 K 來做匹配，這個匹配只會發生在同個句子（同個顏色）底下（即 <code>shape[1:]</code>）。在深度學習世界，我們會為了最大化 GPU 的運算效率而一次將 64 個、128 個或是更多個 <code>batch_size</code> 的句子丟入模型。習慣 batch 維度的存在是非常實際的。</p>
<p>接著讓我們看看 scaled dot product attention 在 TensorFlow 裡是<a href="https://www.tensorflow.org/beta/tutorials/text/transformer?authuser=1#scaled_dot_product_attention">怎麼被實作</a>的：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">scaled_dot_product_attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
  <span class="sd">"""Calculate the attention weights.</span>
<span class="sd">  q, k, v must have matching leading dimensions.</span>
<span class="sd">  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.</span>
<span class="sd">  The mask has different shapes depending on its type(padding or look ahead) </span>
<span class="sd">  but it must be broadcastable for addition.</span>
<span class="sd">  </span>
<span class="sd">  Args:</span>
<span class="sd">    q: query shape == (..., seq_len_q, depth)</span>
<span class="sd">    k: key shape == (..., seq_len_k, depth)</span>
<span class="sd">    v: value shape == (..., seq_len_v, depth_v)</span>
<span class="sd">    mask: Float tensor with shape broadcastable </span>
<span class="sd">          to (..., seq_len_q, seq_len_k). Defaults to None.</span>
<span class="sd">    </span>
<span class="sd">  Returns:</span>
<span class="sd">    output, attention_weights</span>
<span class="sd">  """</span>
  <span class="c1"># 將 `q`、 `k` 做點積再 scale</span>
  <span class="n">matmul_qk</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># (..., seq_len_q, seq_len_k)</span>
  
  <span class="n">dk</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">k</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># 取得 seq_k 的序列長度</span>
  <span class="n">scaled_attention_logits</span> <span class="o">=</span> <span class="n">matmul_qk</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dk</span><span class="p">)</span>  <span class="c1"># scale by sqrt(dk)</span>

  <span class="c1"># 將遮罩「加」到被丟入 softmax 前的 logits</span>
  <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">scaled_attention_logits</span> <span class="o">+=</span> <span class="p">(</span><span class="n">mask</span> <span class="o">*</span> <span class="o">-</span><span class="mf">1e9</span><span class="p">)</span>

  <span class="c1"># 取 softmax 是為了得到總和為 1 的比例之後對 `v` 做加權平均</span>
  <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scaled_attention_logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (..., seq_len_q, seq_len_k)</span>
  
  <span class="c1"># 以注意權重對 v 做加權平均（weighted average）</span>
  <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>  <span class="c1"># (..., seq_len_q, depth_v)</span>

  <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attention_weights</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>別被嚇到了。除了遮罩的運算部分我們還沒解釋，這 Python 函式事實上就是用 TensorFlow API 來實現剛剛才說的注意力機制邏輯罷了：</p>
<ol>
<li>將 <code>q</code> 和 <code>k</code> 做點積得到 <code>matmul_qk</code></li>
<li>將 <code>matmul_qk</code> 除以 scaling factor <code>sqrt(dk)</code></li>
<li>有遮罩的話在丟入 softmax <strong>前</strong>套用</li>
<li>通過 softmax 取得加總為 1 的注意權重</li>
<li>以該權重加權平均 <code>v</code> 作為輸出結果</li>
<li>回傳輸出結果以及注意權重</li>
</ol>
<p>扣掉註解事實上也就只有 8 行代碼（當然有很多實作細節）。現在先讓我們實際將 <code>q</code>, <code>k</code>, <code>v</code> 輸入此函式看看得到的結果。假設沒有遮罩的存在：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">output</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">scaled_dot_product_attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"output:"</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"attention_weights:"</span><span class="p">,</span> <span class="n">attention_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>output: tf.Tensor(
[[[0.37502408 0.37503672 0.37488326 0.49993956]
  [0.37513658 0.37514552 0.37500778 0.49994028]
  [0.37483314 0.37482613 0.3749625  0.50006175]
  [0.37516367 0.37501514 0.3750258  0.49997073]
  [0.37503195 0.3751256  0.3750621  0.49998796]
  [0.37512696 0.37512186 0.37502852 0.49996266]
  [0.3748441  0.3749599  0.37492597 0.50001484]
  [0.3748441  0.3749599  0.37492597 0.50001484]]

 [[0.62516296 0.2500847  0.6250717  0.37522966]
  [0.62490153 0.24994145 0.62504375 0.37497035]
  [0.62509674 0.2501282  0.6249581  0.37518966]
  [0.62518024 0.25003165 0.6250133  0.37507355]
  [0.6250232  0.25011832 0.62486345 0.37516582]
  [0.6251376  0.25018096 0.625095   0.37525034]
  [0.62478966 0.24995528 0.6248975  0.37490302]
  [0.62492853 0.24997747 0.62507135 0.37497336]]], shape=(2, 8, 4), dtype=float32)
--------------------
attention_weights: tf.Tensor(
[[[0.12517719 0.12502946 0.12490283 0.12493535 0.12491155 0.12497091
   0.12503636 0.12503636]
  [0.12505189 0.12512855 0.12479477 0.1250193  0.12506542 0.12509388
   0.12492308 0.12492308]
  [0.12497574 0.12484524 0.1252356  0.12496044 0.12489695 0.1248758
   0.12510511 0.12510511]
  [0.12500346 0.12506503 0.1249556  0.12519364 0.12496658 0.12508455
   0.12486558 0.12486558]
  [0.12494988 0.12508136 0.12486238 0.12493681 0.12514524 0.12506418
   0.12498005 0.12498005]
  [0.12500885 0.12510943 0.12484082 0.12505434 0.12506378 0.12510203
   0.12491038 0.12491038]
  [0.1250592  0.12492351 0.12505497 0.12482036 0.12496454 0.12489527
   0.12514108 0.12514108]
  [0.1250592  0.12492351 0.12505497 0.12482036 0.12496454 0.12489527
   0.12514108 0.12514108]]

 [[0.12514497 0.1249882  0.12503006 0.12493392 0.1250188  0.12506588
   0.1248794  0.12493874]
  [0.1250289  0.12513264 0.12493595 0.12481083 0.12494826 0.12499319
   0.12507208 0.12507817]
  [0.12506142 0.12492662 0.12505917 0.12498691 0.12506557 0.12506266
   0.12491715 0.12492047]
  [0.12504192 0.12487808 0.1250636  0.12521076 0.12504579 0.12498584
   0.12487733 0.12489669]
  [0.12504749 0.12493626 0.12506288 0.12496644 0.12510824 0.12501009
   0.12496544 0.12490314]
  [0.12506938 0.12495602 0.1250348  0.12488137 0.12498492 0.12519602
   0.12488527 0.12499221]
  [0.12494776 0.12509981 0.1249542  0.12483776 0.12500516 0.12495013
   0.12514311 0.12506206]
  [0.12499588 0.12509465 0.12494626 0.12484587 0.1249316  0.12504588
   0.12505081 0.12508905]]], shape=(2, 8, 8), dtype=float32)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>scaled_dot_product_attention</code> 函式輸出兩個張量：</p>
<ul>
<li><code>output</code> 代表注意力機制的結果</li>
<li><code>attention_weights</code> 代表句子 <code>q</code> 裡頭每個子詞對句子 <code>k</code> 裡頭的每個子詞的注意權重</li>
</ul>
<p>而因為你知道目前的 <code>q</code> 跟 <code>k</code> 都代表同個張量 <code>emb_inp</code>，因此 <code>attention_weights</code> 事實上就代表了 <code>emb_inp</code> 裡頭每個英文序列中的子詞對其他位置的子詞的注意權重。你可以再次參考之前 Transformer 是如何做 encoding 的動畫。</p>
<p><code>output</code> 則是句子裡頭每個位置的子詞將 <code>attention_weights</code> 當作權重，從其他位置的子詞對應的資訊 <code>v</code> 裡頭抽取有用訊息後匯總出來的結果。你可以想像 <code>ouput</code> 裡頭的每個子詞都獲得了一個包含自己以及周遭子詞語義資訊的新 representation。而因為現在每個字詞的注意權重都相同，最後得到的每個 repr. 都長得一樣。</p>
<p>下面則是我們實作的注意函式的所有輸入與輸出張量。透過多次的矩陣運算，注意力機制能讓查詢 Q 跟鍵值 K 做匹配，再依據此匹配程度將值 V 做加權平均獲得新的 representation。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/scaled_dot_product_attention.jpg">
<source src="https://leemeng.tw/images/transformer/scaled_dot_product_attention.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        Scaled dot product attention 的實際運算過程
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>別只聽我碎碎念，自己點擊播放鍵來了解背後到底發生什麼事情吧！</p>
<p>動畫裡包含許多細節，但只要有矩陣運算的基本概念，你應該已經能夠直觀且正確地理解注意函式是怎麼運作的了。在真實世界裡我們當然會用更長的序列、更大的 <code>batch_size</code> 來處理數據，但上面呈現的是程式碼的實際結果，而非示意圖而已。這是注意力機制真正的「所見即所得」。</p>
<p>一般來說注意函式的輸出 <code>output</code>張量維度會跟 <code>q</code> 張量相同（假設圖上的 <code>depth_v</code> 等於 <code>depth</code>）。此張量也被稱作「注意張量」，你可以將其解讀為 <code>q</code> 在關注 <code>k</code> 並從 <code>v</code> 得到上下文訊息後的所獲得的新 representation。而注意權重 <code>attention_weights</code> 則是 <code>q</code> 裡頭每個句子的每個子詞對其他位置的子詞的關注程度。</p>
<p>P.S. 一般注意函式只需輸出注意張量。而我們在這邊將注意權重 <code>attention_weights</code> 也輸出是為了方便之後觀察 Transformer 在訓練的時候將「注意力」放在哪裡。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="直觀理解遮罩在注意函式中的效果">直觀理解遮罩在注意函式中的效果<a class="anchor-link" href="#直觀理解遮罩在注意函式中的效果">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>剛剛為了讓你消化注意函式裡頭最重要的核心邏輯，我刻意忽略了遮罩（masking）的存在。現在讓我們重新把 <code>scaled_dot_product_attention</code> 裡頭跟遮罩相關的程式碼拿出來瞧瞧：</p>
<div class="highlight"><pre><span></span><span class="o">...</span>

<span class="c1"># 將 `q`、 `k` 做點積再 scale</span>
<span class="n">scaled_attention_logits</span> <span class="o">=</span> <span class="n">matmul_qk</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dk</span><span class="p">)</span>

<span class="c1"># 將遮罩「加」到被丟入 softmax 前的 logits</span>
<span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
  <span class="n">scaled_attention_logits</span> <span class="o">+=</span> <span class="p">(</span><span class="n">mask</span> <span class="o">*</span> <span class="o">-</span><span class="mf">1e9</span><span class="p">)</span>

<span class="c1"># 取 softmax 是為了得到總和為 1 的比例做加權平均</span>
<span class="n">attention_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scaled_attention_logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="o">...</span>
</pre></div>
<p>如果你剛剛有仔細看上面的動畫的話（17 秒之後），應該能想像 <code>scaled_attention_logits</code> 的 shape 為 （batch_size, seq_len_q, seq_len_k）。其最後一個維度代表某個序列 <code>q</code> 裡的某個子詞與序列 <code>k</code> 的<strong>每個</strong>子詞的匹配程度，但加總不為 1。而為了之後跟與 <code>k</code> 對應的 <code>v</code> 做加權平均，我們針對最後一個維度做 softmax 運算使其和為 1，也就是上圖 <code>axis=-1</code> 的部分：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/softmax.jpg">
<source src="https://leemeng.tw/images/transformer/softmax.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        對最後一維做 softmax。模型還沒經過訓練所以「注意力」非常平均
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>如果序列 <code>k</code> 裡頭的每個子詞 <code>sub_k</code> 都是實際存在的中文字或英文詞彙，這運算當然沒問題。我們會希望序列 <code>q</code> 裡頭的每個子詞 <code>sub_q</code> 都能從每個 <code>sub_k</code> 獲得它所需要的語義資訊。</p>
<p>但李組長眉頭一皺，發現案情並不單純。</p>
<p>回想一下，我們的 <code>q</code> 跟 <code>k</code> 都是從 <code>emb_inp</code> 來的。<code>emb_inp</code> 代表著英文句子的詞嵌入張量，而裡頭的第一個句子應該是有 <code>&lt;pad&gt;</code> token 的。啊哈！誰會想要放注意力在沒有實際語義的傢伙上呢？</p>
<div class="highlight"><pre><span></span><span class="o">...</span>

<span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
  <span class="n">scaled_attention_logits</span> <span class="o">+=</span> <span class="p">(</span><span class="n">mask</span> <span class="o">*</span> <span class="o">-</span><span class="mf">1e9</span><span class="p">)</span> <span class="c1"># 是 -1e9 不是 1e-9</span>

<span class="n">attention_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scaled_attention_logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="o">...</span>
</pre></div>
<p>因此在注意函式裡頭，我們將遮罩乘上一個接近<strong>負</strong>無窮大的 <code>-1e9</code>，並把它加到進入 softmax <strong>前</strong>的 logits 上面。這樣可以讓這些被加上<strong>極大負值</strong>的位置變得無關緊要，在經過 softmax 以後的值趨近於 0。這效果等同於序列 <code>q</code> 中的某個子詞 <code>sub_q</code> 完全沒放注意力在這些被遮罩蓋住的子詞 <code>sub_k</code> 之上（此例中 <code>sub_k</code> 指是的 <code>&lt;pad&gt;</code>）。</p>
<p>（動腦時間：為何遮罩要放在 softmax 之前而不能放之後？）</p>
<p>聽我說那麼多不如看實際的運算結果。讓我們再次為英文句子 <code>inp</code> 產生對應的 padding mask：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">create_padding_mask</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span>
  <span class="c1"># padding mask 的工作就是把索引序列中為 0 的位置設為 1</span>
  <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">mask</span><span class="p">[:,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span> <span class="c1">#　broadcasting</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"inp:"</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
<span class="n">inp_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"inp_mask:"</span><span class="p">,</span> <span class="n">inp_mask</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>inp: tf.Tensor(
[[8135  105   10 1304 7925 8136    0    0]
 [8135   17 3905 6013   12 2572 7925 8136]], shape=(2, 8), dtype=int64)
--------------------
inp_mask: tf.Tensor(
[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]


 [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>很明顯地，<strong>第一個</strong>英文序列的最後 2 個位置是不具任何語義的 <code>&lt;pad&gt;</code>（圖中為 <code>0</code> 的部分）。而這也是為何我們需要將遮罩 <code>inp_mask</code> 輸入到注意函式，避免序列中的子詞關注到這 2 個傢伙的原因。</p>
<p>我們這次把 <code>inp_mask</code> 降到 3 維，並且將其跟剛剛的 <code>q</code>、<code>k</code> 和 <code>v</code> 一起丟進注意函式裡頭，看看注意權重有什麼變化：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 這次讓我們將 padding mask 放入注意函式並觀察</span>
<span class="c1"># 注意權重的變化</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">inp_mask</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># (batch_size, 1, seq_len_q)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">scaled_dot_product_attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"attention_weights:"</span><span class="p">,</span> <span class="n">attention_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>attention_weights: tf.Tensor(
[[[0.16691911 0.1667221  0.16655324 0.16659662 0.1665649  0.16664404
   0.         0.        ]
  [0.16670164 0.16680385 0.1663589  0.16665822 0.16671969 0.16675764
   0.         0.        ]
  [0.16668104 0.16650699 0.16702762 0.16666064 0.16657597 0.16654775
   0.         0.        ]
  [0.16661155 0.16669361 0.16654776 0.16686502 0.16656238 0.16671962
   0.         0.        ]
  [0.16659099 0.16676629 0.16647433 0.16657357 0.16685146 0.16674338
   0.         0.        ]
  [0.16663864 0.16677272 0.16641466 0.16669929 0.16671185 0.16676286
   0.         0.        ]
  [0.16680835 0.16662736 0.1668027  0.16648975 0.16668208 0.1665897
   0.         0.        ]
  [0.16680835 0.16662736 0.1668027  0.16648975 0.16668208 0.1665897
   0.         0.        ]]

 [[0.12514497 0.1249882  0.12503006 0.12493392 0.1250188  0.12506588
   0.1248794  0.12493874]
  [0.1250289  0.12513264 0.12493595 0.12481083 0.12494826 0.12499319
   0.12507208 0.12507817]
  [0.12506142 0.12492662 0.12505917 0.12498691 0.12506557 0.12506266
   0.12491715 0.12492047]
  [0.12504192 0.12487808 0.1250636  0.12521076 0.12504579 0.12498584
   0.12487733 0.12489669]
  [0.12504749 0.12493626 0.12506288 0.12496644 0.12510824 0.12501009
   0.12496544 0.12490314]
  [0.12506938 0.12495602 0.1250348  0.12488137 0.12498492 0.12519602
   0.12488527 0.12499221]
  [0.12494776 0.12509981 0.1249542  0.12483776 0.12500516 0.12495013
   0.12514311 0.12506206]
  [0.12499588 0.12509465 0.12494626 0.12484587 0.1249316  0.12504588
   0.12505081 0.12508905]]], shape=(2, 8, 8), dtype=float32)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>加了 padding mask 後，第一個句子裡頭的每個子詞針對倒數兩個字詞的「注意權重」的值都變成 0 了。上句話非常饒舌，但我相信已經是非常精準的說法了。讓我把這句話翻譯成 numpy 的 slice 語法：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 事實上也不完全是上句話的翻譯，</span>
<span class="c1"># 因為我們在第一個維度還是把兩個句子都拿出來方便你比較</span>
<span class="n">attention_weights</span><span class="p">[:,</span> <span class="p">:,</span> <span class="o">-</span><span class="mi">2</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: id=193086, shape=(2, 8, 2), dtype=float32, numpy=
array([[[0.        , 0.        ],
        [0.        , 0.        ],
        [0.        , 0.        ],
        [0.        , 0.        ],
        [0.        , 0.        ],
        [0.        , 0.        ],
        [0.        , 0.        ],
        [0.        , 0.        ]],

       [[0.1248794 , 0.12493874],
        [0.12507208, 0.12507817],
        [0.12491715, 0.12492047],
        [0.12487733, 0.12489669],
        [0.12496544, 0.12490314],
        [0.12488527, 0.12499221],
        [0.12514311, 0.12506206],
        [0.12505081, 0.12508905]]], dtype=float32)&gt;</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>第一個英文句子的最後 2 個位置因為是 <code>&lt;pad&gt;</code> 所以被遮罩「蓋住」而沒有權重值（上方 2 維陣列）；第二個句子的序列（下方 2 維陣列）則因為最後 2 個位置仍是正常的英文子詞，因此都有被其他子詞關注。</p>
<p>如果聽完我的碎碎念你還是無法理解以上結果，或是不確定有遮罩的注意函式到底怎麼運作，就實際看看其中的計算過程吧！</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/padding_mask_in_attn_func.jpg">
<source src="https://leemeng.tw/images/transformer/padding_mask_in_attn_func.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        將 padding mask 應用到自注意力機制運算（q = k）
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>一張圖勝過千言萬語。在 padding mask 的幫助下，注意函式輸出的新序列 <code>output</code> 裡頭的每個子詞都只從序列 <code>k</code> （也就是序列 <code>q</code> 自己）的前 6 個實際子詞而非 <code>&lt;pad&gt;</code> 來獲得語義資訊（最後一張圖的黑框部分）。</p>
<p>再次提醒，因為我們輸入注意函式的 <code>q</code> 跟 <code>k</code> 都是同樣的英文詞嵌入張量 <code>emb_inp</code>，事實上這邊做的就是讓英文句子裡頭的每個子詞都去關注同句子中其他位置的子詞的資訊，並從中獲得上下文語義，而這就是所謂的自注意力機制（self-attention）：序列關注自己。</p>
<p>當序列 <code>q</code> 換成 Decoder 的輸出序列而序列 <code>k</code> 變成 Encoder 的輸出序列時，我們就變成在計算一般 Seq2Seq 模型中的注意力機制。這點觀察非常重要，且<a href="#Transformer：Seq2Seq-模型-+-自注意力機制">我們在前面就已經提過了</a>。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>打鐵趁熱，讓我們看看前面提過的另一種遮罩 look ahead mask：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 建立一個 2 維矩陣，維度為 (size, size)，</span>
<span class="c1"># 其遮罩為一個右上角的三角形</span>
<span class="k">def</span> <span class="nf">create_look_ahead_mask</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
  <span class="n">mask</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">band_part</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">mask</span>  <span class="c1"># (seq_len, seq_len)</span>

<span class="n">seq_len</span> <span class="o">=</span> <span class="n">emb_tar</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># 注意這次我們用中文的詞嵌入張量 `emb_tar`</span>
<span class="n">look_ahead_mask</span> <span class="o">=</span> <span class="n">create_look_ahead_mask</span><span class="p">(</span><span class="n">seq_len</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"emb_tar:"</span><span class="p">,</span> <span class="n">emb_tar</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"look_ahead_mask"</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>emb_tar: tf.Tensor(
[[[-0.0441955  -0.01026772  0.03740635  0.02017349]
  [ 0.02129837 -0.00746276  0.03881821 -0.01586295]
  [-0.01179456  0.02825376  0.00738146  0.02963744]
  [ 0.01171205  0.04350302 -0.01190796  0.02526634]
  [ 0.03814722 -0.03364048 -0.03744673  0.04369817]
  [ 0.0280853   0.01269842  0.04268574 -0.04069148]
  [ 0.04029209 -0.00619308 -0.04934603  0.02242902]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]]

 [[-0.0441955  -0.01026772  0.03740635  0.02017349]
  [-0.00359621 -0.01380367 -0.02875998 -0.03855735]
  [ 0.04516688 -0.04480755 -0.03278694 -0.0093614 ]
  [ 0.04131394 -0.04065727 -0.04330624 -0.03341667]
  [ 0.03572228 -0.04500845  0.0470326   0.03095007]
  [-0.03566641 -0.03730996 -0.00597564 -0.03933349]
  [ 0.01850356  0.03993076  0.02729526 -0.04848848]
  [-0.02294568 -0.02494572 -0.0136737  -0.04278342]
  [ 0.0280853   0.01269842  0.04268574 -0.04069148]
  [ 0.04029209 -0.00619308 -0.04934603  0.02242902]]], shape=(2, 10, 4), dtype=float32)
--------------------
look_ahead_mask tf.Tensor(
[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>我們已經知道 demo 用的中文（目標語言）的序列長度為 <code>10</code>，而 look ahead 遮罩就是產生一個 2 維矩陣，其兩個維度都跟中文的詞嵌入張量 <code>emb_tar</code> 的倒數第 2 個維度（序列長度）一樣，且裡頭是一個倒三角形（1 的部分）。</p>
<p>我們<a href="#%E9%81%AE%E7%BD%A9%EF%BC%9ATransformer-%E7%9A%84%E7%A5%95%E5%AF%86%E9%85%8D%E6%96%B9">前面曾經說過</a> <code>look_ahead_mask</code> 是用來確保 Decoder 在進行自注意力機制時輸出序列裡頭的每個子詞只會關注到自己之前（左邊）的字詞，不會不小心關注到未來（右邊）理論上還沒被  Decoder 生成的子詞。</p>
<p>運用從 padding mask 學到的概念，想像一下如果把這個倒三角的遮罩跟之前一樣套用到進入 softmax <strong>之前</strong>的 <code>scaled_attention_logits</code>，輸出序列 <code>output</code> 裡頭的每個子詞的 repr. 會有什麼性質？</p>
<p>溫馨小提醒：<code>scaled_attention_logits</code> 裡頭的每一 row 紀錄了某個特定子詞對其他子詞的注意權重。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 讓我們用目標語言（中文）的 batch</span>
<span class="c1"># 來模擬 Decoder 處理的情況</span>
<span class="n">temp_q</span> <span class="o">=</span> <span class="n">temp_k</span> <span class="o">=</span> <span class="n">emb_tar</span>
<span class="n">temp_v</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">emb_tar</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># 將 look_ahead_mask 放入注意函式</span>
<span class="n">_</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">scaled_dot_product_attention</span><span class="p">(</span>
    <span class="n">temp_q</span><span class="p">,</span> <span class="n">temp_k</span><span class="p">,</span> <span class="n">temp_v</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"attention_weights:"</span><span class="p">,</span> <span class="n">attention_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>attention_weights: tf.Tensor(
[[[1.         0.         0.         0.         0.         0.
   0.         0.         0.         0.        ]
  [0.49974996 0.50025004 0.         0.         0.         0.
   0.         0.         0.         0.        ]
  [0.33338806 0.33309633 0.3335156  0.         0.         0.
   0.         0.         0.         0.        ]
  [0.24980238 0.2497976  0.25013384 0.25026616 0.         0.
   0.         0.         0.         0.        ]
  [0.19975185 0.19982941 0.19989952 0.199991   0.20052823 0.
   0.         0.         0.         0.        ]
  [0.16658378 0.16686733 0.16656147 0.16657883 0.1664059  0.16700274
   0.         0.         0.         0.        ]
  [0.14259693 0.1427213  0.14279391 0.1429158  0.14314583 0.14267854
   0.14314772 0.         0.         0.        ]
  [0.12491751 0.12487698 0.12503591 0.12508857 0.12503389 0.12487747
   0.12507991 0.12508978 0.         0.        ]
  [0.11102892 0.1109929  0.11113416 0.11118097 0.11113235 0.11099333
   0.11117328 0.11118205 0.11118205 0.        ]
  [0.09991965 0.09988723 0.10001437 0.10005648 0.10001273 0.09988762
   0.10004956 0.10005745 0.10005745 0.10005745]]

 [[1.         0.         0.         0.         0.         0.
   0.         0.         0.         0.        ]
  [0.4994912  0.5005088  0.         0.         0.         0.
   0.         0.         0.         0.        ]
  [0.33261845 0.33340293 0.3339786  0.         0.         0.
   0.         0.         0.         0.        ]
  [0.24919374 0.25002357 0.25033304 0.25044966 0.         0.
   0.         0.         0.         0.        ]
  [0.19997214 0.19964042 0.20002526 0.19986893 0.20049322 0.
   0.         0.         0.         0.        ]
  [0.16662474 0.16674054 0.16659829 0.16668092 0.16645522 0.16690029
   0.         0.         0.         0.        ]
  [0.14276491 0.14288287 0.14274995 0.14281946 0.1427529  0.14282054
   0.14320944 0.         0.         0.        ]
  [0.12491003 0.1250709  0.12497466 0.12504703 0.12481265 0.1251362
   0.12493407 0.12511446 0.         0.        ]
  [0.11102156 0.11105824 0.11103692 0.11106326 0.11112017 0.11104742
   0.11128615 0.11106552 0.11130078 0.        ]
  [0.09983386 0.10001399 0.10016464 0.10015456 0.09999382 0.09989963
   0.0998925  0.09993652 0.099891   0.10021948]]], shape=(2, 10, 10), dtype=float32)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>答案呼之欲出，套用 look ahead mask 的結果就是讓序列 <code>q</code> 裡的每個字詞只關注包含自己左側的子詞，在自己之後的位置的字詞都不看。比方說兩個中文句子的第一個字詞都只關注自己：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">attention_weights</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: id=193126, shape=(2, 10), dtype=float32, numpy=
array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)&gt;</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>注意到了嗎？兩個句子的第一個子詞因為自己前面已經沒有其他子詞，所以將全部的注意力 <code>1</code>都放在自己身上。讓我們看看第二個子詞：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">attention_weights</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: id=193131, shape=(2, 10), dtype=float32, numpy=
array([[0.49974996, 0.50025004, 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ],
       [0.4994912 , 0.5005088 , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ]],
      dtype=float32)&gt;</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>兩個句子的第 2 個子詞因為只能看到序列中的第一個子詞以及自己，因此前兩個位置的注意權重加總即為 1，後面位置的權重皆為 0。而現在 2 個值都接近 0.5 是因為我們還沒開始訓練，Transformer 還不知道該把注意力放在哪裡。</p>
<p>就跟一般的 <a href="#%E7%A5%9E%E7%B6%93%E6%A9%9F%E5%99%A8%E7%BF%BB%E8%AD%AF%EF%BC%9AEncoder-Decoder-%E6%A8%A1%E5%9E%8B">Seq2Seq 模型</a>相同，Transformer 裡頭的 Decoder 在生成輸出序列時也是一次產生一個子詞。因此跟輸入的英文句子不同，中文句子裡頭的每個子詞都是在不同時間點產生的。所以理論上 Decoder 在時間點 <code>t - 1</code> （或者說是位置 <code>t - 1</code>）已經生成的子詞 <code>subword_t_minus_1</code> 在生成的時候是不可能能夠關注到下個時間點 <code>t</code>（位置 <code>t</code>）所生成的子詞 <code>subword_t</code> 的，儘管它們在 Transformer 裡頭同時被做矩陣運算。</p>
<p>一個位置的子詞不能去關注未來會在自己之後生成的子詞，而這就像是<a href="https://zh.wikipedia.org/wiki/%E7%A5%96%E7%88%B6%E6%82%96%E8%AB%96">祖父悖論</a>一樣有趣。</p>
<p>實際上 look ahead mask 讓 Decoder 在生成第 1 個子詞時只看自己；在生成第 2 個子詞時關注前 1 個子詞與自己； 在生成第 3 個子詞時關注前兩個已經生成的子詞以及自己，以此類推。透過 look ahead mask，你可以想像 Transformer 既可以平行運算，又可以像是 RNN 一樣，在生成子詞時從前面已生成的子詞獲得必要的語義資訊。</p>
<p>挺酷的，不是嗎？</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/look_ahead_mask_in_attn_func.jpg">
<source src="https://leemeng.tw/images/transformer/look_ahead_mask_in_attn_func.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        look ahead mask 讓每個子詞都只關注序列中自己與之前的位置
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在實際做矩陣運算的時候我們當然還是會讓注意權重為 0 的位置跟對應的 <code>v</code> 相乘，但是上圖的黑框才是實際會對最後的 <code>output</code> 值造成影響的權重與 <code>v</code>。</p>
<p>我們在這節了解 Transformer 架構裡頭的兩種遮罩以及它們的作用：</p>
<ul>
<li>padding mask：遮住 <code>&lt;pad&gt;</code> token 不讓所有子詞關注</li>
<li>look ahead mask：遮住 Decoder 未來生成的子詞不讓之前的子詞關注</li>
</ul>
<p>你現在應該能夠想像遮罩在注意力機制裡頭顯得有多麽重要了：它讓注意函式進行高效率的矩陣平行運算的時候不需擔心會關注到不該關注的位置，一次獲得序列中所有位置的子詞各自應有的注意權重以及新的 reprsentation。</p>
<p>如果 Transformer 是<a href="https://zh.wikipedia.org/wiki/%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A">變形金剛</a>的話，注意力機制跟遮罩就是<a href="https://www.easyatm.com.tw/wiki/%E7%81%AB%E7%A8%AE%E6%BA%90">火種源</a>了。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<img src="https://leemeng.tw/images/transformer/transformer-movie.jpg"/>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Multi-head-attention：你看你的，我看我的">Multi-head attention：你看你的，我看我的<a class="anchor-link" href="#Multi-head-attention：你看你的，我看我的">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>有好好聽教授講解 Transformer 的話，你應該還記得所謂的多頭注意（multi-head attention）概念。如果你到現在還沒看課程影片或者想複習一下，我把 multi-head attention 的開始跟結束時間都設置好了，你只需觀看大約 1 分半左右的影片：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="resp-container">
<iframe allow="accelerometer; 
                            autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" class="resp-iframe" frameborder="0" src="https://www.youtube-nocookie.com/embed/ugWDIIOHtPA?start=1526&amp;end=1676">
</iframe>
</div>
<center>
                        李宏毅教授講解 multi-head attention 的概念
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>複習完了嗎？mutli-head attention 的概念本身並不難，用比較正式的說法就是將 Q、K 以及 V 這三個張量先<strong>個別</strong>轉換到 <em>d_model</em> 維空間，再將其拆成多個比較低維的 <em>depth</em> 維度 N 次以後，將這些產生的小 q、小 k 以及小 v 分別丟入前面的注意函式得到 N 個結果。接著將這 N 個 heads 的結果串接起來，最後通過一個線性轉換就能得到 multi-head attention 的輸出</p>
<p>而為何要那麼「搞剛」把本來 <code>d_model</code> 維的空間投影到多個維度較小的子空間（subspace）以後才各自進行注意力機制呢？這是因為這給予模型更大的彈性，讓它可以同時關注不同位置的子詞在不同子空間下的 representation，而不只是本來 <code>d_model</code> 維度下的一個 representation。</p>
<p>我們在文章最開頭看過的英翻中就是一個活生生的 mutli-head attention 例子：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<img src="https://leemeng.tw/images/transformer/en-to-ch-attention-map.png"/>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在經過<a href="#Scaled-dot-product-attention：一種注意函式">前面 2 節注意函式</a>的洗禮之後，你應該已經能夠看出這裏每張小圖都是一個注意權重（為了方便渲染我做了 transpose）。而事實上每張小圖都是 multi-head attention 裡頭某一個 head 的結果，總共是 8 個 heads。</p>
<p>你會發現每個 head 在 Transformer 生成同樣的中文字時關注的英文子詞有所差異：</p>
<ul>
<li>Head 4 在生成「們」與「再」時特別關注「renewed」</li>
<li>Head 5 在生成「必」與「須」時特別關注「must」</li>
<li>Head 6 &amp; 8 在生成「希」與「望」時特別關注「hope」</li>
</ul>
<p>透過這樣同時關注多個不同子空間裡頭的子詞的 representation，Transformer 最終可以生成更好的結果。</p>
<p>話是這麼說，但程式碼該怎麼寫呢？</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<img src="https://leemeng.tw/images/transformer/multi-head-imagining.jpg"/>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>為了要實現 multi-head attention，得先能把一個 head 變成多個 heads。而這實際上就是把一個 <code>d_model</code> 維度的向量「折」成 <code>num_heads</code> 個 <code>depth</code> 維向量，使得：</p>
<div class="highlight"><pre><span></span>num_heads * depth = d_model
</pre></div>
<p>讓我們實作一個可以做到這件事情的函式，並將英文詞嵌入張量 <code>emb_inp</code> 實際丟進去看看：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">split_heads</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">):</span>
  <span class="c1"># x.shape: (batch_size, seq_len, d_model)</span>
  <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
  
  <span class="c1"># 我們要確保維度 `d_model` 可以被平分成 `num_heads` 個 `depth` 維度</span>
  <span class="k">assert</span> <span class="n">d_model</span> <span class="o">%</span> <span class="n">num_heads</span> <span class="o">==</span> <span class="mi">0</span>
  <span class="n">depth</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">//</span> <span class="n">num_heads</span>  <span class="c1"># 這是分成多頭以後每個向量的維度 </span>
  
  <span class="c1"># 將最後一個 d_model 維度分成 num_heads 個 depth 維度。</span>
  <span class="c1"># 最後一個維度變成兩個維度，張量 x 從 3 維到 4 維</span>
  <span class="c1"># (batch_size, seq_len, num_heads, depth)</span>
  <span class="n">reshaped_x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">depth</span><span class="p">))</span>
  
  <span class="c1"># 將 head 的維度拉前使得最後兩個維度為子詞以及其對應的 depth 向量</span>
  <span class="c1"># (batch_size, num_heads, seq_len, depth)</span>
  <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">reshaped_x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
  
  <span class="k">return</span> <span class="n">output</span>

<span class="c1"># 我們的 `emb_inp` 裡頭的子詞本來就是 4 維的詞嵌入向量</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">4</span>
<span class="c1"># 將 4 維詞嵌入向量分為 2 個 head 的 2 維矩陣</span>
<span class="n">num_heads</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">emb_inp</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">split_heads</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>  
<span class="nb">print</span><span class="p">(</span><span class="s2">"x:"</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"output:"</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>x: tf.Tensor(
[[[ 0.00695511 -0.03370368 -0.03656032 -0.03336458]
  [-0.02707888 -0.03917687 -0.01213828  0.00909697]
  [ 0.0355427   0.04111305  0.00751223 -0.01974255]
  [ 0.02443342 -0.03273199  0.01267544  0.03127003]
  [-0.04879753 -0.00119017 -0.00157104  0.01117355]
  [-0.02148524 -0.03413673  0.00708324  0.0121879 ]
  [-0.00680635  0.02136201 -0.02036932 -0.04211974]
  [-0.00680635  0.02136201 -0.02036932 -0.04211974]]

 [[ 0.00695511 -0.03370368 -0.03656032 -0.03336458]
  [-0.0325227  -0.03433502 -0.01849879  0.01439226]
  [ 0.00144588 -0.00377025 -0.00798036 -0.04099905]
  [ 0.04524285  0.02524642 -0.00924555 -0.01368124]
  [-0.0159062   0.01108797 -0.0177028  -0.0435766 ]
  [ 0.00240784 -0.04652226  0.01821991 -0.04349295]
  [-0.04879753 -0.00119017 -0.00157104  0.01117355]
  [-0.02148524 -0.03413673  0.00708324  0.0121879 ]]], shape=(2, 8, 4), dtype=float32)
output: tf.Tensor(
[[[[ 0.00695511 -0.03370368]
   [-0.02707888 -0.03917687]
   [ 0.0355427   0.04111305]
   [ 0.02443342 -0.03273199]
   [-0.04879753 -0.00119017]
   [-0.02148524 -0.03413673]
   [-0.00680635  0.02136201]
   [-0.00680635  0.02136201]]

  [[-0.03656032 -0.03336458]
   [-0.01213828  0.00909697]
   [ 0.00751223 -0.01974255]
   [ 0.01267544  0.03127003]
   [-0.00157104  0.01117355]
   [ 0.00708324  0.0121879 ]
   [-0.02036932 -0.04211974]
   [-0.02036932 -0.04211974]]]


 [[[ 0.00695511 -0.03370368]
   [-0.0325227  -0.03433502]
   [ 0.00144588 -0.00377025]
   [ 0.04524285  0.02524642]
   [-0.0159062   0.01108797]
   [ 0.00240784 -0.04652226]
   [-0.04879753 -0.00119017]
   [-0.02148524 -0.03413673]]

  [[-0.03656032 -0.03336458]
   [-0.01849879  0.01439226]
   [-0.00798036 -0.04099905]
   [-0.00924555 -0.01368124]
   [-0.0177028  -0.0435766 ]
   [ 0.01821991 -0.04349295]
   [-0.00157104  0.01117355]
   [ 0.00708324  0.0121879 ]]]], shape=(2, 2, 8, 2), dtype=float32)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>觀察 <code>output</code> 與 <code>emb_inp</code> 之間的關係，你會發現 3 維詞嵌入張量 <code>emb_inp</code> 已經被轉換成一個 4 維張量了，且最後一個維度 <code>shape[-1] = 4</code> 被拆成兩半。</p>
<p>不過如果你不熟 TensorFlow API 或是矩陣運算，或許無法馬上理解 head 的維度在哪裡、還有不同 heads 之間有什麼差異。為了幫助你直觀理解 <code>split_heads</code> 函式，我將運算過程中產生的張量都視覺化出來給你瞧瞧：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/split_heads.jpg">
<source src="https://leemeng.tw/images/transformer/split_heads.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        split_heads 函式將 3 維張量轉換為 multi-head 的 4 維張量過程
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>觀察 <code>split_heads</code> 的輸入輸出，你會發現序列裡每個子詞原來為 <code>d_model</code> 維的 reprsentation 被拆成多個相同但較短的 <code>depth</code> 維度。而每個 head 的 2 維矩陣事實上仍然代表原來的序列，只是裡頭子詞的 repr. 維度降低了。</p>
<p>透過動畫，你現在應該已經能夠了解要產生 multi-head 就是將輸入張量中本來是 <code>d_model</code> 的最後一個維度平均地「折」成想要的 head 數，進而產生一個新的 head 維度。一個句子裡頭的子詞現在不只會有一個 <code>d_model</code> 的 repr.，而是會有 <code>num_heads</code> 個 <code>depth</code> 維度的 representation。</p>
<p>接下來只要把 3 維的 Q、K 以及 V 用 <code>split_heads</code> 拆成多個 heads 的 4 維張量，利用 broadcasting 就能以之前定義的<a href="#Scaled-dot-product-attention：一種注意函式"> Scaled dot product attention</a> 來為每個句子裡頭的每個 head 平行計算注意結果了，超有效率！</p>
<p>在明白如何產生 multi-head 的 4 維張量以後，multi-head attention 的實現就比較容易理解了：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 實作一個執行多頭注意力機制的 keras layer</span>
<span class="c1"># 在初始的時候指定輸出維度 `d_model` &amp; `num_heads，</span>
<span class="c1"># 在呼叫的時候輸入 `v`, `k`, `q` 以及 `mask`</span>
<span class="c1"># 輸出跟 scaled_dot_product_attention 函式一樣有兩個：</span>
<span class="c1"># output.shape            == (batch_size, seq_len_q, d_model)</span>
<span class="c1"># attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)</span>
<span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="c1"># 在初始的時候建立一些必要參數</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MultiHeadAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span> <span class="c1"># 指定要將 `d_model` 拆成幾個 heads</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span> <span class="c1"># 在 split_heads 之前的基底維度</span>
    
    <span class="k">assert</span> <span class="n">d_model</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">==</span> <span class="mi">0</span>  <span class="c1"># 前面看過，要確保可以平分</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">depth</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span>  <span class="c1"># 每個 head 裡子詞的新的 repr. 維度</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">wq</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>  <span class="c1"># 分別給 q, k, v 的 3 個線性轉換 </span>
    <span class="bp">self</span><span class="o">.</span><span class="n">wk</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>  <span class="c1"># 注意我們並沒有指定 activation func</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">wv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>  <span class="c1"># 多 heads 串接後通過的線性轉換</span>
  
  <span class="c1"># 這跟我們前面看過的函式有 87% 相似</span>
  <span class="k">def</span> <span class="nf">split_heads</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sd">"""Split the last dimension into (num_heads, depth).</span>
<span class="sd">    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)</span>
<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
  
  <span class="c1"># multi-head attention 的實際執行流程，注意參數順序（這邊跟論文以及 TensorFlow 官方教學一致）</span>
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">q</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="c1"># 將輸入的 q, k, v 都各自做一次線性轉換到 `d_model` 維空間</span>
    <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wq</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wk</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wv</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)</span>
    
    <span class="c1"># 前面看過的，將最後一個 `d_model` 維度分成 `num_heads` 個 `depth` 維度</span>
    <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># (batch_size, num_heads, seq_len_q, depth)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># (batch_size, num_heads, seq_len_k, depth)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># (batch_size, num_heads, seq_len_v, depth)</span>
    
    <span class="c1"># 利用 broadcasting 讓每個句子的每個 head 的 qi, ki, vi 都各自進行注意力機制</span>
    <span class="c1"># 輸出會多一個 head 維度</span>
    <span class="n">scaled_attention</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">scaled_dot_product_attention</span><span class="p">(</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
    <span class="c1"># scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)</span>
    <span class="c1"># attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)</span>
    
    <span class="c1"># 跟我們在 `split_heads` 函式做的事情剛好相反，先做 transpose 再做 reshape</span>
    <span class="c1"># 將 `num_heads` 個 `depth` 維度串接回原來的 `d_model` 維度</span>
    <span class="n">scaled_attention</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">scaled_attention</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="c1"># (batch_size, seq_len_q, num_heads, depth)</span>
    <span class="n">concat_attention</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">scaled_attention</span><span class="p">,</span> 
                                  <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">))</span> 
    <span class="c1"># (batch_size, seq_len_q, d_model)</span>

    <span class="c1"># 通過最後一個線性轉換</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">concat_attention</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len_q, d_model)</span>
        
    <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attention_weights</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>是的，就算你有自己實作過 keras layer，multi-head attention layer 也不算短的實作。如果這是你第一次碰到客製化的 keras layer，別打退堂鼓，你可以多看幾次我寫給你的註解，或是參考等等下方的動畫來加深對 multi-head attention 的理解。</p>
<p><code>split_heads</code> 函式我們在前面就已經看過了，你應該還有印象。<code>call</code> 函式則定義了這個 multi-head attention layer 實際的計算流程，而這流程跟我在本節開頭講的可以說是有 87% 相似：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        將 Q、K 以及 V 這三個張量先個別轉換到 d_model 維空間，再將其拆成多個比較低維的 depth 維度 N 次以後，將這些產生的小 q、小 k 以及小 v 分別丟入前面的注意函式得到 N 個結果。接著將這 N 個 heads 的結果串接起來，最後通過一個線性轉換就能得到 multi-head attention 的輸出
                        <br/>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>差別只在於實際上我們是利用矩陣運算以及 broadcasting 讓 GPU 一次計算整個 batch 裡所有句子的所有 head 的注意結果。</p>
<p>定義了一個新 layer 當然要實際試試。現在讓我們初始一個 multi-head attention layer 並將英文詞嵌入向量 <code>emb_inp</code> 輸入進去看看：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="c1"># emb_inp.shape == (batch_size, seq_len, d_model)</span>
<span class="c1">#               == (2, 8, 4)</span>
<span class="k">assert</span> <span class="n">d_model</span> <span class="o">==</span> <span class="n">emb_inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="o">==</span> <span class="mi">4</span>
<span class="n">num_heads</span> <span class="o">=</span> <span class="mi">2</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"d_model: </span><span class="si">{d_model}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"num_heads: </span><span class="si">{num_heads}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># 初始化一個 multi-head attention layer</span>
<span class="n">mha</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>

<span class="c1"># 簡單將 v, k, q 都設置為 `emb_inp`</span>
<span class="c1"># 順便看看 padding mask 的作用。</span>
<span class="c1"># 別忘記，第一個英文序列的最後兩個 tokens 是 &lt;pad&gt;</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">k</span> <span class="o">=</span> <span class="n">q</span> <span class="o">=</span> <span class="n">emb_inp</span>
<span class="n">padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"q.shape:"</span><span class="p">,</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"k.shape:"</span><span class="p">,</span> <span class="n">k</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"v.shape:"</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"padding_mask.shape:"</span><span class="p">,</span> <span class="n">padding_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">output</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">mha</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"output.shape:"</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"attention_weights.shape:"</span><span class="p">,</span> <span class="n">attention_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">output:"</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>d_model: 4
num_heads: 2

q.shape: (2, 8, 4)
k.shape: (2, 8, 4)
v.shape: (2, 8, 4)
padding_mask.shape: (2, 1, 1, 8)
output.shape: (2, 8, 4)
attention_weights.shape: (2, 2, 8, 8)

output: tf.Tensor(
[[[ 0.00862424  0.00463534  0.00123856  0.01982255]
  [ 0.00860434  0.00464583  0.00125165  0.01984711]
  [ 0.00863869  0.00461318  0.00122942  0.01981261]
  [ 0.00858585  0.00465442  0.00125683  0.0198578 ]
  [ 0.0086211   0.00462923  0.0012448   0.01983759]
  [ 0.00860078  0.00464716  0.00125472  0.01985404]
  [ 0.00865074  0.00461071  0.00122681  0.01980557]
  [ 0.00865074  0.00461071  0.00122681  0.01980557]]

 [[-0.00233657  0.02963993  0.01171194  0.03959805]
  [-0.00234752  0.02964369  0.01171828  0.03960991]
  [-0.00232748  0.02962957  0.01170804  0.03959192]
  [-0.00233163  0.02963142  0.0117076   0.03959151]
  [-0.00231678  0.02962143  0.01170276  0.03957902]
  [-0.00234718  0.02964409  0.01171941  0.03961902]
  [-0.00233476  0.029631    0.01171241  0.03959794]
  [-0.00235306  0.02964601  0.01172148  0.03961948]]], shape=(2, 8, 4), dtype=float32)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>你現在應該明白為何<a href="#遮罩：Transformer-的祕密配方">我們當初要在 padding mask 加入兩個新維度了</a>：一個是用來遮住同個句子但是不同 head 的注意權重，一個則是用來 broadcast 到 2 維注意權重的（詳見<a href="#直觀理解遮罩在注意函式中的效果">直觀理解遮罩</a>一節）。</p>
<p>沒意外的話你也已經能夠解讀 mutli-head attention 的輸出了：</p>
<ul>
<li><code>output</code>：序列中每個子詞的新 repr. 都包含同序列其他位置的資訊</li>
<li><code>attention_weights</code>：包含每個 head 的每個序列 <code>q</code> 中的字詞對序列 <code>k</code> 的注意權重</li>
</ul>
<p>如果你還無法想像每個計算步驟，讓我們看看 multi-head attention 是怎麼將輸入的 <code>q</code>、<code>k</code> 以及 <code>v</code> 轉換成最後的 <code>output</code> 的：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/multi-head-attention.jpg">
<source src="https://leemeng.tw/images/transformer/multi-head-attention.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        Multi-head attention 完整計算過程
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>這應該是你這輩子第一次也可能是唯一一次有機會看到 multi-head 注意力機制是怎麼處理 4 維張量的。</p>
<p>細節不少，我建議將動畫跟程式碼比較一下，確保你能想像每一個步驟產生的張量以及其物理意義。到此為止，我們已經把 Transformer 裡最困難的 multi-head attention 的概念以及運算都看過一遍了。</p>
<p>如果你腦袋還是一團亂，只要記得最後一個畫面：在 <code>q</code>、<code>k</code> 以及 <code>v</code> 的最後一維已經是 <code>d_model</code> 的情況下，multi-head attention 跟 scaled dot product attention 一樣，就是吐出一個完全一樣維度的張量 <code>output</code>。</p>
<p>multi-head attention 的輸出張量 <code>output</code> 裡頭每個句子的每個字詞的 repr. 維度 <code>d_model</code> 雖然跟函式的輸入張量相同，但實際上已經是從同個序列中<strong>不同位置且不同空間</strong>中的 repr. 取得語義資訊的結果。</p>
<p>要確保自己真的掌握了 multi-head attention 的精神，你可以試著向旁邊的朋友（如果他 / 她願意聽的話）解釋一下整個流程。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<img src="https://leemeng.tw/images/transformer/explain-mha.jpg"/>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>喔對了，不用擔心我們做 multi-head 以後計算量會大增。因為 head 的數目雖然變多了，每個子空間的維度也下降了。跟 single-head attention 使用的計算量是差不多的。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="打造-Transformer：疊疊樂時間_1">打造 Transformer：疊疊樂時間<a class="anchor-link" href="#打造-Transformer：疊疊樂時間">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://leemeng.tw/deep-learning-resources.html">以前我們曾提到</a>深度學習模型就是一層層的幾何運算過程。Transformer 也不例外，剛才實作的 mutli-head attention layer 就是一個最明顯的例子。而它正好是 Transformer 裡頭最重要的一層運算。</p>
<p>在這節我們會把 Transformer 裡頭除了注意力機制的其他運算通通實作成一個個的 layers，並將它們全部「疊」起來。</p>
<p>你可以點擊下方的影片來了解接下來的實作順序：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/steps-to-build-transformer.jpg">
<source src="https://leemeng.tw/images/transformer/steps-to-build-transformer.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        一步步打造 Transformer
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>如果這是你第一次看到 Transformer 的架構圖 ... 代表你沒認真上教授的課，等等別忘記<a href="#師傅引進門，修行在個人_1">去前面領補課號碼牌</a>。</p>
<p>影片中左側就是我們接下來會依序實作的 layers。<a href="#Transformer：Seq2Seq-模型-+-自注意力機制">Transformer 是一種使用自注意力機制的 Seq2Seq 模型</a> ，裡頭包含了兩個重要角色，分別為 Encoder 與 Decoder：</p>
<ul>
<li>最初輸入的英文序列會通過 Encoder 中 N 個 Encoder layers 並被轉換成一個<strong>相同長度</strong>的序列。每個 layer 都會為自己的輸入序列裡頭的子詞產生<strong>新的</strong> repr.，然後交給下一個 layer。</li>
<li>Decoder 在生成（預測）下一個中文子詞時會一邊觀察 Encoder 輸出序列裡<strong>所有</strong>英文子詞的 repr.，一邊觀察自己前面已經生成的中文子詞。</li>
</ul>
<p>值得一提的是，N = 1 （Encoder / Decoder layer 數目 = 1）時就是最陽春版的 Transformer。但在深度學習領域裡頭我們常常想對原始數據做多層的轉換，因此會將 N 設為影片最後出現的 2 層或是 Transformer 論文中的 6 層 Encoder / Decoder layers。</p>
<p>Encoder 裡頭的 Encoder layer 裡又分兩個 sub-layers，而 Decoder 底下的 Decoder layer 則包含 3 個 sub-layers。真的是 layer layer 相扣。將這些 layers 的階層關係簡單列出來大概就長這樣（位置 Encoding 等實作時解釋）：</p>
<ul>
<li>Transformer<ul>
<li>Encoder<ul>
<li>輸入 Embedding</li>
<li>位置 Encoding</li>
<li>N 個 Encoder layers<ul>
<li>sub-layer 1: Encoder 自注意力機制</li>
<li>sub-layer 2: Feed Forward</li>
</ul>
</li>
</ul>
</li>
<li>Decoder<ul>
<li>輸出 Embedding</li>
<li>位置 Encoding</li>
<li>N 個 Decoder layers<ul>
<li>sub-layer 1: Decoder 自注意力機制</li>
<li>sub-layer 2: Decoder-Encoder 注意力機制</li>
<li>sub-layer 3: Feed Forward</li>
</ul>
</li>
</ul>
</li>
<li>Final Dense Layer</li>
</ul>
</li>
</ul>
<p>不過就像影片中顯示的一樣，實作的時候我們傾向從下往上疊上去。畢竟地基打得好，樓才蓋得高，對吧？</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Position-wise-Feed-Forward-Networks">Position-wise Feed-Forward Networks<a class="anchor-link" href="#Position-wise-Feed-Forward-Networks">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>如同影片中所看到的， Encoder layer 跟 Decoder layer 裡頭都各自有一個 Feed Forward 的元件。此元件構造簡單，不用像前面的 multi-head attention 建立<a href="https://www.tensorflow.org/beta/tutorials/eager/custom_layers">客製化的 keras layer</a>，只需要寫一個 Python 函式讓它在被呼叫的時候回傳一個<strong>新的</strong> <a href="https://www.tensorflow.org/beta/tutorials/quickstart/beginner">tf.keras.Sequential 模型</a>給我們即可：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 建立 Transformer 裡 Encoder / Decoder layer 都有使用到的 Feed Forward 元件</span>
<span class="k">def</span> <span class="nf">point_wise_feed_forward_network</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dff</span><span class="p">):</span>
  
  <span class="c1"># 此 FFN 對輸入做兩個線性轉換，中間加了一個 ReLU activation func</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">dff</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>  <span class="c1"># (batch_size, seq_len, dff)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)</span>
  <span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>此函式在每次被呼叫的時候都會回傳一組新的全連接前饋神經網路（Fully-connected <strong>F</strong>eed <strong>F</strong>orward <strong>N</strong>etwork，FFN），其輸入張量與輸出張量的最後一個維度皆為 <code>d_model</code>，而在 FFN 中間層的維度則為 <code>dff</code>。一般會讓 <code>dff</code> 大於 <code>d_model</code>，讓 FFN 從輸入的 <code>d_model</code> 維度裡頭擷取些有用的資訊。在論文中 <code>d_model</code> 為 512，<code>dff</code> 則為 4 倍的 2048。兩個都是可以調整的超參數。</p>
<p>讓我們建立一個 FFN 試試：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">seq_len</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">dff</span> <span class="o">=</span> <span class="mi">2048</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">))</span>
<span class="n">ffn</span> <span class="o">=</span> <span class="n">point_wise_feed_forward_network</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dff</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">ffn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"x.shape:"</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"out.shape:"</span><span class="p">,</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>x.shape: (64, 10, 512)
out.shape: (64, 10, 512)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在輸入張量的最後一維已經是 <code>d_model</code> 的情況，FFN 的輸出張量基本上會跟輸入一模一樣：</p>
<ul>
<li>輸入：（batch_size, seq_len, d_model）</li>
<li>輸出：（batch_size, seq_len, d_model） </li>
</ul>
<p>FFN 輸出 / 輸入張量的 shape 相同很容易理解。比較沒那麼明顯的是這個 FFN  事實上對序列中的所有位置做的線性轉換都是一樣的。我們可以假想一個 2 維的 <code>duumy_sentence</code>，裡頭有 5 個以 4 維向量表示的子詞：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">d_model</span> <span class="o">=</span> <span class="mi">4</span> <span class="c1"># FFN 的輸入輸出張量的最後一維皆為 `d_model`</span>
<span class="n">dff</span> <span class="o">=</span> <span class="mi">6</span>

<span class="c1"># 建立一個小 FFN</span>
<span class="n">small_ffn</span> <span class="o">=</span> <span class="n">point_wise_feed_forward_network</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dff</span><span class="p">)</span>
<span class="c1"># 懂子詞梗的站出來</span>
<span class="n">dummy_sentence</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> 
                              <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> 
                              <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> 
                              <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
                              <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">small_ffn</span><span class="p">(</span><span class="n">dummy_sentence</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: id=193585, shape=(5, 4), dtype=float32, numpy=
array([[ 2.8674245, -2.174698 , -1.3073452, -6.4233937],
       [ 2.8674245, -2.174698 , -1.3073452, -6.4233937],
       [ 3.650207 , -0.973258 , -2.4126565, -6.5094995],
       [ 3.650207 , -0.973258 , -2.4126565, -6.5094995],
       [ 3.650207 , -0.973258 , -2.4126565, -6.5094995]], dtype=float32)&gt;</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>你會發現同一個子詞不會因為<strong>位置的改變</strong>而造成 FFN 的輸出結果產生差異。但因為我們實際上會有多個 Encoder / Decoder layers，而每個 layers 都會有不同參數的 FFN，因此每個 layer 裡頭的 FFN 做的轉換都會有所不同。</p>
<p>值得一提的是，儘管對所有位置的子詞都做一樣的轉換，這個轉換是獨立進行的，因此被稱作 Position-wise Feed-Forward Networks。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Encoder-layer：Encoder-小弟">Encoder layer：Encoder 小弟<a class="anchor-link" href="#Encoder-layer：Encoder-小弟">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>有了 <strong>M</strong>ulti-<strong>H</strong>ead <strong>A</strong>ttention（MHA）以及 <strong>F</strong>eed-<strong>F</strong>orward <strong>N</strong>etwork（FFN），我們事實上已經可以實作第一個 Encoder layer 了。讓我們複習一下這 layer 裡頭有什麼重要元件：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/encoder-layer.jpg">
<source src="https://leemeng.tw/images/transformer/encoder-layer.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        Encoder layer 裡的重要元件
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>我想上面的動畫已經很清楚了。一個 Encoder layer 裡頭會有兩個 sub-layers，分別為 MHA 以及 FFN。在 Add &amp; Norm 步驟裡頭，每個 sub-layer 會有一個<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf">殘差連結（residual connection）</a>來幫助減緩梯度消失（Gradient Vanishing）的問題。接著兩個 sub-layers 都會針對最後一維 <code>d_model</code> 做 <a href="https://arxiv.org/abs/1607.06450">layer normalization</a>，將 batch 裡頭每個子詞的輸出獨立做轉換，使其平均與標準差分別靠近 0 和 1 之後輸出。</p>
<p>另外在將 sub-layer 的輸出與其輸入相加之前，我們還會做點 regularization，對該 sub-layer 的輸出使用 <a href="http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf">dropout</a>。</p>
<p>總結一下。如果輸入是 <code>x</code>，最後輸出寫作 <code>out</code> 的話，則每個 sub-layer 的處理邏輯如下：</p>
<div class="highlight"><pre><span></span>sub_layer_out = Sublayer(x)
sub_layer_out = Dropout(sub_layer_out)
out = LayerNorm(x + sub_layer_out)
</pre></div>
<p><code>Sublayer</code> 則可以是 MHA 或是 FFN。現在讓我們看看 Encoder layer 的實作：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Encoder 裡頭會有 N 個 EncoderLayers，而每個 EncoderLayer 裡又有兩個 sub-layers: MHA &amp; FFN</span>
<span class="k">class</span> <span class="nc">EncoderLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="c1"># Transformer 論文內預設 dropout rate 為 0.1</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">EncoderLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">mha</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">point_wise_feed_forward_network</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dff</span><span class="p">)</span>

    <span class="c1"># layer norm 很常在 RNN-based 的模型被使用。一個 sub-layer 一個 layer norm</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layernorm1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layernorm2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
    
    <span class="c1"># 一樣，一個 sub-layer 一個 dropout layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
    
  <span class="c1"># 需要丟入 `training` 參數是因為 dropout 在訓練以及測試的行為有所不同</span>
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="c1"># 除了 `attn`，其他張量的 shape 皆為 (batch_size, input_seq_len, d_model)</span>
    <span class="c1"># attn.shape == (batch_size, num_heads, input_seq_len, input_seq_len)</span>
    
    <span class="c1"># sub-layer 1: MHA</span>
    <span class="c1"># Encoder 利用注意機制關注自己當前的序列，因此 v, k, q 全部都是自己</span>
    <span class="c1"># 另外別忘了我們還需要 padding mask 來遮住輸入序列中的 &lt;pad&gt; token</span>
    <span class="n">attn_output</span><span class="p">,</span> <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mha</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>  
    <span class="n">attn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">attn_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span> 
    <span class="n">out1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm1</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">attn_output</span><span class="p">)</span>  
    
    <span class="c1"># sub-layer 2: FFN</span>
    <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">out1</span><span class="p">)</span> 
    <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">ffn_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>  <span class="c1"># 記得 training</span>
    <span class="n">out2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm2</span><span class="p">(</span><span class="n">out1</span> <span class="o">+</span> <span class="n">ffn_output</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">out2</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>跟當初 MHA layer 的實作比起來輕鬆多了，對吧？</p>
<p>基本上 Encoder layer 裡頭就是兩個架構一模一樣的 sub-layer，只差在一個是 MHA，一個是 FFN。另外為了方便 residual connection 的計算，所有 sub-layers 的<strong>輸出</strong>維度都是 <code>d_model</code>。而 sub-layer 內部產生的維度當然就隨我們開心啦！我們可以為 FFN 設置不同的 <code>dff</code> 值，也能設定不同的 <code>num_heads</code> 來改變 MHA 內部每個 head 裡頭的維度。</p>
<p>論文裡頭的 <code>d_model</code> 為 512，而我們 demo 用的英文詞嵌入張量的 <code>d_model</code> 維度則為 4：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 之後可以調的超參數。這邊為了 demo 設小一點</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">num_heads</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">dff</span> <span class="o">=</span> <span class="mi">8</span>

<span class="c1"># 新建一個使用上述參數的 Encoder Layer</span>
<span class="n">enc_layer</span> <span class="o">=</span> <span class="n">EncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">)</span>
<span class="n">padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>  <span class="c1"># 建立一個當前輸入 batch 使用的 padding mask</span>
<span class="n">enc_out</span> <span class="o">=</span> <span class="n">enc_layer</span><span class="p">(</span><span class="n">emb_inp</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">padding_mask</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"inp:"</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"padding_mask:"</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"emb_inp:"</span><span class="p">,</span> <span class="n">emb_inp</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"enc_out:"</span><span class="p">,</span> <span class="n">enc_out</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">emb_inp</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">enc_out</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>inp: tf.Tensor(
[[8135  105   10 1304 7925 8136    0    0]
 [8135   17 3905 6013   12 2572 7925 8136]], shape=(2, 8), dtype=int64)
--------------------
padding_mask: tf.Tensor(
[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]


 [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)
--------------------
emb_inp: tf.Tensor(
[[[ 0.00695511 -0.03370368 -0.03656032 -0.03336458]
  [-0.02707888 -0.03917687 -0.01213828  0.00909697]
  [ 0.0355427   0.04111305  0.00751223 -0.01974255]
  [ 0.02443342 -0.03273199  0.01267544  0.03127003]
  [-0.04879753 -0.00119017 -0.00157104  0.01117355]
  [-0.02148524 -0.03413673  0.00708324  0.0121879 ]
  [-0.00680635  0.02136201 -0.02036932 -0.04211974]
  [-0.00680635  0.02136201 -0.02036932 -0.04211974]]

 [[ 0.00695511 -0.03370368 -0.03656032 -0.03336458]
  [-0.0325227  -0.03433502 -0.01849879  0.01439226]
  [ 0.00144588 -0.00377025 -0.00798036 -0.04099905]
  [ 0.04524285  0.02524642 -0.00924555 -0.01368124]
  [-0.0159062   0.01108797 -0.0177028  -0.0435766 ]
  [ 0.00240784 -0.04652226  0.01821991 -0.04349295]
  [-0.04879753 -0.00119017 -0.00157104  0.01117355]
  [-0.02148524 -0.03413673  0.00708324  0.0121879 ]]], shape=(2, 8, 4), dtype=float32)
--------------------
enc_out: tf.Tensor(
[[[ 1.2521563   0.3273945  -1.5237452  -0.0558054 ]
  [-1.0591918  -0.42765176 -0.14816867  1.6350121 ]
  [ 0.299005    1.3632457  -1.4101827  -0.252068  ]
  [ 0.7023785  -1.479373   -0.32433346  1.1013279 ]
  [-1.6220697   1.0153029   0.02592759  0.5808392 ]
  [-1.0757908  -0.7200314   0.30136684  1.4944555 ]
  [-0.22072682  1.5675467  -1.215218   -0.1316019 ]
  [-0.22072682  1.5675467  -1.215218   -0.1316019 ]]

 [[ 1.475371    0.30539253 -1.1591307  -0.6216327 ]
  [-1.4569639   0.00421676  0.08528362  1.3674635 ]
  [ 0.61611307  1.3085197  -0.79488575 -1.1297472 ]
  [ 0.80156547  0.9995991  -1.5072922  -0.29387245]
  [-0.11611538  1.6353902  -1.0406278  -0.47864679]
  [ 0.9602699  -0.3459822   0.8696089  -1.4838965 ]
  [-1.6676238   0.9936579   0.2892594   0.38470644]
  [-1.2698565  -0.67637944  1.1073651   0.8388707 ]]], shape=(2, 8, 4), dtype=float32)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在本來的輸入維度即為 <code>d_model</code> 的情況下，Encoder layer 就是給我們一個一模一樣 shape 的張量。當然，實際上內部透過 MHA 以及 FFN sub-layer 的轉換，每個子詞的 repr. 都大幅改變了。</p>
<p>有了 Encoder layer，接著讓我們看看 Decoder layer 的實作。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoder-layer：Decoder-小弟">Decoder layer：Decoder 小弟<a class="anchor-link" href="#Decoder-layer：Decoder-小弟">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>一個 Decoder layer 裡頭有 3 個 sub-layers：</p>
<ol>
<li>Decoder layer 自身的 <strong>Masked</strong> MHA 1</li>
<li>Decoder layer 關注 Encoder 輸出序列的 MHA 2</li>
<li>FFN</li>
</ol>
<p>你也可以看一下影片來回顧它們所在的位置：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/decoder-layer.jpg">
<source src="https://leemeng.tw/images/transformer/decoder-layer.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        Decoder layer 中的 sub-layers
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>跟實作 Encoder layer 時一樣，每個 sub-layer 的邏輯同下：</p>
<div class="highlight"><pre><span></span>sub_layer_out = Sublayer(x)
sub_layer_out = Dropout(sub_layer_out)
out = LayerNorm(x + sub_layer_out)
</pre></div>
<p>Decoder layer 用 MHA 1 來關注輸出序列，查詢 Q、鍵值 K 以及值 V 都是自己。而之所以有個 masked 是因為（中文）輸出序列除了跟（英文）輸入序列一樣需要 padding mask 以外，還需要 look ahead mask 來避免 Decoder layer 關注到未來的子詞。look ahead mask 在<a href="#直觀理解遮罩在注意函式中的效果">前面章節</a>已經有詳細說明了。</p>
<p>MHA1 處理完的輸出序列會成為 MHA 2 的 Q，而 K 與 V 則使用 Encoder 的輸出序列。這個運算的概念是讓一個 Decoder layer 在生成新的中文子詞時先參考先前已經產生的中文字，並為當下要生成的子詞產生一個包含前文語義的 repr. 。接著將此 repr. 拿去跟 Encoder 那邊的英文序列做匹配，看當下字詞的 repr. 有多好並予以修正。</p>
<p>用簡單點的說法就是 Decoder 在生成中文字詞時除了參考已經生成的中文字以外，也會去關注 Encoder 輸出的英文子詞（的 repr.）。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Decoder 裡頭會有 N 個 DecoderLayer，</span>
<span class="c1"># 而 DecoderLayer 又有三個 sub-layers: 自注意的 MHA, 關注 Encoder 輸出的 MHA &amp; FFN</span>
<span class="k">class</span> <span class="nc">DecoderLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">DecoderLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="c1"># 3 個 sub-layers 的主角們</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mha1</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mha2</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">point_wise_feed_forward_network</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dff</span><span class="p">)</span>
 
    <span class="c1"># 定義每個 sub-layer 用的 LayerNorm</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layernorm1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layernorm2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layernorm3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
    
    <span class="c1"># 定義每個 sub-layer 用的 Dropout</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
    
    
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> 
           <span class="n">combined_mask</span><span class="p">,</span> <span class="n">inp_padding_mask</span><span class="p">):</span>
    <span class="c1"># 所有 sub-layers 的主要輸出皆為 (batch_size, target_seq_len, d_model)</span>
    <span class="c1"># enc_output 為 Encoder 輸出序列，shape 為 (batch_size, input_seq_len, d_model)</span>
    <span class="c1"># attn_weights_block_1 則為 (batch_size, num_heads, target_seq_len, target_seq_len)</span>
    <span class="c1"># attn_weights_block_2 則為 (batch_size, num_heads, target_seq_len, input_seq_len)</span>

    <span class="c1"># sub-layer 1: Decoder layer 自己對輸出序列做注意力。</span>
    <span class="c1"># 我們同時需要 look ahead mask 以及輸出序列的 padding mask </span>
    <span class="c1"># 來避免前面已生成的子詞關注到未來的子詞以及 &lt;pad&gt;</span>
    <span class="n">attn1</span><span class="p">,</span> <span class="n">attn_weights_block1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mha1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">combined_mask</span><span class="p">)</span>
    <span class="n">attn1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">attn1</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="n">out1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm1</span><span class="p">(</span><span class="n">attn1</span> <span class="o">+</span> <span class="n">x</span><span class="p">)</span>
    
    <span class="c1"># sub-layer 2: Decoder layer 關注 Encoder 的最後輸出</span>
    <span class="c1"># 記得我們一樣需要對 Encoder 的輸出套用 padding mask 避免關注到 &lt;pad&gt;</span>
    <span class="n">attn2</span><span class="p">,</span> <span class="n">attn_weights_block2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mha2</span><span class="p">(</span>
        <span class="n">enc_output</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">out1</span><span class="p">,</span> <span class="n">inp_padding_mask</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)</span>
    <span class="n">attn2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">attn2</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="n">out2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm2</span><span class="p">(</span><span class="n">attn2</span> <span class="o">+</span> <span class="n">out1</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)</span>
    
    <span class="c1"># sub-layer 3: FFN 部分跟 Encoder layer 完全一樣</span>
    <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">out2</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)</span>

    <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout3</span><span class="p">(</span><span class="n">ffn_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="n">out3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm3</span><span class="p">(</span><span class="n">ffn_output</span> <span class="o">+</span> <span class="n">out2</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)</span>
    
    <span class="c1"># 除了主要輸出 `out3` 以外，輸出 multi-head 注意權重方便之後理解模型內部狀況</span>
    <span class="k">return</span> <span class="n">out3</span><span class="p">,</span> <span class="n">attn_weights_block1</span><span class="p">,</span> <span class="n">attn_weights_block2</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Decoder layer 的實作跟 Encoder layer 大同小異，不過還是有幾點細節特別需要注意：</p>
<ul>
<li>在做 Masked MHA（MHA 1）的時候我們需要同時套用兩種遮罩：<strong>輸出</strong>序列的 padding mask 以及 look ahead mask。因此 Decoder layer 預期的遮罩是兩者結合的 <code>combined_mask</code></li>
<li>MHA 1 因為是 Decoder layer 關注自己，multi-head attention 的參數 <code>v</code>、<code>k</code> 以及 <code>q</code> 都是 <code>x</code></li>
<li>MHA 2 是 Decoder layer 關注 Encoder 輸出序列，因此，multi-head attention 的參數 <code>v</code>、<code>k</code> 為 <code>enc_output</code>，<code>q</code> 則為 MHA 1 sub-layer 的結果 <code>out1</code></li>
</ul>
<p>產生 <code>comined_mask</code> 也很簡單，我們只要把兩個遮罩取大的即可：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tar_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">tar</span><span class="p">)</span>
<span class="n">look_ahead_mask</span> <span class="o">=</span> <span class="n">create_look_ahead_mask</span><span class="p">(</span><span class="n">tar</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">combined_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">tar_padding_mask</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"tar:"</span><span class="p">,</span> <span class="n">tar</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"tar_padding_mask:"</span><span class="p">,</span> <span class="n">tar_padding_mask</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"look_ahead_mask:"</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"combined_mask:"</span><span class="p">,</span> <span class="n">combined_mask</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>tar: tf.Tensor(
[[4201   10  241   80   27    3 4202    0    0    0]
 [4201  162  467  421  189   14    7  553    3 4202]], shape=(2, 10), dtype=int64)
--------------------
tar_padding_mask: tf.Tensor(
[[[[0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]


 [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 10), dtype=float32)
--------------------
look_ahead_mask: tf.Tensor(
[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)
--------------------
combined_mask: tf.Tensor(
[[[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]


 [[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 10, 10), dtype=float32)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>注意 <code>combined_mask</code> 的 shape 以及裡頭遮罩所在的位置。利用 broadcasting 我們將 <code>combined_mask</code> 的 shape 也擴充到 4 維：</p>
<div class="highlight"><pre><span></span>(batch_size, num_heads, seq_len_tar, seq_len_tar)
= (2, 1, 10, 10)
</pre></div>
<p>這方便之後 multi-head attention 的計算。另外因為我們 demo 的中文 batch 裡頭的第一個句子有 <code>&lt;pad&gt;</code>，<code>combined_mask</code> 除了 look ahead 的效果以外還加了 padding mask。</p>
<p>因為剛剛實作的是 Decoder layer，這次讓我們把中文（目標語言）的詞嵌入張量以及相關的遮罩丟進去看看：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 超參數</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">num_heads</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">dff</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">dec_layer</span> <span class="o">=</span> <span class="n">DecoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">)</span>

<span class="c1"># 來源、目標語言的序列都需要 padding mask</span>
<span class="n">inp_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="n">tar_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">tar</span><span class="p">)</span>

<span class="c1"># masked MHA 用的遮罩，把 padding 跟未來子詞都蓋住</span>
<span class="n">look_ahead_mask</span> <span class="o">=</span> <span class="n">create_look_ahead_mask</span><span class="p">(</span><span class="n">tar</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">combined_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">tar_padding_mask</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">)</span>

<span class="c1"># 實際初始一個 decoder layer 並做 3 個 sub-layers 的計算</span>
<span class="n">dec_out</span><span class="p">,</span> <span class="n">dec_self_attn_weights</span><span class="p">,</span> <span class="n">dec_enc_attn_weights</span> <span class="o">=</span> <span class="n">dec_layer</span><span class="p">(</span>
    <span class="n">emb_tar</span><span class="p">,</span> <span class="n">enc_out</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">combined_mask</span><span class="p">,</span> <span class="n">inp_padding_mask</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"emb_tar:"</span><span class="p">,</span> <span class="n">emb_tar</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"enc_out:"</span><span class="p">,</span> <span class="n">enc_out</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"dec_out:"</span><span class="p">,</span> <span class="n">dec_out</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">emb_tar</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">dec_out</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"dec_self_attn_weights.shape:"</span><span class="p">,</span> <span class="n">dec_self_attn_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"dec_enc_attn_weights:"</span><span class="p">,</span> <span class="n">dec_enc_attn_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>emb_tar: tf.Tensor(
[[[-0.0441955  -0.01026772  0.03740635  0.02017349]
  [ 0.02129837 -0.00746276  0.03881821 -0.01586295]
  [-0.01179456  0.02825376  0.00738146  0.02963744]
  [ 0.01171205  0.04350302 -0.01190796  0.02526634]
  [ 0.03814722 -0.03364048 -0.03744673  0.04369817]
  [ 0.0280853   0.01269842  0.04268574 -0.04069148]
  [ 0.04029209 -0.00619308 -0.04934603  0.02242902]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]]

 [[-0.0441955  -0.01026772  0.03740635  0.02017349]
  [-0.00359621 -0.01380367 -0.02875998 -0.03855735]
  [ 0.04516688 -0.04480755 -0.03278694 -0.0093614 ]
  [ 0.04131394 -0.04065727 -0.04330624 -0.03341667]
  [ 0.03572228 -0.04500845  0.0470326   0.03095007]
  [-0.03566641 -0.03730996 -0.00597564 -0.03933349]
  [ 0.01850356  0.03993076  0.02729526 -0.04848848]
  [-0.02294568 -0.02494572 -0.0136737  -0.04278342]
  [ 0.0280853   0.01269842  0.04268574 -0.04069148]
  [ 0.04029209 -0.00619308 -0.04934603  0.02242902]]], shape=(2, 10, 4), dtype=float32)
--------------------
enc_out: tf.Tensor(
[[[ 1.2521563   0.3273945  -1.5237452  -0.0558054 ]
  [-1.0591918  -0.42765176 -0.14816867  1.6350121 ]
  [ 0.299005    1.3632457  -1.4101827  -0.252068  ]
  [ 0.7023785  -1.479373   -0.32433346  1.1013279 ]
  [-1.6220697   1.0153029   0.02592759  0.5808392 ]
  [-1.0757908  -0.7200314   0.30136684  1.4944555 ]
  [-0.22072682  1.5675467  -1.215218   -0.1316019 ]
  [-0.22072682  1.5675467  -1.215218   -0.1316019 ]]

 [[ 1.475371    0.30539253 -1.1591307  -0.6216327 ]
  [-1.4569639   0.00421676  0.08528362  1.3674635 ]
  [ 0.61611307  1.3085197  -0.79488575 -1.1297472 ]
  [ 0.80156547  0.9995991  -1.5072922  -0.29387245]
  [-0.11611538  1.6353902  -1.0406278  -0.47864679]
  [ 0.9602699  -0.3459822   0.8696089  -1.4838965 ]
  [-1.6676238   0.9936579   0.2892594   0.38470644]
  [-1.2698565  -0.67637944  1.1073651   0.8388707 ]]], shape=(2, 8, 4), dtype=float32)
--------------------
dec_out: tf.Tensor(
[[[-0.4073423  -1.3681166   0.4482983   1.3271605 ]
  [ 0.9023904  -1.6660724   0.1386456   0.6250363 ]
  [-0.68705463  0.04485544 -0.9672582   1.6094574 ]
  [ 0.40446007  0.7378753  -1.7199682   0.5776328 ]
  [ 0.66626793 -0.7429294  -1.1866593   1.2633208 ]
  [ 1.3847514   0.0595071  -0.00241444 -1.441844  ]
  [ 0.77179515 -0.15832207 -1.5698854   0.9564123 ]
  [ 0.19740774  0.9835156  -1.6620107   0.4810872 ]
  [ 0.19740774  0.9835156  -1.6620107   0.4810872 ]
  [ 0.19740774  0.9835156  -1.6620107   0.4810872 ]]

 [[-0.35176337 -1.3861214   0.39734656  1.3405383 ]
  [ 1.0155624   0.28156188 -1.6605129   0.36338854]
  [ 0.9295503  -0.96635836 -1.0307404   1.0675484 ]
  [ 1.2389433  -0.7855455  -1.1608163   0.70741844]
  [ 0.11645091 -1.565496    0.23167732  1.2173678 ]
  [-0.44791234 -1.3678643   1.2819183   0.53385824]
  [-0.05676413  0.90384555  0.7641177  -1.611199  ]
  [-0.4362856  -1.3157362   1.397403    0.35461882]
  [ 0.21431251 -0.8140781   1.5471766  -0.94741106]
  [ 0.4220932  -0.4875322  -1.3055642   1.3710032 ]]], shape=(2, 10, 4), dtype=float32)
--------------------
dec_self_attn_weights.shape: (2, 2, 10, 10)
dec_enc_attn_weights: (2, 2, 10, 8)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>跟 Encoder layer 相同，Decoder layer 輸出張量的最後一維也是 <code>d_model</code>。而 <code>dec_self_attn_weights</code> 則代表著 Decoder layer 的自注意權重，因此最後兩個維度皆為中文序列的長度 <code>10</code>；而 <code>dec_enc_attn_weights</code> 因為 Encoder 輸出序列的長度為 <code>8</code>，最後一維即爲 <code>8</code>。</p>
<p>都讀到這裡了，判斷每一維的物理意義對你來說應該是小菜一碟了。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Positional-encoding：神奇數字">Positional encoding：神奇數字<a class="anchor-link" href="#Positional-encoding：神奇數字">&para;</a></h3><p>透過多層的自注意力層，Transformer 在處理序列時裡頭所有子詞都是「天涯若比鄰」：想要關注序列中<strong>任何</strong>位置的資訊只要 O(1) 就能辦到。這讓 Transformer 能很好地 model 序列中長距離的依賴關係（long-range dependencise）。但反過來說 Transformer 則無法 model 序列中字詞的順序關係，所以我們得額外加入一些「位置資訊」給 Transformer。</p>
<p>這個資訊被稱作位置編碼（Positional Encoding），實作上是直接加到最一開始的英文 / 中文詞嵌入向量（word embedding）裡頭。其直觀的想法是想辦法讓被加入位置編碼的 word embedding 在 <code>d_model</code> 維度的空間裡頭不只會因為<strong>語義相近</strong>而靠近，也會因為<strong>位置靠近</strong>而在該空間裡頭靠近。</p>
<p>論文裡頭使用的位置編碼的公式如下：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<img src="https://leemeng.tw/images/transformer/position-encoding-equation.jpg" style="mix-blend-mode: initial;"/>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>嗯 ... 第一次看到這函式的人會黑人問號是很正常。</p>
<p><a href="https://arxiv.org/pdf/1706.03762.pdf">論文裡頭提到</a>他們之所以這樣設計位置編碼（<strong>P</strong>ositional <strong>E</strong>ncoding, PE）是因為這個函數有個很好的特性：給定任一位置 <code>pos</code> 的位置編碼 <code>PE(pos)</code>，跟它距離 <code>k</code> 個單位的位置 <code>pos + k</code> 的位置編碼 <code>PE(pos + k)</code> 可以表示為 <code>PE(pos)</code> 的一個線性函數（linear function）。</p>
<p>因此透過在 word embedding 裡加入這樣的資訊，作者們認為可以幫助 Transformer 學會 model 序列中的子詞的相對位置關係。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        子曰：「由！誨女知之乎？知之為知之，不知為不知，是知也。」
                        <br/>
<span style="float:right;margin-right: 1.5rem">─ 《論語 為政篇》</span>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>就算我們無法自己想出論文裡頭的位置編碼公式，還是可以直接把 <a href="https://www.tensorflow.org/beta/tutorials/text/transformer#positional_encoding">TensorFlow 官方</a>的實作搬過來使用：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 以下直接參考 TensorFlow 官方 tutorial </span>
<span class="k">def</span> <span class="nf">get_angles</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">d_model</span><span class="p">):</span>
  <span class="n">angle_rates</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span><span class="o">//</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">d_model</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">pos</span> <span class="o">*</span> <span class="n">angle_rates</span>

<span class="k">def</span> <span class="nf">positional_encoding</span><span class="p">(</span><span class="n">position</span><span class="p">,</span> <span class="n">d_model</span><span class="p">):</span>
  <span class="n">angle_rads</span> <span class="o">=</span> <span class="n">get_angles</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">position</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
                          <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">d_model</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:],</span>
                          <span class="n">d_model</span><span class="p">)</span>
  
  <span class="c1"># apply sin to even indices in the array; 2i</span>
  <span class="n">sines</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angle_rads</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">])</span>
  
  <span class="c1"># apply cos to odd indices in the array; 2i+1</span>
  <span class="n">cosines</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angle_rads</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">])</span>
  
  <span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">sines</span><span class="p">,</span> <span class="n">cosines</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
  
  <span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">pos_encoding</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
    
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">pos_encoding</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>


<span class="n">seq_len</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">512</span>

<span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">positional_encoding</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
<span class="n">pos_encoding</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: id=194541, shape=(1, 50, 512), dtype=float32, numpy=
array([[[ 0.        ,  0.        ,  0.        , ...,  1.        ,
          1.        ,  1.        ],
        [ 0.84147096,  0.8218562 ,  0.8019618 , ...,  1.        ,
          1.        ,  1.        ],
        [ 0.9092974 ,  0.9364147 ,  0.95814437, ...,  1.        ,
          1.        ,  1.        ],
        ...,
        [ 0.12357312,  0.97718984, -0.24295525, ...,  0.9999863 ,
          0.99998724,  0.99998814],
        [-0.76825464,  0.7312359 ,  0.63279754, ...,  0.9999857 ,
          0.9999867 ,  0.9999876 ],
        [-0.95375264, -0.14402692,  0.99899054, ...,  0.9999851 ,
          0.9999861 ,  0.9999871 ]]], dtype=float32)&gt;</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>一路看下來你應該也可以猜到位置編碼的每一維意義了：</p>
<ul>
<li>第 1 維代表 batch_size，之後可以 broadcasting</li>
<li>第 2 維是序列長度，我們會為每個在輸入 / 輸出序列裡頭的子詞都加入位置編碼</li>
<li>第 3 維跟詞嵌入向量同維度</li>
</ul>
<p>因為是要跟詞嵌入向量相加，位置編碼的維度也得是 <code>d_model</code>。我們也可以把位置編碼畫出感受一下：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">pcolormesh</span><span class="p">(</span><span class="n">pos_encoding</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'RdBu'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'d_model'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Position'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<img src="https://leemeng.tw/images/transformer/positional-encoding.jpg"/>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>這圖你應該在很多教學文章以及教授的影片裡都看過了。就跟我們前面看過的各種 2 維矩陣相同，x 軸代表著跟詞嵌入向量相同的維度 <code>d_model</code>，y 軸則代表序列中的每個位置。之後我們會看輸入 / 輸出序列有多少個子詞，就加入幾個位置編碼。</p>
<p>關於位置編碼我們現在只需要知道這些就夠了，但如果你想知道更多相關的數學計算，可以參考<a href="https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb">這個筆記本</a>。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Encoder">Encoder<a class="anchor-link" href="#Encoder">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Encoder 裡頭主要包含了 3 個元件：</p>
<ul>
<li>輸入的詞嵌入層</li>
<li>位置編碼</li>
<li>N 個 Encoder layers</li>
</ul>
<p>大部分的工作都交給 Encoder layer 小弟做了，因此 Encoder 的實作很單純：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="c1"># Encoder 的初始參數除了本來就要給 EncoderLayer 的參數還多了：</span>
  <span class="c1"># - num_layers: 決定要有幾個 EncoderLayers, 前面影片中的 `N`</span>
  <span class="c1"># - input_vocab_size: 用來把索引轉成詞嵌入向量</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">input_vocab_size</span><span class="p">,</span> 
               <span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">positional_encoding</span><span class="p">(</span><span class="n">input_vocab_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
    
    <span class="c1"># 建立 `num_layers` 個 EncoderLayers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">EncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">rate</span><span class="p">)</span> 
                       <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)]</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
        
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="c1"># 輸入的 x.shape == (batch_size, input_seq_len)</span>
    <span class="c1"># 以下各 layer 的輸出皆為 (batch_size, input_seq_len, d_model)</span>
    <span class="n">input_seq_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># 將 2 維的索引序列轉成 3 維的詞嵌入張量，並依照論文乘上 sqrt(d_model)</span>
    <span class="c1"># 再加上對應長度的位置編碼</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span><span class="p">[:,</span> <span class="p">:</span><span class="n">input_seq_len</span><span class="p">,</span> <span class="p">:]</span>

    <span class="c1"># 對 embedding 跟位置編碼的總合做 regularization</span>
    <span class="c1"># 這在 Decoder 也會做</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    
    <span class="c1"># 通過 N 個 EncoderLayer 做編碼</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">enc_layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_layers</span><span class="p">):</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">enc_layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
      <span class="c1"># 以下只是用來 demo EncoderLayer outputs</span>
      <span class="c1">#print('-' * 20)</span>
      <span class="c1">#print(f"EncoderLayer {i + 1}'s output:", x)</span>
      
    
    <span class="k">return</span> <span class="n">x</span> 
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>比較值得注意的是我們依照論文將 word embedding 乘上 <code>sqrt(d_model)</code>，並在 embedding 跟位置編碼相加以後通過 dropout 層來達到 regularization 的效果。</p>
<p>現在我們可以直接將索引序列 <code>inp</code> 丟入 Encoder：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 超參數</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># 2 層的 Encoder</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">num_heads</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">dff</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">input_vocab_size</span> <span class="o">=</span> <span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">2</span> <span class="c1"># 記得加上 &lt;start&gt;, &lt;end&gt;</span>

<span class="c1"># 初始化一個 Encoder</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">input_vocab_size</span><span class="p">)</span>

<span class="c1"># 將 2 維的索引序列丟入 Encoder 做編碼</span>
<span class="n">enc_out</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"inp:"</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"enc_out:"</span><span class="p">,</span> <span class="n">enc_out</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>inp: tf.Tensor(
[[8135  105   10 1304 7925 8136    0    0]
 [8135   17 3905 6013   12 2572 7925 8136]], shape=(2, 8), dtype=int64)
--------------------
enc_out: tf.Tensor(
[[[-0.80654097 -0.5846039  -0.31439844  1.7055433 ]
  [-0.46891153 -0.57408124 -0.6840381   1.727031  ]
  [-0.319709   -0.17782518 -1.1191479   1.616682  ]
  [-0.49274105  0.26990706 -1.2412689   1.4641027 ]
  [-0.88477194  0.16279429 -0.8493918   1.5713693 ]
  [-0.96625364 -0.25279218 -0.4533522   1.6723981 ]
  [-0.8476429  -0.5615218  -0.28872433  1.6978891 ]
  [-0.61957765 -0.5919263  -0.51938564  1.7308894 ]]

 [[-0.8083886  -0.56457365 -0.33460823  1.7075704 ]
  [-0.50152016 -0.5214133  -0.7037289   1.7266623 ]
  [-0.34244898 -0.11313835 -1.1444559   1.6000432 ]
  [-0.5072439   0.21401608 -1.2050328   1.4982607 ]
  [-0.88611245  0.26368466 -0.9036027   1.5260304 ]
  [-0.96629447 -0.21083635 -0.49055386  1.6676848 ]
  [-0.86832803 -0.5383212  -0.28836083  1.6950101 ]
  [-0.6246328  -0.57586765 -0.5305909   1.7310913 ]]], shape=(2, 8, 4), dtype=float32)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>注意因為 Encoder 已經包含了詞嵌入層，因此我們不用再像呼叫 <a href="#Encoder-的小弟">Encoder layer</a> 時一樣還得自己先做 word embedding。現在的輸入及輸出張量為：</p>
<ul>
<li>輸入：（batch_size, seq_len）</li>
<li>輸出：（batch_size, seq_len, d_model）</li>
</ul>
<p>有了 Encoder，我們之後就可以直接把 2 維的索引序列 <code>inp</code> 丟入 Encoder，讓它幫我們把裡頭所有的英文序列做一連串的轉換。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoder">Decoder<a class="anchor-link" href="#Decoder">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Decoder layer 本來就只跟 Encoder layer 差在一個 MHA，而這邏輯被包起來以後呼叫它的 Decoder 做的事情就跟 Encoder 基本上沒有兩樣了。</p>
<p>在 Decoder 裡頭我們只需要建立一個專門給中文用的詞嵌入層以及位置編碼即可。我們在呼叫每個 Decoder layer 的時候也順便把其注意權重存下來，方便我們了解模型訓練完後是怎麼做翻譯的。</p>
<p>以下則是實作：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="c1"># 初始參數跟 Encoder 只差在用 `target_vocab_size` 而非 `inp_vocab_size`</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span> 
               <span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
    
    <span class="c1"># 為中文（目標語言）建立詞嵌入層</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">positional_encoding</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">dec_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">DecoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">rate</span><span class="p">)</span> 
                       <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
  
  <span class="c1"># 呼叫時的參數跟 DecoderLayer 一模一樣</span>
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> 
           <span class="n">combined_mask</span><span class="p">,</span> <span class="n">inp_padding_mask</span><span class="p">):</span>
    
    <span class="n">tar_seq_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">attention_weights</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># 用來存放每個 Decoder layer 的注意權重</span>
    
    <span class="c1"># 這邊跟 Encoder 做的事情完全一樣</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># (batch_size, tar_seq_len, d_model)</span>
    <span class="n">x</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span><span class="p">[:,</span> <span class="p">:</span><span class="n">tar_seq_len</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>

    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dec_layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dec_layers</span><span class="p">):</span>
      <span class="n">x</span><span class="p">,</span> <span class="n">block1</span><span class="p">,</span> <span class="n">block2</span> <span class="o">=</span> <span class="n">dec_layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span>
                                    <span class="n">combined_mask</span><span class="p">,</span> <span class="n">inp_padding_mask</span><span class="p">)</span>
      
      <span class="c1"># 將從每個 Decoder layer 取得的注意權重全部存下來回傳，方便我們觀察</span>
      <span class="n">attention_weights</span><span class="p">[</span><span class="s1">'decoder_layer</span><span class="si">{}</span><span class="s1">_block1'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">block1</span>
      <span class="n">attention_weights</span><span class="p">[</span><span class="s1">'decoder_layer</span><span class="si">{}</span><span class="s1">_block2'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">block2</span>
    
    <span class="c1"># x.shape == (batch_size, tar_seq_len, d_model)</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">attention_weights</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>接著讓我們初始並呼叫一個 Decoder 看看：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 超參數</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># 2 層的 Decoder</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">num_heads</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">dff</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">target_vocab_size</span> <span class="o">=</span> <span class="n">subword_encoder_zh</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">2</span> <span class="c1"># 記得加上 &lt;start&gt;, &lt;end&gt;</span>

<span class="c1"># 遮罩</span>
<span class="n">inp_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="n">tar_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">tar</span><span class="p">)</span>
<span class="n">look_ahead_mask</span> <span class="o">=</span> <span class="n">create_look_ahead_mask</span><span class="p">(</span><span class="n">tar</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">combined_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">tar_padding_mask</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">)</span>

<span class="c1"># 初始化一個 Decoder</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">)</span>

<span class="c1"># 將 2 維的索引序列以及遮罩丟入 Decoder</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"tar:"</span><span class="p">,</span> <span class="n">tar</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"combined_mask:"</span><span class="p">,</span> <span class="n">combined_mask</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"enc_out:"</span><span class="p">,</span> <span class="n">enc_out</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"inp_padding_mask:"</span><span class="p">,</span> <span class="n">inp_padding_mask</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">dec_out</span><span class="p">,</span> <span class="n">attn</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">tar</span><span class="p">,</span> <span class="n">enc_out</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                        <span class="n">combined_mask</span><span class="o">=</span><span class="n">combined_mask</span><span class="p">,</span>
                        <span class="n">inp_padding_mask</span><span class="o">=</span><span class="n">inp_padding_mask</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"dec_out:"</span><span class="p">,</span> <span class="n">dec_out</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="k">for</span> <span class="n">block_name</span><span class="p">,</span> <span class="n">attn_weights</span> <span class="ow">in</span> <span class="n">attn</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{block_name}</span><span class="s2">.shape: </span><span class="si">{attn_weights.shape}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>tar: tf.Tensor(
[[4201   10  241   80   27    3 4202    0    0    0]
 [4201  162  467  421  189   14    7  553    3 4202]], shape=(2, 10), dtype=int64)
--------------------
combined_mask: tf.Tensor(
[[[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]


 [[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 10, 10), dtype=float32)
--------------------
enc_out: tf.Tensor(
[[[-0.80654097 -0.5846039  -0.31439844  1.7055433 ]
  [-0.46891153 -0.57408124 -0.6840381   1.727031  ]
  [-0.319709   -0.17782518 -1.1191479   1.616682  ]
  [-0.49274105  0.26990706 -1.2412689   1.4641027 ]
  [-0.88477194  0.16279429 -0.8493918   1.5713693 ]
  [-0.96625364 -0.25279218 -0.4533522   1.6723981 ]
  [-0.8476429  -0.5615218  -0.28872433  1.6978891 ]
  [-0.61957765 -0.5919263  -0.51938564  1.7308894 ]]

 [[-0.8083886  -0.56457365 -0.33460823  1.7075704 ]
  [-0.50152016 -0.5214133  -0.7037289   1.7266623 ]
  [-0.34244898 -0.11313835 -1.1444559   1.6000432 ]
  [-0.5072439   0.21401608 -1.2050328   1.4982607 ]
  [-0.88611245  0.26368466 -0.9036027   1.5260304 ]
  [-0.96629447 -0.21083635 -0.49055386  1.6676848 ]
  [-0.86832803 -0.5383212  -0.28836083  1.6950101 ]
  [-0.6246328  -0.57586765 -0.5305909   1.7310913 ]]], shape=(2, 8, 4), dtype=float32)
--------------------
inp_padding_mask: tf.Tensor(
[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]


 [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)
--------------------
dec_out: tf.Tensor(
[[[-0.5437632  -1.055963    1.6090912  -0.0093651 ]
  [-0.35729456 -1.2363737   1.5295789   0.06408926]
  [ 0.35950443 -1.4217519   1.3327445  -0.27049693]
  [ 0.00910451 -1.3681054   1.4556323  -0.09663116]
  [-0.39842203 -1.0891637   1.6237149  -0.13612938]
  [-0.41910946 -1.0254465   1.6521797  -0.20762381]
  [-0.36797434 -1.036104    1.6521349  -0.2480565 ]
  [-0.19375193 -1.1218892   1.6165614  -0.30092025]
  [ 0.40127647 -1.3597702   1.3540744  -0.39558053]
  [ 0.17590097 -1.419068    1.3905344  -0.14736754]]

 [[-0.54991776 -1.0509207   1.6102997  -0.00946123]
  [-0.3790077  -1.2450974   1.514628    0.10947719]
  [ 0.1746773  -1.3877552   1.415193   -0.20211506]
  [-0.03870562 -1.3375971   1.4825788  -0.10627584]
  [-0.43508232 -1.067575    1.6293938  -0.12673649]
  [-0.41048303 -1.0317237   1.6503688  -0.20816201]
  [-0.3626595  -1.0360833   1.652463   -0.25372016]
  [-0.24817836 -1.1092765   1.6238651  -0.26641032]
  [ 0.1850568  -1.3670969   1.4271388  -0.2450987 ]
  [ 0.09142628 -1.3988855   1.4218552  -0.11439597]]], shape=(2, 10, 4), dtype=float32)
--------------------
decoder_layer1_block1.shape: (2, 2, 10, 10)
decoder_layer1_block2.shape: (2, 2, 10, 8)
decoder_layer2_block1.shape: (2, 2, 10, 10)
decoder_layer2_block2.shape: (2, 2, 10, 8)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>麻雀雖小，五臟俱全。雖然我們是使用 demo 數據，但基本上這就是你在呼叫 Decoder 時需要做的所有事情：</p>
<ul>
<li>初始時給它中文（目標語言）的字典大小、其他超參數</li>
<li>輸入中文 batch 的索引序列</li>
<li>也要輸入兩個遮罩以及 Encoder 輸出 <code>enc_out</code></li>
</ul>
<p>Decoder 的輸出你現在應該都可以很輕鬆地解讀才是。基本上跟 Decoder layer 一模一樣，只差在我們額外輸出一個 Python dict，裡頭存放所有 Decoder layers 的注意權重。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="第一個-Transformer">第一個 Transformer<a class="anchor-link" href="#第一個-Transformer">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>沒錯，終於到了這個時刻。在實作 Transformer 之前先點擊影片來簡單回顧一下我們在這一章實作了什麼些玩意兒：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/transformer-imple.jpg">
<source src="https://leemeng.tw/images/transformer/transformer-imple.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        Transformer 本身只有 3 個 layers
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在我們前面已經將大大小小的 layers 一一實作並組裝起來以後，真正的 Transformer  模型只需要 3 個元件：</p>
<ol>
<li>Encoder </li>
<li>Decoder</li>
<li>Final linear layer</li>
</ol>
<p>馬上讓我們看看 Transformer  的實作：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Transformer 之上已經沒有其他 layers 了，我們使用 tf.keras.Model 建立一個模型</span>
<span class="k">class</span> <span class="nc">Transformer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
  <span class="c1"># 初始參數包含 Encoder &amp; Decoder 都需要超參數以及中英字典數目</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">input_vocab_size</span><span class="p">,</span> 
               <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Transformer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> 
                           <span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">rate</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> 
                           <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">rate</span><span class="p">)</span>
    <span class="c1"># 這個 FFN 輸出跟中文字典一樣大的 logits 數，等通過 softmax 就代表每個中文字的出現機率</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">final_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">)</span>
  
  <span class="c1"># enc_padding_mask 跟 dec_padding_mask 都是英文序列的 padding mask，</span>
  <span class="c1"># 只是一個給 Encoder layer 的 MHA 用，一個是給 Decoder layer 的 MHA 2 使用</span>
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">enc_padding_mask</span><span class="p">,</span> 
           <span class="n">combined_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span><span class="p">):</span>

    <span class="n">enc_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">enc_padding_mask</span><span class="p">)</span>  <span class="c1"># (batch_size, inp_seq_len, d_model)</span>
    
    <span class="c1"># dec_output.shape == (batch_size, tar_seq_len, d_model)</span>
    <span class="n">dec_output</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span>
        <span class="n">tar</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">combined_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span><span class="p">)</span>
    
    <span class="c1"># 將 Decoder 輸出通過最後一個 linear layer</span>
    <span class="n">final_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_layer</span><span class="p">(</span><span class="n">dec_output</span><span class="p">)</span>  <span class="c1"># (batch_size, tar_seq_len, target_vocab_size)</span>
    
    <span class="k">return</span> <span class="n">final_output</span><span class="p">,</span> <span class="n">attention_weights</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>扣掉註解，Transformer 的實作本身非常簡短。</p>
<p>被輸入 Transformer 的多個 2 維英文張量 <code>inp</code> 會一路通過 <strong>Encoder</strong> 裡頭的詞嵌入層，位置編碼以及 N 個 Encoder layers 後被轉換成 Encoder 輸出 <code>enc_output</code>，接著對應的中文序列 <code>tar</code> 則會在 <strong>Decoder</strong> 裡頭走過相似的旅程並在每一層的 Decoder layer 利用 MHA 2 關注 Encoder 的輸出 <code>enc_output</code>，最後被 Decoder 輸出。</p>
<p>而 Decoder 的輸出 <code>dec_output</code> 則會通過 <strong>Final linear layer</strong>，被轉成進入 Softmax 前的 logits <code>final_output</code>，其 logit 的數目則跟中文字典裡的子詞數相同。</p>
<p>因為 Transformer 把 Decoder 也包起來了，現在我們連 Encoder 輸出 <code>enc_output</code> 也不用管，只要把英文（來源）以及中文（目標）的索引序列 batch 丟入 Transformer，它就會輸出最後一維為中文字典大小的張量。第 2 維是輸出序列，裡頭每一個位置的向量就代表著該位置的中文字的機率分佈（事實上通過 softmax 才是，但這邊先這樣說方便你理解）：</p>
<ul>
<li>輸入：<ul>
<li>英文序列：（batch_size, inp_seq_len）</li>
<li>中文序列：（batch_size, tar_seq_len）</li>
</ul>
</li>
<li>輸出：<ul>
<li>生成序列：（batch_size, tar_seq_len, target_vocab_size）</li>
<li>注意權重的 dict</li>
</ul>
</li>
</ul>
<p>讓我們馬上建一個 Transformer，並假設我們已經準備好用 demo 數據來訓練它做英翻中：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 超參數</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">num_heads</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">dff</span> <span class="o">=</span> <span class="mi">8</span>

<span class="c1"># + 2 是為了 &lt;start&gt; &amp; &lt;end&gt; token</span>
<span class="n">input_vocab_size</span> <span class="o">=</span> <span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">2</span>
<span class="n">output_vocab_size</span> <span class="o">=</span> <span class="n">subword_encoder_zh</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">2</span>

<span class="c1"># 重點中的重點。訓練時用前一個字來預測下一個中文字</span>
<span class="n">tar_inp</span> <span class="o">=</span> <span class="n">tar</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">tar_real</span> <span class="o">=</span> <span class="n">tar</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>

<span class="c1"># 來源 / 目標語言用的遮罩。注意 `comined_mask` 已經將目標語言的兩種遮罩合而為一</span>
<span class="n">inp_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="n">tar_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">tar_inp</span><span class="p">)</span>
<span class="n">look_ahead_mask</span> <span class="o">=</span> <span class="n">create_look_ahead_mask</span><span class="p">(</span><span class="n">tar_inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">combined_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">tar_padding_mask</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">)</span>

<span class="c1"># 初始化我們的第一個 transformer</span>
<span class="n">transformer</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> 
                          <span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">output_vocab_size</span><span class="p">)</span>

<span class="c1"># 將英文、中文序列丟入取得 Transformer 預測下個中文字的結果</span>
<span class="n">predictions</span><span class="p">,</span> <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">transformer</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar_inp</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">inp_padding_mask</span><span class="p">,</span> 
                                        <span class="n">combined_mask</span><span class="p">,</span> <span class="n">inp_padding_mask</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"tar:"</span><span class="p">,</span> <span class="n">tar</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"tar_inp:"</span><span class="p">,</span> <span class="n">tar_inp</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"tar_real:"</span><span class="p">,</span> <span class="n">tar_real</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"predictions:"</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>tar: tf.Tensor(
[[4201   10  241   80   27    3 4202    0    0    0]
 [4201  162  467  421  189   14    7  553    3 4202]], shape=(2, 10), dtype=int64)
--------------------
tar_inp: tf.Tensor(
[[4201   10  241   80   27    3 4202    0    0]
 [4201  162  467  421  189   14    7  553    3]], shape=(2, 9), dtype=int64)
--------------------
tar_real: tf.Tensor(
[[  10  241   80   27    3 4202    0    0    0]
 [ 162  467  421  189   14    7  553    3 4202]], shape=(2, 9), dtype=int64)
--------------------
predictions: tf.Tensor(
[[[ 0.00929452 -0.01123782  0.05421777 ... -0.01170466  0.00628542
   -0.07576236]
  [ 0.03640017 -0.01885041  0.05113849 ... -0.02349908  0.01716622
   -0.06729948]
  [ 0.05617092 -0.02265774  0.04667147 ... -0.02913139  0.0241506
   -0.05331099]
  ...
  [ 0.00905135 -0.01058669  0.05486142 ... -0.01039154  0.0058039
   -0.07445519]
  [ 0.02215609 -0.01478041  0.05375389 ... -0.0170105   0.01135763
   -0.07241639]
  [ 0.0478656  -0.02148081  0.04837158 ... -0.02759764  0.02148173
   -0.06043392]]

 [[ 0.00996658 -0.01115559  0.05453676 ... -0.0114185   0.00637141
   -0.07500792]
  [ 0.03897631 -0.01930442  0.0508956  ... -0.02409907  0.01803425
   -0.0656432 ]
  [ 0.05387272 -0.02244362  0.04702405 ... -0.02893805  0.02348556
   -0.05554678]
  ...
  [ 0.01048942 -0.01085559  0.05502523 ... -0.01070841  0.0062833
   -0.07385261]
  [ 0.02370835 -0.01504852  0.05381611 ... -0.01732858  0.01186723
   -0.07158875]
  [ 0.04920105 -0.02166032  0.0481827  ... -0.02781233  0.02190085
   -0.05933255]]], shape=(2, 9, 4203), dtype=float32)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>有了前面的各種 layers，建立一個 Transformer 並不難。但要輸入什麼數據就是一門大學問了：</p>
<div class="highlight"><pre><span></span><span class="o">...</span>

<span class="n">tar_inp</span> <span class="o">=</span> <span class="n">tar</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">tar_real</span> <span class="o">=</span> <span class="n">tar</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>

<span class="n">predictions</span><span class="p">,</span> <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">transformer</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar_inp</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>

<span class="o">...</span>
</pre></div>
<p>為何是丟少了尾巴一個字的 <code>tar_inp</code> 序列進去 Transformer，而不是直接丟 <code>tar</code> 呢？</p>
<p>別忘記我們才剛初始一個 Transformer，裡頭所有 layers 的權重都是隨機的，你可不能指望它真的會什麼「黑魔法」來幫你翻譯。我們得先訓練才行。但訓練時如果你把整個正確的中文序列 <code>tar</code>都進去給 Transformer 看，你期待它產生什麼？一首新的中文詩嗎？</p>
<p>如果你曾經實作過序列生成模型或是看過<a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html">我之前的語言模型文章</a>，就會知道在序列生成任務裡頭，模型獲得的正確答案是輸入序列往左位移一個位置的結果。</p>
<p>這樣講很抽象，讓我們看個影片了解序列生成是怎麼運作的：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/how-sequence-generation-work.jpg">
<source src="https://leemeng.tw/images/transformer/how-sequence-generation-work.mp4" type="video/mp4"/>
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                </video>
<center>
                        了解序列生成以及如何訓練一個生成模型
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>你現在應該明白 Transformer 在訓練的時候並不是吃整個中文序列，而是吃一個去掉尾巴的序列 <code>tar_inp</code>，然後試著去預測「左移」一個字以後的序列 <code>tar_real</code>。同樣概念當然也可以運用到以 RNN 或是 CNN-based 的模型上面。</p>
<p>從影片中你也可以發現給定 <code>tar_inp</code> 序列中的任一位置，其對應位置的 <code>tar_real</code> 就是下個時間點模型應該要預測的中文字。</p>
<p>序列生成任務可以被視為是一個分類任務（Classification），而每一個中文字都是一個分類。而 Transformer 就是要去產生一個中文字的機率分佈，想辦法跟正解越接近越好。</p>
<p>跟用已訓練的 Transformer 做<strong>預測</strong>時不同，在<strong>訓練</strong>時為了穩定模型表現，我們並不會將 Transformer 的輸出再度丟回去當做其輸入（人形蜈蚣？），而是像影片中所示，給它左移一個位置後的序列 <code>tar_real</code> 當作正解讓它去最小化 error。</p>
<p>這種無視模型預測結果，而將正確解答丟入的訓練方法一般被稱作 <a href="https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/">teacher forcing</a>。你也可以參考教授的 <a href="https://youtu.be/ZjfjPzXw6og?t=1952">Sequence-to-sequence Learning 教學</a>。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="定義損失函數與指標_1">定義損失函數與指標<a class="anchor-link" href="#定義損失函數與指標">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>因為被視為是一個分類任務，我們可以使用 cross entropy 來計算序列生成任務中實際的中文字跟模型預測的中文字分佈（distribution）相差有多遠。</p>
<p>這邊簡單定義一個損失函式：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">loss_object</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span>
    <span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">'none'</span><span class="p">)</span>

<span class="c1"># 假設我們要解的是一個 binary classifcation， 0 跟 1 個代表一個 label</span>
<span class="n">real</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">loss_object</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: id=197487, shape=(3,), dtype=float32, numpy=array([0.31326166, 0.31326166, 1.3132616 ], dtype=float32)&gt;</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>如果你曾做過分類問題，應該能看出預測序列 <code>pred</code> 裡頭的第 3 個預測結果出錯因此 entropy 值上升。損失函數 <code>loss_object</code> 做的事情就是比較 2 個序列並計算 cross entropy：</p>
<ul>
<li><code>real</code>：一個包含 N 個正確 labels 的序列</li>
<li><code>pred</code>：一個包含 N 個維度為 label 數的 logit 序列</li>
</ul>
<p>我們在這邊將 <code>reduction</code> 參數設為 <code>none</code>，請 <code>loss_object</code> 不要把每個位置的 error 加總。而這是因為我們之後要自己把 <code>&lt;pad&gt;</code> token 出現的位置的損失捨棄不計。</p>
<p>而將 <code>from_logits</code> 參數設為 <code>True</code> 是因為從 Transformer 得到的預測還沒有經過 softmax，因此加總還不等於 1：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"predictions:"</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>predictions: tf.Tensor(
[[[ 0.00929452 -0.01123782  0.05421777 ... -0.01170466  0.00628542
   -0.07576236]
  [ 0.03640017 -0.01885041  0.05113849 ... -0.02349908  0.01716622
   -0.06729948]
  [ 0.05617092 -0.02265774  0.04667147 ... -0.02913139  0.0241506
   -0.05331099]
  ...
  [ 0.00905135 -0.01058669  0.05486142 ... -0.01039154  0.0058039
   -0.07445519]
  [ 0.02215609 -0.01478041  0.05375389 ... -0.0170105   0.01135763
   -0.07241639]
  [ 0.0478656  -0.02148081  0.04837158 ... -0.02759764  0.02148173
   -0.06043392]]

 [[ 0.00996658 -0.01115559  0.05453676 ... -0.0114185   0.00637141
   -0.07500792]
  [ 0.03897631 -0.01930442  0.0508956  ... -0.02409907  0.01803425
   -0.0656432 ]
  [ 0.05387272 -0.02244362  0.04702405 ... -0.02893805  0.02348556
   -0.05554678]
  ...
  [ 0.01048942 -0.01085559  0.05502523 ... -0.01070841  0.0062833
   -0.07385261]
  [ 0.02370835 -0.01504852  0.05381611 ... -0.01732858  0.01186723
   -0.07158875]
  [ 0.04920105 -0.02166032  0.0481827  ... -0.02781233  0.02190085
   -0.05933255]]], shape=(2, 9, 4203), dtype=float32)
--------------------
tf.Tensor(
[[1.4971986 3.1899047 4.1454954 3.7353938 2.869739  1.8605256 1.3746347
  2.2779167 3.8190796]
 [1.4881071 3.303587  4.0757227 3.7524652 2.836317  1.9132937 1.4376438
  2.3432927 3.8689976]], shape=(2, 9), dtype=float32)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>有了 <code>loss_object</code> 實際算 cross entropy 以後，我們需要另外一個函式來建立遮罩並加總序列裡頭不包含 `<pad> token 位置的損失：</pad></p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">pred</span><span class="p">):</span>
  <span class="c1"># 這次的 mask 將序列中不等於 0 的位置視為 1，其餘為 0 </span>
  <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
  <span class="c1"># 照樣計算所有位置的 cross entropy 但不加總</span>
  <span class="n">loss_</span> <span class="o">=</span> <span class="n">loss_object</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
  <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">loss_</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
  <span class="n">loss_</span> <span class="o">*=</span> <span class="n">mask</span>  <span class="c1"># 只計算非 &lt;pad&gt; 位置的損失 </span>
  
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">loss_</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>我另外再定義兩個 <a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/metrics">tf.keras.metrics</a>，方便之後使用 <a href="https://www.tensorflow.org/guide/summaries_and_tensorboard?hl=zh-cn">TensorBoard</a> 來追蹤模型 performance：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">train_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">'train_loss'</span><span class="p">)</span>
<span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">'train_accuracy'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="設置超參數">設置超參數<a class="anchor-link" href="#設置超參數">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>前面實作了那麼多 layers，你應該還記得有哪些是你自己可以調整的超參數吧？</p>
<p>讓我幫你全部列出來：</p>
<ul>
<li><code>num_layers</code> 決定 Transfomer 裡頭要有幾個 Encoder / Decoder layers</li>
<li><code>d_model</code> 決定我們子詞的 representation space 維度</li>
<li><code>num_heads</code> 要做幾頭的自注意力運算</li>
<li><code>dff</code> 決定 FFN 的中間維度</li>
<li><code>dropout_rate</code> 預設 0.1，一般用預設值即可</li>
<li><code>input_vocab_size</code>：輸入語言（英文）的字典大小</li>
<li><code>target_vocab_size</code>：輸出語言（中文）的字典大小</li>
</ul>
<p>論文裡頭最基本的 Transformer 配置為：</p>
<ul>
<li><code>num_layers=6</code></li>
<li><code>d_model=512</code></li>
<li><code>dff=2048</code></li>
</ul>
<p>有大量數據以及大的 Transformer，你可以在很多機器學習任務都達到不錯的成績。為了不要讓訓練時間太長，在這篇文章裡頭我會把 Transformer 裡頭的超參數設小一點：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">num_layers</span> <span class="o">=</span> <span class="mi">4</span> 
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dff</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">num_heads</span> <span class="o">=</span> <span class="mi">8</span>

<span class="n">input_vocab_size</span> <span class="o">=</span> <span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">2</span>
<span class="n">target_vocab_size</span> <span class="o">=</span> <span class="n">subword_encoder_zh</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">2</span>
<span class="n">dropout_rate</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># 預設值</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"input_vocab_size:"</span><span class="p">,</span> <span class="n">input_vocab_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"target_vocab_size:"</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>input_vocab_size: 8137
target_vocab_size: 4203
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>4 層 Encoder / Decoder layers 不算貪心，小巫見大巫（笑</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="設置-Optimizer">設置 Optimizer<a class="anchor-link" href="#設置-Optimizer">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>我們在這邊跟<a href="https://arxiv.org/pdf/1706.03762.pdf">論文</a>一致，使用 <a href="optimization-6be9a291375c">Adam optimizer</a> 以及自定義的 learning rate scheduler：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<img src="https://leemeng.tw/images/transformer/lr-equation.jpg" style="mix-blend-mode: initial;"/>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>這 schedule 讓訓練過程的前 <code>warmup_steps</code> 的 learning rate 線性增加，在那之後則跟步驟數 <code>step_num</code> 的反平方根成比例下降。不用擔心你沒有完全理解這公式，我們一樣可以直接使用 <a href="https://www.tensorflow.org/beta/tutorials/text/transformer?authuser=1#optimizer">TensorFlow 官方教學的實作</a>：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">CustomSchedule</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">schedules</span><span class="o">.</span><span class="n">LearningRateSchedule</span><span class="p">):</span>
  <span class="c1"># 論文預設 `warmup_steps` = 4000</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">4000</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">CustomSchedule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">=</span> <span class="n">warmup_steps</span>
    
  <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
    <span class="n">arg1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
    <span class="n">arg2</span> <span class="o">=</span> <span class="n">step</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">**</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">)</span>
  
<span class="c1"># 將客製化 learning rate schdeule 丟入 Adam opt.</span>
<span class="c1"># Adam opt. 的參數都跟論文相同</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="n">CustomSchedule</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.98</span><span class="p">,</span> 
                                     <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>我們可以觀察看看這個 schedule 是怎麼隨著訓練步驟而改變 learning rate 的：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="n">d_models</span> <span class="o">=</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">]</span>
<span class="n">warmup_steps</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1000</span> <span class="o">*</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)]</span>

<span class="n">schedules</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"blue"</span><span class="p">,</span> <span class="s2">"red"</span><span class="p">,</span> <span class="s2">"black"</span><span class="p">]</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">d_models</span><span class="p">:</span>
  <span class="n">schedules</span> <span class="o">+=</span> <span class="p">[</span><span class="n">CustomSchedule</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">warmup_steps</span><span class="p">]</span>
  <span class="n">labels</span> <span class="o">+=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">"d_model: </span><span class="si">{d}</span><span class="s2">, warm: </span><span class="si">{s}</span><span class="s2">"</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">warmup_steps</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">schedule</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">schedules</span><span class="p">,</span> <span class="n">labels</span><span class="p">)):</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">schedule</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)),</span> 
           <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span> <span class="o">//</span> <span class="mi">3</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"Learning Rate"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"Train Step"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/transformer/transformer-custom-lr.jpg" style="mix-blend-mode: initial;"/>
</center>
<center>
                        不同 d_model 以及 warmup_steps 的 learning rate 變化
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>你可以明顯地看到所有 schedules 都先經過 <code>warmup_steps</code> 個步驟直線提升 learning rate，接著逐漸平滑下降。另外我們也會給比較高維的 <code>d_model</code> 維度比較小的 learning rate。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="實際訓練以及定時存檔">實際訓練以及定時存檔<a class="anchor-link" href="#實際訓練以及定時存檔">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>好啦，什麼都準備齊全了，讓我們開始訓練 Transformer 吧！記得使用前面已經定義好的超參數來初始化一個全新的 Transformer：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">transformer</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span>
                          <span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"""這個 Transformer 有 </span><span class="si">{num_layers}</span><span class="s2"> 層 Encoder / Decoder layers</span>
<span class="s2">d_model: </span><span class="si">{d_model}</span><span class="s2"></span>
<span class="s2">num_heads: </span><span class="si">{num_heads}</span><span class="s2"></span>
<span class="s2">dff: </span><span class="si">{dff}</span><span class="s2"></span>
<span class="s2">input_vocab_size: </span><span class="si">{input_vocab_size}</span><span class="s2"></span>
<span class="s2">target_vocab_size: </span><span class="si">{target_vocab_size}</span><span class="s2"></span>
<span class="s2">dropout_rate: </span><span class="si">{dropout_rate}</span><span class="s2"></span>

<span class="s2">"""</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>這個 Transformer 有 4 層 Encoder / Decoder layers
d_model: 128
num_heads: 8
dff: 512
input_vocab_size: 8137
target_vocab_size: 4203
dropout_rate: 0.1


</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>打遊戲時你會記得要定期存檔以防任何意外發生，訓練深度學習模型也是同樣道理。設置 <a href="https://www.tensorflow.org/beta/guide/checkpoints">checkpoint</a> 來定期儲存 / 讀取模型及 optimizer 是必備的。</p>
<p>我們在底下會定義一個 checkpoint 路徑，此路徑包含了各種超參數的資訊，方便之後比較不同實驗的結果並載入已訓練的進度。我們也需要一個 checkpoint manager 來做所有跟存讀模型有關的雜事，並只保留最新 5 個 checkpoints 以避免佔用太多空間：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 方便比較不同實驗/ 不同超參數設定的結果</span>
<span class="n">run_id</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{num_layers}</span><span class="s2">layers_</span><span class="si">{d_model}</span><span class="s2">d_</span><span class="si">{num_heads}</span><span class="s2">heads_</span><span class="si">{dff}</span><span class="s2">dff_</span><span class="si">{train_perc}</span><span class="s2">train_perc"</span>
<span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">run_id</span><span class="p">)</span>
<span class="n">log_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">log_dir</span><span class="p">,</span> <span class="n">run_id</span><span class="p">)</span>

<span class="c1"># tf.train.Checkpoint 可以幫我們把想要存下來的東西整合起來，方便儲存與讀取</span>
<span class="c1"># 一般來說你會想存下模型以及 optimizer 的狀態</span>
<span class="n">ckpt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">transformer</span><span class="o">=</span><span class="n">transformer</span><span class="p">,</span>
                           <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>

<span class="c1"># ckpt_manager 會去 checkpoint_path 看有沒有符合 ckpt 裡頭定義的東西</span>
<span class="c1"># 存檔的時候只保留最近 5 次 checkpoints，其他自動刪除</span>
<span class="n">ckpt_manager</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">CheckpointManager</span><span class="p">(</span><span class="n">ckpt</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">max_to_keep</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># 如果在 checkpoint 路徑上有發現檔案就讀進來</span>
<span class="k">if</span> <span class="n">ckpt_manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">:</span>
  <span class="n">ckpt</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">ckpt_manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">)</span>
  
  <span class="c1"># 用來確認之前訓練多少 epochs 了</span>
  <span class="n">last_epoch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">ckpt_manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"-"</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'已讀取最新的 checkpoint，模型已訓練 </span><span class="si">{last_epoch}</span><span class="s1"> epochs。'</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">last_epoch</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">"沒找到 checkpoint，從頭訓練。"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>已讀取最新的 checkpoint，模型已訓練 50 epochs。
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<img src="https://leemeng.tw/images/transformer/am-i-a-joke-to-you.jpg"/>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>我知道你在想什麼。</p>
<p>「誒！？ 你不當場訓練嗎？」「直接載入已訓練的模型太狗了吧！」</p>
<p>拜託，我都訓練 N 遍了，每次都重新訓練也太沒意義了。而且你能想像為了寫一個章節我就得重新訓練一個 Transformer 來 demo 嗎？這樣太沒效率了。比起每次重新訓練模型，這才是你在真實世界中應該做的事情：盡可能回復之前的訓練進度來節省時間。</p>
<p>不過放心，我仍會秀出完整的訓練程式碼讓你可以執行第一次的訓練。當你想要依照本文訓練自己的 Transformer 時會感謝有 checkpoint manager 的存在。現在假設我們還沒有 checkpoints。</p>
<p>在實際訓練 Transformer 之前還需要定義一個簡單函式來產生所有的遮罩：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 為 Transformer 的 Encoder / Decoder 準備遮罩</span>
<span class="k">def</span> <span class="nf">create_masks</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">):</span>
  <span class="c1"># 英文句子的 padding mask，要交給 Encoder layer 自注意力機制用的</span>
  <span class="n">enc_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
  
  <span class="c1"># 同樣也是英文句子的 padding mask，但是是要交給 Decoder layer 的 MHA 2 </span>
  <span class="c1"># 關注 Encoder 輸出序列用的</span>
  <span class="n">dec_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
  
  <span class="c1"># Decoder layer 的 MHA1 在做自注意力機制用的</span>
  <span class="c1"># `combined_mask` 是中文句子的 padding mask 跟 look ahead mask 的疊加</span>
  <span class="n">look_ahead_mask</span> <span class="o">=</span> <span class="n">create_look_ahead_mask</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tar</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
  <span class="n">dec_target_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">tar</span><span class="p">)</span>
  <span class="n">combined_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">dec_target_padding_mask</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">)</span>
  
  <span class="k">return</span> <span class="n">enc_padding_mask</span><span class="p">,</span> <span class="n">combined_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>如果沒有本文前面針對遮罩的詳細說明，很多第一次實作的人得花不少時間來確實地掌握這些遮罩的用途。不過對現在的你來說應該也是小菜一碟。</p>
<p>一個數據集包含多個 batch，而每次拿一個 batch 來訓練的步驟就稱作 <code>train_step</code>。為了讓程式碼更簡潔以及容易優化，我們會定義 Transformer 在一次訓練步驟（處理一個 batch）所需要做的所有事情。</p>
<p>不限於 Transformer，一般來說 <code>train_step</code> 函式裡會有幾個重要步驟：</p>
<ol>
<li>對訓練數據做些必要的前處理</li>
<li>將數據丟入模型，取得預測結果</li>
<li>用預測結果跟正確解答計算 loss</li>
<li>取出梯度並利用 optimizer 做梯度下降</li>
</ol>
<p>有了這個概念以後看看程式碼：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>  <span class="c1"># 讓 TensorFlow 幫我們將 eager code 優化並加快運算</span>
<span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">):</span>
  <span class="c1"># 前面說過的，用去尾的原始序列去預測下一個字的序列</span>
  <span class="n">tar_inp</span> <span class="o">=</span> <span class="n">tar</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">tar_real</span> <span class="o">=</span> <span class="n">tar</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
  
  <span class="c1"># 建立 3 個遮罩</span>
  <span class="n">enc_padding_mask</span><span class="p">,</span> <span class="n">combined_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span> <span class="o">=</span> <span class="n">create_masks</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar_inp</span><span class="p">)</span>
  
  <span class="c1"># 紀錄 Transformer 的所有運算過程以方便之後做梯度下降</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
    <span class="c1"># 注意是丟入 `tar_inp` 而非 `tar`。記得將 `training` 參數設定為 True</span>
    <span class="n">predictions</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">transformer</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar_inp</span><span class="p">,</span> 
                                 <span class="kc">True</span><span class="p">,</span> 
                                 <span class="n">enc_padding_mask</span><span class="p">,</span> 
                                 <span class="n">combined_mask</span><span class="p">,</span> 
                                 <span class="n">dec_padding_mask</span><span class="p">)</span>
    <span class="c1"># 跟影片中顯示的相同，計算左移一個字的序列跟模型預測分佈之間的差異，當作 loss</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">tar_real</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

  <span class="c1"># 取出梯度並呼叫前面定義的 Adam optimizer 幫我們更新 Transformer 裡頭可訓練的參數</span>
  <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">transformer</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>    
  <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">transformer</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
  
  <span class="c1"># 將 loss 以及訓練 acc 記錄到 TensorBoard 上，非必要</span>
  <span class="n">train_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
  <span class="n">train_accuracy</span><span class="p">(</span><span class="n">tar_real</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>如果你曾經以TensorFlow 2 實作過稍微複雜一點的模型，應該就知道  <code>train_step</code> 函式的寫法非常固定：</p>
<ul>
<li>對輸入數據做些前處理（本文中的遮罩、將輸出序列左移當成正解 etc.）</li>
<li>利用 <code>tf.GradientTape</code> 輕鬆記錄數據被模型做的所有轉換並計算 loss</li>
<li>將梯度取出並讓 optimzier 對可被訓練的權重做梯度下降（上升）</li>
</ul>
<p>你完全可以用一模一樣的方式將任何複雜模型的處理過程包在 <code>train_step</code> 函式，這樣可以讓我們之後在 iterate 數據集時非常輕鬆。而且最重要的是可以用 <a href="https://www.tensorflow.org/beta/tutorials/eager/tf_function">tf.function</a> 來提高此函式裡頭運算的速度。你可以點擊連結來了解更多。</p>
<p>處理一個 batch 的 <code>train_step</code> 函式也有了，就只差寫個 for loop 將數據集跑個幾遍了。我之前的模型雖然訓練了 50 個 epochs，但事實上大概 30 epochs 翻譯的結果就差不多穩定了。所以讓我們將 <code>EPOCHS</code> 設定為 30：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 定義我們要看幾遍數據集</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">30</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"此超參數組合的 Transformer 已經訓練 </span><span class="si">{last_epoch}</span><span class="s2"> epochs。"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"剩餘 epochs：{min(0, last_epoch - EPOCHS)}"</span><span class="p">)</span>


<span class="c1"># 用來寫資訊到 TensorBoard，非必要但十分推薦</span>
<span class="n">summary_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">create_file_writer</span><span class="p">(</span><span class="n">log_dir</span><span class="p">)</span>

<span class="c1"># 比對設定的 `EPOCHS` 以及已訓練的 `last_epoch` 來決定還要訓練多少 epochs</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">last_epoch</span><span class="p">,</span> <span class="n">EPOCHS</span><span class="p">):</span>
  <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
  
  <span class="c1"># 重置紀錄 TensorBoard 的 metrics</span>
  <span class="n">train_loss</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
  <span class="n">train_accuracy</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
  
  <span class="c1"># 一個 epoch 就是把我們定義的訓練資料集一個一個 batch 拿出來處理，直到看完整個數據集 </span>
  <span class="k">for</span> <span class="p">(</span><span class="n">step_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">))</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">):</span>
    
    <span class="c1"># 每次 step 就是將數據丟入 Transformer，讓它生預測結果並計算梯度最小化 loss</span>
    <span class="n">train_step</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">)</span>  

  <span class="c1"># 每個 epoch 完成就存一次檔    </span>
  <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">ckpt_save_path</span> <span class="o">=</span> <span class="n">ckpt_manager</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
    <span class="nb">print</span> <span class="p">(</span><span class="s1">'Saving checkpoint for epoch </span><span class="si">{}</span><span class="s1"> at </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span>
                                                         <span class="n">ckpt_save_path</span><span class="p">))</span>
    
  <span class="c1"># 將 loss 以及 accuracy 寫到 TensorBoard 上</span>
  <span class="k">with</span> <span class="n">summary_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">"train_loss"</span><span class="p">,</span> <span class="n">train_loss</span><span class="o">.</span><span class="n">result</span><span class="p">(),</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">"train_acc"</span><span class="p">,</span> <span class="n">train_accuracy</span><span class="o">.</span><span class="n">result</span><span class="p">(),</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  
  <span class="nb">print</span><span class="p">(</span><span class="s1">'Epoch </span><span class="si">{}</span><span class="s1"> Loss </span><span class="si">{:.4f}</span><span class="s1"> Accuracy </span><span class="si">{:.4f}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> 
                                                <span class="n">train_loss</span><span class="o">.</span><span class="n">result</span><span class="p">(),</span> 
                                                <span class="n">train_accuracy</span><span class="o">.</span><span class="n">result</span><span class="p">()))</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'Time taken for 1 epoch: </span><span class="si">{}</span><span class="s1"> secs</span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>此超參數組合的 Transformer 已經訓練 50 epochs。
剩餘 epochs：0
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>如訊息所示，當指定的 <code>EPOCHS</code> 「落後」於之前的訓練進度我們就不再訓練了。但如果是第一次訓練或是訓練到指定 <code>EPOCHS</code> 的一部分，我們都會從正確的地方開始訓練並存檔，不會浪費到訓練時間或計算資源。</p>
<p>這邊的邏輯也很簡單，在每個 epoch 都：</p>
<ul>
<li>（非必要）重置寫到 TensorBoard 的 metrics 的值</li>
<li>將整個數據集的 batch 取出，交給 <code>train_step</code> 函式處理</li>
<li>（非必要）存 checkpoints</li>
<li>（非必要）將當前 epoch 結果寫到 TensorBoard</li>
<li>（非必要）在標準輸出顯示當前 epoch 結果</li>
</ul>
<p>是的，如果你真的只是想要訓練個模型，什麼其他事情都不想考慮的話那你可以：</p>
<div class="highlight"><pre><span></span><span class="c1"># 87 分，不能再高了。</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">inp</span><span class="p">,</span> <span class="n">tar</span> <span class="ow">in</span> <span class="n">train_dataset</span><span class="p">:</span>
    <span class="n">train_step</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<img src="https://leemeng.tw/images/transformer/go-home-every-body.jpg"/>
<br/>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>嗯 ... 話是這麼說，但我仍然建議你至少要記得存檔並將訓練過程顯示出來。我知道你會好奇訓練一個這樣的 Transformer 要多久時間，讓我把之前訓練的一些 log 顯示出來給你瞧瞧：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>

Saving checkpoint for epoch 1 at nmt/checkpoints/4layers_128d_8heads_512dff_20train_perc/ckpt-1
Epoch 1 Loss 5.2072 Accuracy 0.0179
Time taken for 1 epoch: 206.54558181762695 secs

Saving checkpoint for epoch 2 at nmt/checkpoints/4layers_128d_8heads_512dff_20train_perc/ckpt-2
Epoch 2 Loss 4.2652 Accuracy 0.0560
Time taken for 1 epoch: 68.48831677436829 secs

Saving checkpoint for epoch 3 at nmt/checkpoints/4layers_128d_8heads_512dff_20train_perc/ckpt-3
Epoch 3 Loss 3.7987 Accuracy 0.0910
Time taken for 1 epoch: 68.41022562980652 secs


...


Saving checkpoint for epoch 29 at nmt/checkpoints/4layers_128d_8heads_512dff_20train_perc/ckpt-29
Epoch 29 Loss 1.2693 Accuracy 0.3929
Time taken for 1 epoch: 69.18679404258728 secs

Saving checkpoint for epoch 30 at nmt/checkpoints/4layers_128d_8heads_512dff_20train_perc/ckpt-30
Epoch 30 Loss 1.2426 Accuracy 0.3965
Time taken for 1 epoch: 68.7313539981842 secs



</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>事實上我們定義的 4 層 Transformer 大約每 70 秒就可以看完一遍有 3 萬筆訓練例子的數據集，而且你從上面的 loss 以及 accuracy 可以看出來 Transformer 至少在訓練集裡頭進步地挺快的。</p>
<p>而就我自己的觀察大約經過 30 個 epochs 翻譯結果就很穩定了。所以你大約只需半個小時就能有一個非常簡單，有點水準的英翻中 Transformer（在至少有個一般 GPU 的情況）。</p>
<p>但跟看上面的 log 比起來，我個人還是比較推薦使用 TensorBoard。在 TensorFlow 2 裡頭，你甚至能直接在 <a href="https://www.tensorflow.org/tensorboard/r2/get_started#using_tensorboard_with_other_methods">Jupyter Notebook 或是 Colab</a> 裡頭開啟它：</p>
<div class="highlight"><pre><span></span><span class="o">%</span><span class="n">load_ext</span> <span class="n">tensorboard</span>
<span class="o">%</span><span class="n">tensorboard</span> <span class="o">--</span><span class="n">logdir</span> <span class="p">{</span><span class="n">your_log_dir</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><video autoplay="" loop="" muted="" playsinline="">
<source src="https://leemeng.tw/images/transformer/tensorboard.mp4" type="video/mp4"/>
</video></p>
<center>
    使用 TensorBoard 可以讓你輕鬆比較不同超參數的訓練結果
    <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>透過 TensorBoard，你能非常清楚地比較不同實驗以及不同點子的效果，知道什麼 work 什麼不 work，進而修正之後嘗試的方向。如果只是簡單寫個 <code>print</code>，那你永遠只會看到最新一次訓練過程的 log，然後忘記之前到底發生過什麼事。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="實際進行英翻中">實際進行英翻中<a class="anchor-link" href="#實際進行英翻中">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>有了已經訓練一陣子的 Transformer，當然得拿它來實際做做翻譯。</p>
<p>跟訓練的時候不同，在做預測時我們不需做 teacher forcing 來穩定 Transformer 的訓練過程。反之，我們將 Transformer 在每個時間點生成的中文索引加到之前已經生成的序列尾巴，並以此新序列作為其下一次的輸入。這是因為 Transformer 事實上是一個<a href="https://zh.wikipedia.org/wiki/%E8%87%AA%E8%BF%B4%E6%AD%B8%E6%A8%A1%E5%9E%8B">自迴歸模型（Auto-regressive  model）</a>：依據自己生成的結果預測下次輸出。</p>
<p>利用 Transformer 進行翻譯（預測）的邏輯如下：</p>
<ul>
<li>將輸入的英文句子利用 Subword Tokenizer 轉換成子詞索引序列（還記得 <code>inp</code> 吧？）</li>
<li>在該英文索引序列前後加上代表英文 BOS / EOS 的 tokens</li>
<li>在 Transformer 輸出序列長度達到 <code>MAX_LENGTH</code> 之前重複以下步驟：<ul>
<li>為目前已經生成的中文索引序列產生新的遮罩</li>
<li>將剛剛的英文序列、當前的中文序列以及各種遮罩放入 Transformer</li>
<li>將 Transformer 輸出序列的最後一個位置的向量取出，並取 argmax 取得新的預測中文索引</li>
<li>將此索引加到目前的中文索引序列裡頭作為 Transformer 到此為止的輸出結果</li>
<li>如果新生成的中文索引為 <code>&lt;end&gt;</code> 則代表中文翻譯已全部生成完畢，直接回傳</li>
</ul>
</li>
<li>將最後得到的中文索引序列回傳作為翻譯結果</li>
</ul>
<p>是的，一個時間點生成一個中文字，而在第一個時間點因為 Transformer 還沒有任何輸出，我們會丟中文字的 <code>&lt;start&gt;</code> token 進去。你可能會想：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        為何每次翻譯開頭都是 start token，Transformer 還能產生不一樣且正確的結果？
                        <br/>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>答案也很簡單，因為 Decoder 可以透過「關注」 Encoder 處理完不同英文句子的輸出來獲得語義資訊，了解它在當下該生成什麼中文字作為第一個輸出。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>現在讓我們定義一個 <code>evaluate</code> 函式實現上述邏輯。此函式的輸入是一個完全沒有經過處理的英文句子（以字串表示），輸出則是一個索引序列，裡頭的每個索引就代表著 Transformer 預測的中文字。</p>
<p>讓我們實際看看 <code>evaluate</code> 函式：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 給定一個英文句子，輸出預測的中文索引數字序列以及注意權重 dict</span>
<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">inp_sentence</span><span class="p">):</span>
  
  <span class="c1"># 準備英文句子前後會加上的 &lt;start&gt;, &lt;end&gt;</span>
  <span class="n">start_token</span> <span class="o">=</span> <span class="p">[</span><span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">]</span>
  <span class="n">end_token</span> <span class="o">=</span> <span class="p">[</span><span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
  
  <span class="c1"># inp_sentence 是字串，我們用 Subword Tokenizer 將其變成子詞的索引序列</span>
  <span class="c1"># 並在前後加上 BOS / EOS</span>
  <span class="n">inp_sentence</span> <span class="o">=</span> <span class="n">start_token</span> <span class="o">+</span> <span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">inp_sentence</span><span class="p">)</span> <span class="o">+</span> <span class="n">end_token</span>
  <span class="n">encoder_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">inp_sentence</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
  
  <span class="c1"># 跟我們在影片裡看到的一樣，Decoder 在第一個時間點吃進去的輸入</span>
  <span class="c1"># 是一個只包含一個中文 &lt;start&gt; token 的序列</span>
  <span class="n">decoder_input</span> <span class="o">=</span> <span class="p">[</span><span class="n">subword_encoder_zh</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">]</span>
  <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># 增加 batch 維度</span>
  
  <span class="c1"># auto-regressive，一次生成一個中文字並將預測加到輸入再度餵進 Transformer</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">):</span>
    <span class="c1"># 每多一個生成的字就得產生新的遮罩</span>
    <span class="n">enc_padding_mask</span><span class="p">,</span> <span class="n">combined_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span> <span class="o">=</span> <span class="n">create_masks</span><span class="p">(</span>
        <span class="n">encoder_input</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
  
    <span class="c1"># predictions.shape == (batch_size, seq_len, vocab_size)</span>
    <span class="n">predictions</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">transformer</span><span class="p">(</span><span class="n">encoder_input</span><span class="p">,</span> 
                                                 <span class="n">output</span><span class="p">,</span>
                                                 <span class="kc">False</span><span class="p">,</span>
                                                 <span class="n">enc_padding_mask</span><span class="p">,</span>
                                                 <span class="n">combined_mask</span><span class="p">,</span>
                                                 <span class="n">dec_padding_mask</span><span class="p">)</span>
    

    <span class="c1"># 將序列中最後一個 distribution 取出，並將裡頭值最大的當作模型最新的預測字</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[:</span> <span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># (batch_size, 1, vocab_size)</span>

    <span class="n">predicted_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    
    <span class="c1"># 遇到 &lt;end&gt; token 就停止回傳，代表模型已經產生完結果</span>
    <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">predicted_id</span><span class="p">,</span> <span class="n">subword_encoder_zh</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">attention_weights</span>
    
    <span class="c1">#將 Transformer 新預測的中文索引加到輸出序列中，讓 Decoder 可以在產生</span>
    <span class="c1"># 下個中文字的時候關注到最新的 `predicted_id`</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">output</span><span class="p">,</span> <span class="n">predicted_id</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

  <span class="c1"># 將 batch 的維度去掉後回傳預測的中文索引序列</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">attention_weights</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>我知道這章節程式碼很多很長，但搭配註解後你會發現它們實際上都不難，而且這也是你看這篇文章的主要目的：實際了解 Transformer 是怎麼做英中翻譯的。你不想只是紙上談兵，對吧？</p>
<p>有了 <code>evaluate</code> 函式，要透過 Transformer 做翻譯非常容易：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 要被翻譯的英文句子</span>
<span class="n">sentence</span> <span class="o">=</span> <span class="s2">"China, India, and others have enjoyed continuing economic growth."</span>

<span class="c1"># 取得預測的中文索引序列</span>
<span class="n">predicted_seq</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>

<span class="c1"># 過濾掉 &lt;start&gt; &amp; &lt;end&gt; tokens 並用中文的 subword tokenizer 幫我們將索引序列還原回中文句子</span>
<span class="n">target_vocab_size</span> <span class="o">=</span> <span class="n">subword_encoder_zh</span><span class="o">.</span><span class="n">vocab_size</span>
<span class="n">predicted_seq_without_bos_eos</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">predicted_seq</span> <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="n">target_vocab_size</span><span class="p">]</span>
<span class="n">predicted_sentence</span> <span class="o">=</span> <span class="n">subword_encoder_zh</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">predicted_seq_without_bos_eos</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"sentence:"</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"predicted_seq:"</span><span class="p">,</span> <span class="n">predicted_seq</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"predicted_sentence:"</span><span class="p">,</span> <span class="n">predicted_sentence</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>sentence: China, India, and others have enjoyed continuing economic growth.
--------------------
predicted_seq: tf.Tensor(
[4201   16    4   37  386  101    8   34   32    4   33  110  956  186
   14   22   52  107   84    1  104  292   49  218    3], shape=(25,), dtype=int32)
--------------------
predicted_sentence: 中国、印度和其他国家都享受了经济增长的持续发展。
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>考慮到這個 Transformer 不算巨大（約 400 萬個參數），且模型訓練時用的數據集不大的情況下，我們達到相當不錯的結果，你說是吧？在這個例子裡頭該翻的詞彙都翻了出來，句子本身也還算自然。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">transformer</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: "transformer_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
encoder_2 (Encoder)          multiple                  1834624   
_________________________________________________________________
decoder_2 (Decoder)          multiple                  1596288   
_________________________________________________________________
dense_137 (Dense)            multiple                  542187    
=================================================================
Total params: 3,973,099
Trainable params: 3,973,099
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="視覺化注意權重">視覺化注意權重<a class="anchor-link" href="#視覺化注意權重">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>除了其運算高度平行以及表現不錯以外，Transformer 另外一個優點在於我們可以透過視覺化注意權重（attention weights）來了解模型實際在生成序列的時候放「注意力」在哪裡。別忘記我們當初在 Decoder layers 做完 multi-head attention 之後都將注意權重輸出。現在正是它們派上用場的時候了。</p>
<p>先讓我們看看有什麼注意權重可以拿來視覺化：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">predicted_seq</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>

<span class="c1"># 在這邊我們自動選擇最後一個 Decoder layer 的 MHA 2，也就是 Decoder 關注 Encoder 的 MHA</span>
<span class="n">layer_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"decoder_layer</span><span class="si">{num_layers}</span><span class="s2">_block2"</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"sentence:"</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"predicted_seq:"</span><span class="p">,</span> <span class="n">predicted_seq</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"attention_weights.keys():"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">layer_name</span><span class="p">,</span> <span class="n">attn</span> <span class="ow">in</span> <span class="n">attention_weights</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{layer_name}</span><span class="s2">.shape: </span><span class="si">{attn.shape}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"-"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"layer_name:"</span><span class="p">,</span> <span class="n">layer_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>sentence: China, India, and others have enjoyed continuing economic growth.
--------------------
predicted_seq: tf.Tensor(
[4201   16    4   37  386  101    8   34   32    4   33  110  956  186
   14   22   52  107   84    1  104  292   49  218    3], shape=(25,), dtype=int32)
--------------------
attention_weights.keys():
decoder_layer1_block1.shape: (1, 8, 25, 25)
decoder_layer1_block2.shape: (1, 8, 25, 15)
decoder_layer2_block1.shape: (1, 8, 25, 25)
decoder_layer2_block2.shape: (1, 8, 25, 15)
decoder_layer3_block1.shape: (1, 8, 25, 25)
decoder_layer3_block2.shape: (1, 8, 25, 15)
decoder_layer4_block1.shape: (1, 8, 25, 25)
decoder_layer4_block2.shape: (1, 8, 25, 15)
--------------------
layer_name: decoder_layer4_block2
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>block1</code> 代表是 Decoder layer 自己關注自己的 MHA 1，因此倒數兩個維度都跟中文序列長度相同；<code>block2</code> 則是 Decoder layer 用來關注 Encoder 輸出的 MHA 2 ，在這邊我們選擇最後一個 Decoder layer 的 MHA 2 來看 Transformer 在生成中文序列時關注在英文句子的那些位置。</p>
<p>但首先，我們得要有一個繪圖的函式才行：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="c1"># 你可能會需要自行下載一個中文字體檔案以讓 matplotlib 正確顯示中文</span>
<span class="n">zhfont</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">font_manager</span><span class="o">.</span><span class="n">FontProperties</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s1">'/usr/share/fonts/SimHei/simhei.ttf'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"seaborn-whitegrid"</span><span class="p">)</span>

<span class="c1"># 這個函式將英 -&gt; 中翻譯的注意權重視覺化（注意：我們將注意權重 transpose 以最佳化渲染結果</span>
<span class="k">def</span> <span class="nf">plot_attention_weights</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">predicted_seq</span><span class="p">,</span> <span class="n">layer_name</span><span class="p">,</span> <span class="n">max_len_tar</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    
  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
  
  <span class="n">sentence</span> <span class="o">=</span> <span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
  
  <span class="c1"># 只顯示中文序列前 `max_len_tar` 個字以避免畫面太過壅擠</span>
  <span class="k">if</span> <span class="n">max_len_tar</span><span class="p">:</span>
    <span class="n">predicted_seq</span> <span class="o">=</span> <span class="n">predicted_seq</span><span class="p">[:</span><span class="n">max_len_tar</span><span class="p">]</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">max_len_tar</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">predicted_seq</span><span class="p">)</span>
  
  <span class="c1"># 將某一個特定 Decoder layer 裡頭的 MHA 1 或 MHA2 的注意權重拿出來並去掉 batch 維度</span>
  <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">[</span><span class="n">layer_name</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  
  <span class="c1"># (num_heads, tar_seq_len, inp_seq_len)</span>
  
  <span class="c1"># 將每個 head 的注意權重畫出</span>
  <span class="k">for</span> <span class="n">head</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">attention_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">head</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># [注意]我為了將長度不短的英文子詞顯示在 y 軸，將注意權重做了 transpose</span>
    <span class="n">attn_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">[</span><span class="n">head</span><span class="p">][:</span><span class="n">max_len_tar</span><span class="p">,</span> <span class="p">:])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">attn_map</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'viridis'</span><span class="p">)</span>  <span class="c1"># (inp_seq_len, tar_seq_len)</span>
    
    <span class="n">fontdict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"fontproperties"</span><span class="p">:</span> <span class="n">zhfont</span><span class="p">}</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">max_len_tar</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">predicted_seq</span><span class="p">))))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">max_len_tar</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">)</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="n">subword_encoder_zh</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">predicted_seq</span> 
                        <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">subword_encoder_zh</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">],</span> 
                       <span class="n">fontdict</span><span class="o">=</span><span class="n">fontdict</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>    
    
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span>
        <span class="p">[</span><span class="s1">'&lt;start&gt;'</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">subword_encoder_en</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="s1">'&lt;end&gt;'</span><span class="p">],</span> 
        <span class="n">fontdict</span><span class="o">=</span><span class="n">fontdict</span><span class="p">)</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Head </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">head</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s2">"x"</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s2">"y"</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
  
  <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>這個函式不難，且裡頭不少是調整圖片的細節設定因此我將它留給你自行參考。</p>
<p>比較值得注意的是因為我們在這篇文章是做英文（來源）到中文（目標）的翻譯，注意權重的 shape 為：</p>
<div class="highlight"><pre><span></span>(batch_size, num_heads, zh_seq_len, en_seq_len)
</pre></div>
<p>如果你直接把注意權重繪出的話 y 軸就會是每個中文字，而 x 軸則會是每個英文子詞。而英文子詞繪在 x 軸太佔空間，我將每個注意權重都做 transpose 並呈現結果，這點你得注意一下。</p>
<p>讓我們馬上畫出剛剛翻譯的注意權重看看：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">plot_attention_weights</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> 
                       <span class="n">predicted_seq</span><span class="p">,</span> <span class="n">layer_name</span><span class="p">,</span> <span class="n">max_len_tar</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_png output_subarea">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABMUAAAHvCAYAAABUoWiWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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=
"/>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br/>
<br/></p>
<p>很美，不是嗎？</p>
<p>如果你還記得，我在本文開頭就曾經秀過這張圖甚至開玩笑地跟你說：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        好黑魔法，不學嗎？
                        <br/>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>我不知道你當初跟現在的感受，但我相信在你閱讀完本文，尤其是對自注意機制以及 Transformer 有了深刻理解之後，這之間的感受肯定是有不少差異的。</p>
<p>儘管其運算機制十分錯綜複雜，閱讀本文後 Transformer 對你來說不再是黑魔法，也不再是遙不可及的存在。如果你現在覺得「Transformer 也不過就這樣嘛！」那就達成我寫這篇文章的目的了。</p>
<p>自注意力機制以及 Transformer 在推出之後就被非常廣泛地使用並改進，但在我自己開始接觸相關知識以後一直沒有發現完整的繁中教學，因此寫了這篇當初的我殷殷期盼的文章，也希望能幫助到更多人學習。</p>
<p>在進入結語之前，讓我們看看文中的 Transformer 是怎麼逐漸學會做好翻譯的：</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><video autoplay="" loop="" muted="" playsinline="">
<source src="https://leemeng.tw/images/transformer/attention_weights_change_by_time.mp4" type="video/mp4"/>
    您的瀏覽器不支援影片標籤，請留言通知我：S
</video></p>
<center>
    Transformer 在訓練過程中逐漸學會關注在對的位置
    <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="在你離開之前">在你離開之前<a class="anchor-link" href="#在你離開之前">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        這篇是當初在學習 Transformer 的我希望有人分享給自己的文章。
                        <br/>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>我相信人類之所以強大是因為集體知識：我們能透過書籍、影片以及語言將一個人腦中的知識與思想共享給其他人，讓寶貴的知識能夠「scale」，在更多人的腦袋中發光發熱，創造更多價值。</p>
<p>我希望你有從本文中學到一點東西，並幫助我將本文的這些知識「scale」，把文章分享給更多有興趣的人，並利用所學應用在一些你一直想要完成的任務上面。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center>
<img src="https://leemeng.tw/images/bert/bert-intro.jpg"/>
</center>
<center>
                        以 Transformer 為基礎的語言代表模型 BERT
                        （<a href="https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html" target="_blank">圖片來源</a>）
                        
                        <br/>
<br/>
</center>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>如果你想要了解更多 Transformer 的相關應用，我推薦接著閱讀<a href="https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html">進擊的 BERT：NLP 界的巨人之力與遷移學習</a>，了解現在 NLP 領域裡頭知名的語言代表模型 BERT。</p>
<p>最後一點提醒，就算 Transformer 比古早時代的方法好再多終究也只是個工具，其最大價值不會超過於被你拿來應用的問題之上。就好像現在已有不少超越基本 Transformer 的翻譯方法，但我們仍然持續在追尋更好的機器翻譯系統。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        工具會被淘汰，需求一直都在。
                        <br/>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        " linebreaks: { automatic: true, width: '95% container' }, " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>


                <!-- Tags -->
                <p class="blog-content__tags">
                    <span>Post Tags</span>

                    <span class="blog-content__tag-list">
                        <a href="https://leemeng.tw/tag/zi-ran-yu-yan-chu-li.html" rel="tag">自然語言處理</a>
                        <a href="https://leemeng.tw/tag/nlp.html" rel="tag">NLP</a>
                        <a href="https://leemeng.tw/tag/tensorflow.html" rel="tag">Tensorflow</a>
                    </span>

                </p>















                <!-- end Tags -->


                <!-- Mail-list-subscribe -->
                <div id="article-inner-subscribe" class="blog-content__pagenav">
                    <div class="blog-content__nav">
                        <div class="blog-content__prev">
                            <a class="open-popup" rel="subscribe">
                                <span>Get Latest Arrivals</span>
                                訂閱最新文章
                            </a>
                        </div>
                        <div class="blog-content__next">
                            <p>
                                跟資料科學相關的最新文章直接送到家。</br>
                                只要加入訂閱名單，當新文章出爐時，</br>
                                你將能馬上收到通知 <i class="im im-newspaper-o" aria-hidden="true"></i>
                            </p>
                        </div>
                    </div>
                    <div class="blog-content__all">
                        <a class="open-popup btn btn--primary ">&nbsp;&nbsp;Subscribe&nbsp;&nbsp;&nbsp;</a>
                    </div>
                </div>
                <!-- end Mail-list-subscribe -->

                <!--Pagination-->
                <div id="article-inner-neighbor-pages" class="blog-content__pagenav">
                    <div class="blog-content__nav">
                        <div class="blog-content__prev">
                            <a href="https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html" rel="prev">
                                <span>Previous Post</span>
                                進擊的 BERT：NLP 界的巨人之力與遷移學習
                            </a>
                        </div>
                        <div class="blog-content__next">
                            <a href="https://leemeng.tw/generate-anime-using-cartoongan-and-tensorflow2.html" rel="next">
                                <span>Next Post</span>
                                用 CartoonGAN 及 TensorFlow 2 生成新海誠與宮崎駿動畫
                            </a>
                        </div>
                    </div>

                    <div class="blog-content__all">
                        <a href="blog.html" class="btn btn--primary">
                            View All Post
                        </a>
                    </div>
                </div>
                <!-- end Pagination-->

            </div><!-- end blog-content__main -->


        </div>
        </div> <!-- end blog-content -->

    </article>

<div class="comments-wrap">
    <div id="comments" class="row">
        <div class="col-full">
            <div id="disqus_thread"></div>
        </div>
    </div>
</div>

<script type="text/javascript">
var disqus_shortname = 'leemengtaiwan';
var disqus_title = '淺談神經機器翻譯 & 用 Transformer 與 TensorFlow 2 英翻中';

(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


<!-- footer
================================================== -->
<footer style="background:#0a0809">
    <div class="row">
        <div class="col-full">

            <div class="footer-logo">
                <a class="footer-site-logo" href="#0"><img src="https://leemeng.tw/theme/images/logo.png" alt="Homepage"></a>
            </div>

            <ul class="footer-social">
<li><a href="https://github.com/leemengtaiwan" target="_blank">
    <i class="im im-github" aria-hidden="true"></i>
    <span>Github</span>
</a></li>
<li><a href="https://www.facebook.com/LeeMengTaiwan" target="_blank">
    <i class="im im-facebook" aria-hidden="true"></i>
    <span>Facebook</span>
</a></li>
<li><a href="https://www.instagram.com/leemengtaiwan/" target="_blank">
    <i class="im im-instagram" aria-hidden="true"></i>
    <span>Instagram</span>
</a></li>
<li><a href="https://www.linkedin.com/in/leemeng1990/" target="_blank">
    <i class="im im-linkedin" aria-hidden="true"></i>
    <span>LinkedIn</span>
</a></li>            </ul>
        </div>
    </div>
    <div class="row footer-bottom">
        <div class="col-twelve">
            <div class="go-top">
            <a class="smoothscroll" title="Back to Top" href="#top"><i class="im im-arrow-up" aria-hidden="true"></i></a>
            </div>
        </div>
    </div> <!-- end footer-bottom -->
</footer> <!-- end footer -->


        <!-- Javascript
    ================================================== -->
    <script src="https://leemeng.tw/theme/js/jquery-3.2.1.min.js"></script>
    <script src="https://leemeng.tw/theme/js/plugins.js"></script>
    <script src="https://leemeng.tw/theme/js/main_raw.js"></script>
    <script type='text/javascript' src='https://leemeng.tw/theme/js/scroll-detect.js'></script>

    <!--https://instant.page/-->
    <script src="//instant.page/1.0.0" type="module" integrity="sha384-6w2SekMzCkuMQ9sEbq0cLviD/yR2HfA/+ekmKiBnFlsoSvb/VmQFSi/umVShadQI"></script>


    <script type='text/javascript' src='https://leemeng.tw/theme/js/progress-bar.js'></script>
    <script type='text/javascript' src='https://leemeng.tw/theme/js/scroll-detect.js'></script>

    <!--show and hide left navigation by scrolling-->
    <script>
    $(document).scroll(function() {
        var y = $(this).scrollTop();
      if ( $(window).width() > 980 ) {
        if (y > 600) {
          $('#left-navigation').fadeIn(300);
        } else {
          $('#left-navigation').fadeOut(300);
        }
      }
    });
    </script>

<!--reference: https://gist.github.com/scottmagdalein/259d878ad46ed6f2cdce-->
<script type="text/javascript" src="//downloads.mailchimp.com/js/signup-forms/popup/embed.js" data-dojo-config="usePlainJson: true, isDebug: false">
</script>

<script type="text/javascript">
  function showMailingPopUp() {
    require(["mojo/signup-forms/Loader"], function(L) { L.start({"baseUrl":"mc.us18.list-manage.com","uuid":"151cb59f2de814c499c76b77a","lid":"dd1d78cc5e"})})
    document.cookie = "MCPopupClosed=; expires=Thu, 01 Jan 1970 00:00:00 UTC";
    document.cookie = "MCPopupSubscribed=; expires=Thu, 01 Jan 1970 00:00:00 UTC";
  };

  $(function() {
    $(".open-popup").on('click', function() {
      showMailingPopUp();
    });
  });
</script><!--https://darkmodejs.learn.uno/-->
<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.4.0/lib/darkmode-js.min.js"></script>
<script>
var options = {
  bottom: '32px', // default: '32px'
  right: 'unset', // default: '32px'
  left: '32px', // default: 'unset'
  time: '0.2s', // default: '0.3s'
  mixColor: '#fff', // default: '#fff'
  backgroundColor: '#fff',  // default: '#fff'
  buttonColorDark: '#100f2c',  // default: '#100f2c'
  buttonColorLight: '#fff', // default: '#fff'
  saveInCookies: true, // default: true,
  label: '🌓', // default: ''
  autoMatchOsTheme: true // default: true
}

const darkmode = new Darkmode(options);
darkmode.showWidget();
</script>
<!--reference: https://www.w3schools.com/howto/tryit.asp?filename=tryhow_js_overlay-->
<script>
function openTocNav() {
    document.getElementById("tocNav").style.width = "100%";
}

function closeTocNav() {
    document.getElementById("tocNav").style.width = "0%";
}

function toggleTocNav() {
    var current_width = document.getElementById("tocNav").style.width;
    if (current_width == "100%") {
        document.getElementById("tocNav").style.width = "0%";
    } else {
        document.getElementById("tocNav").style.width = "100%";
    }
}

function closeLeftNavImage(elementId) {
    document.getElementById(elementId).style.width = "0%";
}

function toggleLeftNavImage(elementId) {
    var current_width = document.getElementById(elementId).style.width;
    if (current_width == "100%") {
        document.getElementById(elementId).style.width = "0%";
    } else {
        document.getElementById(elementId).style.width = "100%";
    }
}

</script>


</body>
</html>